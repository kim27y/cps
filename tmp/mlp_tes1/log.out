2022-10-17 14:59:10,380 - trainer - INFO - MLP(
  (linears): ModuleList(
    (0): Linear(in_features=1, out_features=128, bias=True)
    (1): Linear(in_features=128, out_features=64, bias=True)
    (2): Linear(in_features=64, out_features=32, bias=True)
  )
  (activation_layers): ModuleList(
    (0): ReLU(inplace=True)
    (1): ReLU(inplace=True)
    (2): ReLU(inplace=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
  (linear_output): Linear(in_features=32, out_features=3, bias=True)
)
2022-10-17 14:59:10,381 - trainer - INFO -   Total params: 10691
2022-10-17 14:59:10,382 - trainer - INFO -   Trainable params: 10691
2022-10-17 14:59:10,382 - trainer - INFO -   Non-trainable params: 0
2022-10-17 14:59:10,382 - trainer - INFO -   There are 6  training examples
2022-10-17 14:59:10,383 - trainer - INFO -   There are 6 examples for development
2022-10-17 14:59:10,508 - trainer - INFO - start training epoch 1
2022-10-17 14:59:10,508 - trainer - INFO - training using device=cuda
2022-10-17 14:59:10,508 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:10,509 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:11,603 - trainer - INFO - 
*****************[epoch: 1, global step: 2] eval training set at end of epoch***************
2022-10-17 14:59:11,607 - trainer - INFO -               precision    recall  f1-score   support

           0       0.33      1.00      0.50         2
           1       0.00      0.00      0.00         2
           2       0.00      0.00      0.00         2

    accuracy                           0.33         6
   macro avg       0.11      0.33      0.17         6
weighted avg       0.11      0.33      0.17         6

2022-10-17 14:59:11,609 - trainer - INFO - {
  "train_accuracy_score": 0.3333333333333333,
  "train_loss": 1.1227144002914429
}
2022-10-17 14:59:11,610 - trainer - INFO - start training epoch 2
2022-10-17 14:59:11,611 - trainer - INFO - training using device=cuda
2022-10-17 14:59:11,611 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:11,613 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:11,621 - trainer - INFO - 
*****************[epoch: 2, global step: 2] eval training set based on eval_every=2***************
2022-10-17 14:59:11,625 - trainer - INFO -               precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.33      1.00      0.50         2
           2       0.00      0.00      0.00         2

    accuracy                           0.33         6
   macro avg       0.11      0.33      0.17         6
weighted avg       0.11      0.33      0.17         6

2022-10-17 14:59:11,627 - trainer - INFO - {
  "train_accuracy_score": 0.3333333333333333,
  "train_loss": 1.2274925708770752
}
2022-10-17 14:59:11,640 - trainer - INFO - 
*****************[epoch: 2, global step: 2] eval development set based on eval_every=2***************
2022-10-17 14:59:11,645 - trainer - INFO -               precision    recall  f1-score   support

         0.0       0.00      0.00      0.00         2
         1.0       0.00      0.00      0.00         2
         2.0       0.33      1.00      0.50         2

    accuracy                           0.33         6
   macro avg       0.11      0.33      0.17         6
weighted avg       0.11      0.33      0.17         6

2022-10-17 14:59:11,646 - trainer - INFO - {
  "dev_loss": 1.1804144382476807,
  "dev_accuracy": 0.3333333333333333,
  "dev_best_score_for_accuracy": 0.3333333333333333
}
2022-10-17 14:59:11,647 - trainer - INFO -    save the model with best score so far
2022-10-17 14:59:11,648 - trainer - INFO -    Check 0 checkpoints already saved
2022-10-17 14:59:11,648 - trainer - INFO -   Save checkpoint to tmp/mlp_tes1
2022-10-17 14:59:11,652 - trainer - INFO - save model to path: tmp/mlp_tes1
2022-10-17 14:59:11,652 - trainer - INFO -   no_improve_count: 0
2022-10-17 14:59:11,652 - trainer - INFO -   patience: 200
2022-10-17 14:59:11,654 - trainer - INFO -    Check 0 checkpoints already saved
2022-10-17 14:59:11,654 - trainer - INFO -   Save checkpoint to tmp/mlp_tes1\ck_2
2022-10-17 14:59:11,658 - trainer - INFO - save model to path: tmp/mlp_tes1\ck_2
2022-10-17 14:59:11,659 - trainer - INFO - 
*****************[epoch: 2, global step: 3] eval training set at end of epoch***************
2022-10-17 14:59:11,665 - trainer - INFO -               precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.33      1.00      0.50         2
           2       0.00      0.00      0.00         2

    accuracy                           0.33         6
   macro avg       0.11      0.33      0.17         6
weighted avg       0.11      0.33      0.17         6

2022-10-17 14:59:11,666 - trainer - INFO - {
  "train_accuracy_score": 0.3333333333333333,
  "train_loss": 1.3322707414627075
}
2022-10-17 14:59:11,666 - trainer - INFO - start training epoch 3
2022-10-17 14:59:11,667 - trainer - INFO - training using device=cuda
2022-10-17 14:59:11,667 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:11,668 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:11,678 - trainer - INFO - 
*****************[epoch: 3, global step: 4] eval training set at end of epoch***************
2022-10-17 14:59:11,683 - trainer - INFO -               precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.00      0.00      0.00         2
           2       0.33      1.00      0.50         2

    accuracy                           0.33         6
   macro avg       0.11      0.33      0.17         6
weighted avg       0.11      0.33      0.17         6

2022-10-17 14:59:11,684 - trainer - INFO - {
  "train_accuracy_score": 0.3333333333333333,
  "train_loss": 1.1867318153381348
}
2022-10-17 14:59:11,686 - trainer - INFO - start training epoch 4
2022-10-17 14:59:11,687 - trainer - INFO - training using device=cuda
2022-10-17 14:59:11,687 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:11,688 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:11,696 - trainer - INFO - 
*****************[epoch: 4, global step: 4] eval training set based on eval_every=2***************
2022-10-17 14:59:11,700 - trainer - INFO -               precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.00      0.00      0.00         2
           2       0.33      1.00      0.50         2

    accuracy                           0.33         6
   macro avg       0.11      0.33      0.17         6
weighted avg       0.11      0.33      0.17         6

2022-10-17 14:59:11,702 - trainer - INFO - {
  "train_accuracy_score": 0.3333333333333333,
  "train_loss": 1.1695498824119568
}
2022-10-17 14:59:11,719 - trainer - INFO - 
*****************[epoch: 4, global step: 4] eval development set based on eval_every=2***************
2022-10-17 14:59:11,725 - trainer - INFO -               precision    recall  f1-score   support

         0.0       0.33      1.00      0.50         2
         1.0       0.00      0.00      0.00         2
         2.0       0.00      0.00      0.00         2

    accuracy                           0.33         6
   macro avg       0.11      0.33      0.17         6
weighted avg       0.11      0.33      0.17         6

2022-10-17 14:59:11,726 - trainer - INFO - {
  "dev_loss": 1.1345025300979614,
  "dev_accuracy": 0.3333333333333333,
  "dev_best_score_for_accuracy": 0.3333333333333333
}
2022-10-17 14:59:11,727 - trainer - INFO -   no_improve_count: 1
2022-10-17 14:59:11,728 - trainer - INFO -   patience: 200
2022-10-17 14:59:11,729 - trainer - INFO -    Check 1 checkpoints already saved
2022-10-17 14:59:11,729 - trainer - INFO -   Save checkpoint to tmp/mlp_tes1\ck_4
2022-10-17 14:59:11,733 - trainer - INFO - save model to path: tmp/mlp_tes1\ck_4
2022-10-17 14:59:11,735 - trainer - INFO - 
*****************[epoch: 4, global step: 5] eval training set at end of epoch***************
2022-10-17 14:59:11,739 - trainer - INFO -               precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.00      0.00      0.00         2
           2       0.33      1.00      0.50         2

    accuracy                           0.33         6
   macro avg       0.11      0.33      0.17         6
weighted avg       0.11      0.33      0.17         6

2022-10-17 14:59:11,740 - trainer - INFO - {
  "train_accuracy_score": 0.3333333333333333,
  "train_loss": 1.1523679494857788
}
2022-10-17 14:59:11,742 - trainer - INFO - start training epoch 5
2022-10-17 14:59:11,742 - trainer - INFO - training using device=cuda
2022-10-17 14:59:11,743 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:11,744 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:11,751 - trainer - INFO - 
*****************[epoch: 5, global step: 6] eval training set at end of epoch***************
2022-10-17 14:59:11,755 - trainer - INFO -               precision    recall  f1-score   support

           0       0.33      1.00      0.50         2
           1       0.00      0.00      0.00         2
           2       0.00      0.00      0.00         2

    accuracy                           0.33         6
   macro avg       0.11      0.33      0.17         6
weighted avg       0.11      0.33      0.17         6

2022-10-17 14:59:11,756 - trainer - INFO - {
  "train_accuracy_score": 0.3333333333333333,
  "train_loss": 1.1263970136642456
}
2022-10-17 14:59:11,756 - trainer - INFO - start training epoch 6
2022-10-17 14:59:11,757 - trainer - INFO - training using device=cuda
2022-10-17 14:59:11,757 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:11,758 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:11,768 - trainer - INFO - 
*****************[epoch: 6, global step: 6] eval training set based on eval_every=2***************
2022-10-17 14:59:11,771 - trainer - INFO -               precision    recall  f1-score   support

           0       0.33      1.00      0.50         2
           1       0.00      0.00      0.00         2
           2       0.00      0.00      0.00         2

    accuracy                           0.33         6
   macro avg       0.11      0.33      0.17         6
weighted avg       0.11      0.33      0.17         6

2022-10-17 14:59:11,772 - trainer - INFO - {
  "train_accuracy_score": 0.3333333333333333,
  "train_loss": 1.1191442012786865
}
2022-10-17 14:59:11,784 - trainer - INFO - 
*****************[epoch: 6, global step: 6] eval development set based on eval_every=2***************
2022-10-17 14:59:11,787 - trainer - INFO -               precision    recall  f1-score   support

         0.0       0.33      1.00      0.50         2
         1.0       0.00      0.00      0.00         2
         2.0       0.00      0.00      0.00         2

    accuracy                           0.33         6
   macro avg       0.11      0.33      0.17         6
weighted avg       0.11      0.33      0.17         6

2022-10-17 14:59:11,788 - trainer - INFO - {
  "dev_loss": 1.0846980810165405,
  "dev_accuracy": 0.3333333333333333,
  "dev_best_score_for_accuracy": 0.3333333333333333
}
2022-10-17 14:59:11,788 - trainer - INFO -   no_improve_count: 2
2022-10-17 14:59:11,789 - trainer - INFO -   patience: 200
2022-10-17 14:59:11,790 - trainer - INFO -    Check 2 checkpoints already saved
2022-10-17 14:59:11,790 - trainer - INFO -   Save checkpoint to tmp/mlp_tes1\ck_6
2022-10-17 14:59:11,794 - trainer - INFO - save model to path: tmp/mlp_tes1\ck_6
2022-10-17 14:59:11,796 - trainer - INFO - 
*****************[epoch: 6, global step: 7] eval training set at end of epoch***************
2022-10-17 14:59:11,802 - trainer - INFO -               precision    recall  f1-score   support

           0       0.33      1.00      0.50         2
           1       0.00      0.00      0.00         2
           2       0.00      0.00      0.00         2

    accuracy                           0.33         6
   macro avg       0.11      0.33      0.17         6
weighted avg       0.11      0.33      0.17         6

2022-10-17 14:59:11,803 - trainer - INFO - {
  "train_accuracy_score": 0.3333333333333333,
  "train_loss": 1.1118913888931274
}
2022-10-17 14:59:11,804 - trainer - INFO - start training epoch 7
2022-10-17 14:59:11,804 - trainer - INFO - training using device=cuda
2022-10-17 14:59:11,805 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:11,805 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:11,814 - trainer - INFO - 
*****************[epoch: 7, global step: 8] eval training set at end of epoch***************
2022-10-17 14:59:11,817 - trainer - INFO -               precision    recall  f1-score   support

           0       0.33      1.00      0.50         2
           1       0.00      0.00      0.00         2
           2       0.00      0.00      0.00         2

    accuracy                           0.33         6
   macro avg       0.11      0.33      0.17         6
weighted avg       0.11      0.33      0.17         6

2022-10-17 14:59:11,818 - trainer - INFO - {
  "train_accuracy_score": 0.3333333333333333,
  "train_loss": 1.1102274656295776
}
2022-10-17 14:59:11,819 - trainer - INFO - start training epoch 8
2022-10-17 14:59:11,819 - trainer - INFO - training using device=cuda
2022-10-17 14:59:11,820 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:11,820 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:11,827 - trainer - INFO - 
*****************[epoch: 8, global step: 8] eval training set based on eval_every=2***************
2022-10-17 14:59:11,832 - trainer - INFO -               precision    recall  f1-score   support

           0       0.33      1.00      0.50         2
           1       0.00      0.00      0.00         2
           2       0.00      0.00      0.00         2

    accuracy                           0.33         6
   macro avg       0.11      0.33      0.17         6
weighted avg       0.11      0.33      0.17         6

2022-10-17 14:59:11,833 - trainer - INFO - {
  "train_accuracy_score": 0.3333333333333333,
  "train_loss": 1.1055335998535156
}
2022-10-17 14:59:11,846 - trainer - INFO - 
*****************[epoch: 8, global step: 8] eval development set based on eval_every=2***************
2022-10-17 14:59:11,852 - trainer - INFO -               precision    recall  f1-score   support

         0.0       0.33      1.00      0.50         2
         1.0       0.00      0.00      0.00         2
         2.0       0.00      0.00      0.00         2

    accuracy                           0.33         6
   macro avg       0.11      0.33      0.17         6
weighted avg       0.11      0.33      0.17         6

2022-10-17 14:59:11,852 - trainer - INFO - {
  "dev_loss": 1.0997352600097656,
  "dev_accuracy": 0.3333333333333333,
  "dev_best_score_for_accuracy": 0.3333333333333333
}
2022-10-17 14:59:11,853 - trainer - INFO -   no_improve_count: 3
2022-10-17 14:59:11,854 - trainer - INFO -   patience: 200
2022-10-17 14:59:11,855 - trainer - INFO -    Check 3 checkpoints already saved
2022-10-17 14:59:11,856 - trainer - INFO -    There are more than keep_ck_num as specified, then remove the oldest saved checkpoint
2022-10-17 14:59:11,856 - trainer - INFO -   Remove checkpoint tmp/mlp_tes1\ck_2
2022-10-17 14:59:11,858 - trainer - INFO -   Save checkpoint to tmp/mlp_tes1\ck_8
2022-10-17 14:59:11,864 - trainer - INFO - save model to path: tmp/mlp_tes1\ck_8
2022-10-17 14:59:11,865 - trainer - INFO - 
*****************[epoch: 8, global step: 9] eval training set at end of epoch***************
2022-10-17 14:59:11,873 - trainer - INFO -               precision    recall  f1-score   support

           0       0.33      1.00      0.50         2
           1       0.00      0.00      0.00         2
           2       0.00      0.00      0.00         2

    accuracy                           0.33         6
   macro avg       0.11      0.33      0.17         6
weighted avg       0.11      0.33      0.17         6

2022-10-17 14:59:11,874 - trainer - INFO - {
  "train_accuracy_score": 0.3333333333333333,
  "train_loss": 1.1008397340774536
}
2022-10-17 14:59:11,876 - trainer - INFO - start training epoch 9
2022-10-17 14:59:11,876 - trainer - INFO - training using device=cuda
2022-10-17 14:59:11,877 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:11,878 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:11,888 - trainer - INFO - 
*****************[epoch: 9, global step: 10] eval training set at end of epoch***************
2022-10-17 14:59:11,894 - trainer - INFO -               precision    recall  f1-score   support

           0       0.33      1.00      0.50         2
           1       0.00      0.00      0.00         2
           2       0.00      0.00      0.00         2

    accuracy                           0.33         6
   macro avg       0.11      0.33      0.17         6
weighted avg       0.11      0.33      0.17         6

2022-10-17 14:59:11,895 - trainer - INFO - {
  "train_accuracy_score": 0.3333333333333333,
  "train_loss": 1.0985790491104126
}
2022-10-17 14:59:11,896 - trainer - INFO - start training epoch 10
2022-10-17 14:59:11,897 - trainer - INFO - training using device=cuda
2022-10-17 14:59:11,898 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:11,899 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:11,909 - trainer - INFO - 
*****************[epoch: 10, global step: 10] eval training set based on eval_every=2***************
2022-10-17 14:59:11,914 - trainer - INFO -               precision    recall  f1-score   support

           0       0.33      1.00      0.50         2
           1       0.00      0.00      0.00         2
           2       0.00      0.00      0.00         2

    accuracy                           0.33         6
   macro avg       0.11      0.33      0.17         6
weighted avg       0.11      0.33      0.17         6

2022-10-17 14:59:11,916 - trainer - INFO - {
  "train_accuracy_score": 0.3333333333333333,
  "train_loss": 1.0981268286705017
}
2022-10-17 14:59:11,934 - trainer - INFO - 
*****************[epoch: 10, global step: 10] eval development set based on eval_every=2***************
2022-10-17 14:59:11,940 - trainer - INFO -               precision    recall  f1-score   support

         0.0       0.33      1.00      0.50         2
         1.0       0.00      0.00      0.00         2
         2.0       0.00      0.00      0.00         2

    accuracy                           0.33         6
   macro avg       0.11      0.33      0.17         6
weighted avg       0.11      0.33      0.17         6

2022-10-17 14:59:11,940 - trainer - INFO - {
  "dev_loss": 1.0986123085021973,
  "dev_accuracy": 0.3333333333333333,
  "dev_best_score_for_accuracy": 0.3333333333333333
}
2022-10-17 14:59:11,941 - trainer - INFO -   no_improve_count: 4
2022-10-17 14:59:11,942 - trainer - INFO -   patience: 200
2022-10-17 14:59:11,943 - trainer - INFO -    Check 3 checkpoints already saved
2022-10-17 14:59:11,943 - trainer - INFO -    There are more than keep_ck_num as specified, then remove the oldest saved checkpoint
2022-10-17 14:59:11,944 - trainer - INFO -   Remove checkpoint tmp/mlp_tes1\ck_4
2022-10-17 14:59:11,945 - trainer - INFO -   Save checkpoint to tmp/mlp_tes1\ck_10
2022-10-17 14:59:11,950 - trainer - INFO - save model to path: tmp/mlp_tes1\ck_10
2022-10-17 14:59:11,953 - trainer - INFO - 
*****************[epoch: 10, global step: 11] eval training set at end of epoch***************
2022-10-17 14:59:11,958 - trainer - INFO -               precision    recall  f1-score   support

           0       0.33      1.00      0.50         2
           1       0.00      0.00      0.00         2
           2       0.00      0.00      0.00         2

    accuracy                           0.33         6
   macro avg       0.11      0.33      0.17         6
weighted avg       0.11      0.33      0.17         6

2022-10-17 14:59:11,959 - trainer - INFO - {
  "train_accuracy_score": 0.3333333333333333,
  "train_loss": 1.0976746082305908
}
2022-10-17 14:59:11,960 - trainer - INFO - start training epoch 11
2022-10-17 14:59:11,961 - trainer - INFO - training using device=cuda
2022-10-17 14:59:11,962 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:11,962 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:11,971 - trainer - INFO - 
*****************[epoch: 11, global step: 12] eval training set at end of epoch***************
2022-10-17 14:59:11,975 - trainer - INFO -               precision    recall  f1-score   support

           0       0.67      1.00      0.80         2
           1       0.33      0.50      0.40         2
           2       0.00      0.00      0.00         2

    accuracy                           0.50         6
   macro avg       0.33      0.50      0.40         6
weighted avg       0.33      0.50      0.40         6

2022-10-17 14:59:11,976 - trainer - INFO - {
  "train_accuracy_score": 0.5,
  "train_loss": 1.0969043970108032
}
2022-10-17 14:59:11,979 - trainer - INFO - start training epoch 12
2022-10-17 14:59:11,980 - trainer - INFO - training using device=cuda
2022-10-17 14:59:11,981 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:11,981 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:11,990 - trainer - INFO - 
*****************[epoch: 12, global step: 12] eval training set based on eval_every=2***************
2022-10-17 14:59:11,996 - trainer - INFO -               precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.33      1.00      0.50         2
           2       0.00      0.00      0.00         2

    accuracy                           0.33         6
   macro avg       0.11      0.33      0.17         6
weighted avg       0.11      0.33      0.17         6

2022-10-17 14:59:11,997 - trainer - INFO - {
  "train_accuracy_score": 0.3333333333333333,
  "train_loss": 1.0966721177101135
}
2022-10-17 14:59:12,008 - trainer - INFO - 
*****************[epoch: 12, global step: 12] eval development set based on eval_every=2***************
2022-10-17 14:59:12,013 - trainer - INFO -               precision    recall  f1-score   support

         0.0       1.00      0.50      0.67         2
         1.0       0.40      1.00      0.57         2
         2.0       0.00      0.00      0.00         2

    accuracy                           0.50         6
   macro avg       0.47      0.50      0.41         6
weighted avg       0.47      0.50      0.41         6

2022-10-17 14:59:12,014 - trainer - INFO - {
  "dev_loss": 1.0939925909042358,
  "dev_accuracy": 0.5,
  "dev_best_score_for_accuracy": 0.5
}
2022-10-17 14:59:12,016 - trainer - INFO -    save the model with best score so far
2022-10-17 14:59:12,017 - trainer - INFO -    Check 3 checkpoints already saved
2022-10-17 14:59:12,017 - trainer - INFO -    There are more than keep_ck_num as specified, then remove the oldest saved checkpoint
2022-10-17 14:59:12,018 - trainer - INFO -   Remove checkpoint tmp/mlp_tes1\ck_6
2022-10-17 14:59:12,019 - trainer - INFO -   Save checkpoint to tmp/mlp_tes1
2022-10-17 14:59:12,023 - trainer - INFO - save model to path: tmp/mlp_tes1
2022-10-17 14:59:12,023 - trainer - INFO -   no_improve_count: 0
2022-10-17 14:59:12,023 - trainer - INFO -   patience: 200
2022-10-17 14:59:12,025 - trainer - INFO -    Check 2 checkpoints already saved
2022-10-17 14:59:12,025 - trainer - INFO -   Save checkpoint to tmp/mlp_tes1\ck_12
2022-10-17 14:59:12,030 - trainer - INFO - save model to path: tmp/mlp_tes1\ck_12
2022-10-17 14:59:12,031 - trainer - INFO - 
*****************[epoch: 12, global step: 13] eval training set at end of epoch***************
2022-10-17 14:59:12,035 - trainer - INFO -               precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.33      1.00      0.50         2
           2       0.00      0.00      0.00         2

    accuracy                           0.33         6
   macro avg       0.11      0.33      0.17         6
weighted avg       0.11      0.33      0.17         6

2022-10-17 14:59:12,036 - trainer - INFO - {
  "train_accuracy_score": 0.3333333333333333,
  "train_loss": 1.0964398384094238
}
2022-10-17 14:59:12,036 - trainer - INFO - start training epoch 13
2022-10-17 14:59:12,037 - trainer - INFO - training using device=cuda
2022-10-17 14:59:12,037 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:12,038 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:12,047 - trainer - INFO - 
*****************[epoch: 13, global step: 14] eval training set at end of epoch***************
2022-10-17 14:59:12,051 - trainer - INFO -               precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.33      1.00      0.50         2
           2       0.00      0.00      0.00         2

    accuracy                           0.33         6
   macro avg       0.11      0.33      0.17         6
weighted avg       0.11      0.33      0.17         6

2022-10-17 14:59:12,053 - trainer - INFO - {
  "train_accuracy_score": 0.3333333333333333,
  "train_loss": 1.0957143306732178
}
2022-10-17 14:59:12,053 - trainer - INFO - start training epoch 14
2022-10-17 14:59:12,054 - trainer - INFO - training using device=cuda
2022-10-17 14:59:12,054 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:12,055 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:12,064 - trainer - INFO - 
*****************[epoch: 14, global step: 14] eval training set based on eval_every=2***************
2022-10-17 14:59:12,068 - trainer - INFO -               precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.33      1.00      0.50         2
           2       0.00      0.00      0.00         2

    accuracy                           0.33         6
   macro avg       0.11      0.33      0.17         6
weighted avg       0.11      0.33      0.17         6

2022-10-17 14:59:12,069 - trainer - INFO - {
  "train_accuracy_score": 0.3333333333333333,
  "train_loss": 1.0950708985328674
}
2022-10-17 14:59:12,082 - trainer - INFO - 
*****************[epoch: 14, global step: 14] eval development set based on eval_every=2***************
2022-10-17 14:59:12,087 - trainer - INFO -               precision    recall  f1-score   support

         0.0       0.00      0.00      0.00         2
         1.0       0.33      1.00      0.50         2
         2.0       0.00      0.00      0.00         2

    accuracy                           0.33         6
   macro avg       0.11      0.33      0.17         6
weighted avg       0.11      0.33      0.17         6

2022-10-17 14:59:12,087 - trainer - INFO - {
  "dev_loss": 1.0997353792190552,
  "dev_accuracy": 0.3333333333333333,
  "dev_best_score_for_accuracy": 0.5
}
2022-10-17 14:59:12,090 - trainer - INFO -   no_improve_count: 1
2022-10-17 14:59:12,090 - trainer - INFO -   patience: 200
2022-10-17 14:59:12,091 - trainer - INFO -    Check 3 checkpoints already saved
2022-10-17 14:59:12,091 - trainer - INFO -    There are more than keep_ck_num as specified, then remove the oldest saved checkpoint
2022-10-17 14:59:12,092 - trainer - INFO -   Remove checkpoint tmp/mlp_tes1\ck_8
2022-10-17 14:59:12,093 - trainer - INFO -   Save checkpoint to tmp/mlp_tes1\ck_14
2022-10-17 14:59:12,097 - trainer - INFO - save model to path: tmp/mlp_tes1\ck_14
2022-10-17 14:59:12,098 - trainer - INFO - 
*****************[epoch: 14, global step: 15] eval training set at end of epoch***************
2022-10-17 14:59:12,102 - trainer - INFO -               precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.33      1.00      0.50         2
           2       0.00      0.00      0.00         2

    accuracy                           0.33         6
   macro avg       0.11      0.33      0.17         6
weighted avg       0.11      0.33      0.17         6

2022-10-17 14:59:12,103 - trainer - INFO - {
  "train_accuracy_score": 0.3333333333333333,
  "train_loss": 1.094427466392517
}
2022-10-17 14:59:12,105 - trainer - INFO - start training epoch 15
2022-10-17 14:59:12,106 - trainer - INFO - training using device=cuda
2022-10-17 14:59:12,107 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:12,108 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:12,117 - trainer - INFO - 
*****************[epoch: 15, global step: 16] eval training set at end of epoch***************
2022-10-17 14:59:12,122 - trainer - INFO -               precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.33      1.00      0.50         2
           2       0.00      0.00      0.00         2

    accuracy                           0.33         6
   macro avg       0.11      0.33      0.17         6
weighted avg       0.11      0.33      0.17         6

2022-10-17 14:59:12,123 - trainer - INFO - {
  "train_accuracy_score": 0.3333333333333333,
  "train_loss": 1.0922473669052124
}
2022-10-17 14:59:12,124 - trainer - INFO - start training epoch 16
2022-10-17 14:59:12,124 - trainer - INFO - training using device=cuda
2022-10-17 14:59:12,125 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:12,125 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:12,135 - trainer - INFO - 
*****************[epoch: 16, global step: 16] eval training set based on eval_every=2***************
2022-10-17 14:59:12,140 - trainer - INFO -               precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.33      1.00      0.50         2
           2       0.00      0.00      0.00         2

    accuracy                           0.33         6
   macro avg       0.11      0.33      0.17         6
weighted avg       0.11      0.33      0.17         6

2022-10-17 14:59:12,141 - trainer - INFO - {
  "train_accuracy_score": 0.3333333333333333,
  "train_loss": 1.09035986661911
}
2022-10-17 14:59:12,158 - trainer - INFO - 
*****************[epoch: 16, global step: 16] eval development set based on eval_every=2***************
2022-10-17 14:59:12,163 - trainer - INFO -               precision    recall  f1-score   support

         0.0       0.00      0.00      0.00         2
         1.0       0.33      1.00      0.50         2
         2.0       0.00      0.00      0.00         2

    accuracy                           0.33         6
   macro avg       0.11      0.33      0.17         6
weighted avg       0.11      0.33      0.17         6

2022-10-17 14:59:12,164 - trainer - INFO - {
  "dev_loss": 1.0785776376724243,
  "dev_accuracy": 0.3333333333333333,
  "dev_best_score_for_accuracy": 0.5
}
2022-10-17 14:59:12,165 - trainer - INFO -   no_improve_count: 2
2022-10-17 14:59:12,165 - trainer - INFO -   patience: 200
2022-10-17 14:59:12,167 - trainer - INFO -    Check 3 checkpoints already saved
2022-10-17 14:59:12,167 - trainer - INFO -    There are more than keep_ck_num as specified, then remove the oldest saved checkpoint
2022-10-17 14:59:12,168 - trainer - INFO -   Remove checkpoint tmp/mlp_tes1\ck_10
2022-10-17 14:59:12,169 - trainer - INFO -   Save checkpoint to tmp/mlp_tes1\ck_16
2022-10-17 14:59:12,174 - trainer - INFO - save model to path: tmp/mlp_tes1\ck_16
2022-10-17 14:59:12,176 - trainer - INFO - 
*****************[epoch: 16, global step: 17] eval training set at end of epoch***************
2022-10-17 14:59:12,181 - trainer - INFO -               precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.33      1.00      0.50         2
           2       0.00      0.00      0.00         2

    accuracy                           0.33         6
   macro avg       0.11      0.33      0.17         6
weighted avg       0.11      0.33      0.17         6

2022-10-17 14:59:12,182 - trainer - INFO - {
  "train_accuracy_score": 0.3333333333333333,
  "train_loss": 1.0884723663330078
}
2022-10-17 14:59:12,183 - trainer - INFO - start training epoch 17
2022-10-17 14:59:12,184 - trainer - INFO - training using device=cuda
2022-10-17 14:59:12,184 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:12,185 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:12,194 - trainer - INFO - 
*****************[epoch: 17, global step: 18] eval training set at end of epoch***************
2022-10-17 14:59:12,202 - trainer - INFO -               precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.33      1.00      0.50         2
           2       0.00      0.00      0.00         2

    accuracy                           0.33         6
   macro avg       0.11      0.33      0.17         6
weighted avg       0.11      0.33      0.17         6

2022-10-17 14:59:12,203 - trainer - INFO - {
  "train_accuracy_score": 0.3333333333333333,
  "train_loss": 1.0823341608047485
}
2022-10-17 14:59:12,204 - trainer - INFO - start training epoch 18
2022-10-17 14:59:12,205 - trainer - INFO - training using device=cuda
2022-10-17 14:59:12,205 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:12,206 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:12,215 - trainer - INFO - 
*****************[epoch: 18, global step: 18] eval training set based on eval_every=2***************
2022-10-17 14:59:12,220 - trainer - INFO -               precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.33      1.00      0.50         2
           2       0.00      0.00      0.00         2

    accuracy                           0.33         6
   macro avg       0.11      0.33      0.17         6
weighted avg       0.11      0.33      0.17         6

2022-10-17 14:59:12,222 - trainer - INFO - {
  "train_accuracy_score": 0.3333333333333333,
  "train_loss": 1.0776365995407104
}
2022-10-17 14:59:12,236 - trainer - INFO - 
*****************[epoch: 18, global step: 18] eval development set based on eval_every=2***************
2022-10-17 14:59:12,240 - trainer - INFO -               precision    recall  f1-score   support

         0.0       1.00      0.50      0.67         2
         1.0       0.40      1.00      0.57         2
         2.0       0.00      0.00      0.00         2

    accuracy                           0.50         6
   macro avg       0.47      0.50      0.41         6
weighted avg       0.47      0.50      0.41         6

2022-10-17 14:59:12,241 - trainer - INFO - {
  "dev_loss": 1.0624648332595825,
  "dev_accuracy": 0.5,
  "dev_best_score_for_accuracy": 0.5
}
2022-10-17 14:59:12,242 - trainer - INFO -   no_improve_count: 3
2022-10-17 14:59:12,242 - trainer - INFO -   patience: 200
2022-10-17 14:59:12,243 - trainer - INFO -    Check 3 checkpoints already saved
2022-10-17 14:59:12,244 - trainer - INFO -    There are more than keep_ck_num as specified, then remove the oldest saved checkpoint
2022-10-17 14:59:12,244 - trainer - INFO -   Remove checkpoint tmp/mlp_tes1\ck_12
2022-10-17 14:59:12,245 - trainer - INFO -   Save checkpoint to tmp/mlp_tes1\ck_18
2022-10-17 14:59:12,249 - trainer - INFO - save model to path: tmp/mlp_tes1\ck_18
2022-10-17 14:59:12,250 - trainer - INFO - 
*****************[epoch: 18, global step: 19] eval training set at end of epoch***************
2022-10-17 14:59:12,254 - trainer - INFO -               precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.33      1.00      0.50         2
           2       0.00      0.00      0.00         2

    accuracy                           0.33         6
   macro avg       0.11      0.33      0.17         6
weighted avg       0.11      0.33      0.17         6

2022-10-17 14:59:12,255 - trainer - INFO - {
  "train_accuracy_score": 0.3333333333333333,
  "train_loss": 1.0729390382766724
}
2022-10-17 14:59:12,256 - trainer - INFO - start training epoch 19
2022-10-17 14:59:12,256 - trainer - INFO - training using device=cuda
2022-10-17 14:59:12,257 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:12,257 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:12,268 - trainer - INFO - 
*****************[epoch: 19, global step: 20] eval training set at end of epoch***************
2022-10-17 14:59:12,272 - trainer - INFO -               precision    recall  f1-score   support

           0       1.00      0.50      0.67         2
           1       0.40      1.00      0.57         2
           2       0.00      0.00      0.00         2

    accuracy                           0.50         6
   macro avg       0.47      0.50      0.41         6
weighted avg       0.47      0.50      0.41         6

2022-10-17 14:59:12,273 - trainer - INFO - {
  "train_accuracy_score": 0.5,
  "train_loss": 1.059722900390625
}
2022-10-17 14:59:12,274 - trainer - INFO - start training epoch 20
2022-10-17 14:59:12,276 - trainer - INFO - training using device=cuda
2022-10-17 14:59:12,277 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:12,279 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:12,290 - trainer - INFO - 
*****************[epoch: 20, global step: 20] eval training set based on eval_every=2***************
2022-10-17 14:59:12,294 - trainer - INFO -               precision    recall  f1-score   support

           0       1.00      0.50      0.67         2
           1       0.67      1.00      0.80         2
           2       1.00      1.00      1.00         2

    accuracy                           0.83         6
   macro avg       0.89      0.83      0.82         6
weighted avg       0.89      0.83      0.82         6

2022-10-17 14:59:12,295 - trainer - INFO - {
  "train_accuracy_score": 0.8333333333333334,
  "train_loss": 1.0506644248962402
}
2022-10-17 14:59:12,309 - trainer - INFO - 
*****************[epoch: 20, global step: 20] eval development set based on eval_every=2***************
2022-10-17 14:59:12,317 - trainer - INFO -               precision    recall  f1-score   support

         0.0       0.50      1.00      0.67         2
         1.0       0.00      0.00      0.00         2
         2.0       0.00      0.00      0.00         2

    accuracy                           0.33         6
   macro avg       0.17      0.33      0.22         6
weighted avg       0.17      0.33      0.22         6

2022-10-17 14:59:12,318 - trainer - INFO - {
  "dev_loss": 1.0305157899856567,
  "dev_accuracy": 0.3333333333333333,
  "dev_best_score_for_accuracy": 0.5
}
2022-10-17 14:59:12,320 - trainer - INFO -   no_improve_count: 4
2022-10-17 14:59:12,321 - trainer - INFO -   patience: 200
2022-10-17 14:59:12,323 - trainer - INFO -    Check 3 checkpoints already saved
2022-10-17 14:59:12,325 - trainer - INFO -    There are more than keep_ck_num as specified, then remove the oldest saved checkpoint
2022-10-17 14:59:12,326 - trainer - INFO -   Remove checkpoint tmp/mlp_tes1\ck_14
2022-10-17 14:59:12,328 - trainer - INFO -   Save checkpoint to tmp/mlp_tes1\ck_20
2022-10-17 14:59:12,333 - trainer - INFO - save model to path: tmp/mlp_tes1\ck_20
2022-10-17 14:59:12,335 - trainer - INFO - 
*****************[epoch: 20, global step: 21] eval training set at end of epoch***************
2022-10-17 14:59:12,340 - trainer - INFO -               precision    recall  f1-score   support

           0       1.00      0.50      0.67         2
           1       0.67      1.00      0.80         2
           2       1.00      1.00      1.00         2

    accuracy                           0.83         6
   macro avg       0.89      0.83      0.82         6
weighted avg       0.89      0.83      0.82         6

2022-10-17 14:59:12,341 - trainer - INFO - {
  "train_accuracy_score": 0.8333333333333334,
  "train_loss": 1.0416059494018555
}
2022-10-17 14:59:12,344 - trainer - INFO - start training epoch 21
2022-10-17 14:59:12,346 - trainer - INFO - training using device=cuda
2022-10-17 14:59:12,347 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:12,348 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:12,360 - trainer - INFO - 
*****************[epoch: 21, global step: 22] eval training set at end of epoch***************
2022-10-17 14:59:12,366 - trainer - INFO -               precision    recall  f1-score   support

           0       0.50      1.00      0.67         2
           1       0.00      0.00      0.00         2
           2       1.00      1.00      1.00         2

    accuracy                           0.67         6
   macro avg       0.50      0.67      0.56         6
weighted avg       0.50      0.67      0.56         6

2022-10-17 14:59:12,368 - trainer - INFO - {
  "train_accuracy_score": 0.6666666666666666,
  "train_loss": 1.0330301523208618
}
2022-10-17 14:59:12,369 - trainer - INFO - start training epoch 22
2022-10-17 14:59:12,369 - trainer - INFO - training using device=cuda
2022-10-17 14:59:12,370 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:12,372 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:12,381 - trainer - INFO - 
*****************[epoch: 22, global step: 22] eval training set based on eval_every=2***************
2022-10-17 14:59:12,385 - trainer - INFO -               precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.00      0.00      0.00         2
           2       0.33      1.00      0.50         2

    accuracy                           0.33         6
   macro avg       0.11      0.33      0.17         6
weighted avg       0.11      0.33      0.17         6

2022-10-17 14:59:12,386 - trainer - INFO - {
  "train_accuracy_score": 0.3333333333333333,
  "train_loss": 1.0496550798416138
}
2022-10-17 14:59:12,397 - trainer - INFO - 
*****************[epoch: 22, global step: 22] eval development set based on eval_every=2***************
2022-10-17 14:59:12,402 - trainer - INFO -               precision    recall  f1-score   support

         0.0       0.00      0.00      0.00         2
         1.0       0.00      0.00      0.00         2
         2.0       0.40      1.00      0.57         2

    accuracy                           0.33         6
   macro avg       0.13      0.33      0.19         6
weighted avg       0.13      0.33      0.19         6

2022-10-17 14:59:12,403 - trainer - INFO - {
  "dev_loss": 1.000381588935852,
  "dev_accuracy": 0.3333333333333333,
  "dev_best_score_for_accuracy": 0.5
}
2022-10-17 14:59:12,403 - trainer - INFO -   no_improve_count: 5
2022-10-17 14:59:12,404 - trainer - INFO -   patience: 200
2022-10-17 14:59:12,405 - trainer - INFO -    Check 3 checkpoints already saved
2022-10-17 14:59:12,405 - trainer - INFO -    There are more than keep_ck_num as specified, then remove the oldest saved checkpoint
2022-10-17 14:59:12,406 - trainer - INFO -   Remove checkpoint tmp/mlp_tes1\ck_16
2022-10-17 14:59:12,407 - trainer - INFO -   Save checkpoint to tmp/mlp_tes1\ck_22
2022-10-17 14:59:12,411 - trainer - INFO - save model to path: tmp/mlp_tes1\ck_22
2022-10-17 14:59:12,412 - trainer - INFO - 
*****************[epoch: 22, global step: 23] eval training set at end of epoch***************
2022-10-17 14:59:12,421 - trainer - INFO -               precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.00      0.00      0.00         2
           2       0.33      1.00      0.50         2

    accuracy                           0.33         6
   macro avg       0.11      0.33      0.17         6
weighted avg       0.11      0.33      0.17         6

2022-10-17 14:59:12,422 - trainer - INFO - {
  "train_accuracy_score": 0.3333333333333333,
  "train_loss": 1.0662800073623657
}
2022-10-17 14:59:12,423 - trainer - INFO - start training epoch 23
2022-10-17 14:59:12,423 - trainer - INFO - training using device=cuda
2022-10-17 14:59:12,424 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:12,424 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:12,436 - trainer - INFO - 
*****************[epoch: 23, global step: 24] eval training set at end of epoch***************
2022-10-17 14:59:12,440 - trainer - INFO -               precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.00      0.00      0.00         2
           2       0.33      1.00      0.50         2

    accuracy                           0.33         6
   macro avg       0.11      0.33      0.17         6
weighted avg       0.11      0.33      0.17         6

2022-10-17 14:59:12,442 - trainer - INFO - {
  "train_accuracy_score": 0.3333333333333333,
  "train_loss": 1.0157660245895386
}
2022-10-17 14:59:12,443 - trainer - INFO - start training epoch 24
2022-10-17 14:59:12,444 - trainer - INFO - training using device=cuda
2022-10-17 14:59:12,444 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:12,445 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:12,454 - trainer - INFO - 
*****************[epoch: 24, global step: 24] eval training set based on eval_every=2***************
2022-10-17 14:59:12,458 - trainer - INFO -               precision    recall  f1-score   support

           0       0.33      1.00      0.50         2
           1       0.00      0.00      0.00         2
           2       0.00      0.00      0.00         2

    accuracy                           0.33         6
   macro avg       0.11      0.33      0.17         6
weighted avg       0.11      0.33      0.17         6

2022-10-17 14:59:12,459 - trainer - INFO - {
  "train_accuracy_score": 0.3333333333333333,
  "train_loss": 1.0364183187484741
}
2022-10-17 14:59:12,476 - trainer - INFO - 
*****************[epoch: 24, global step: 24] eval development set based on eval_every=2***************
2022-10-17 14:59:12,482 - trainer - INFO -               precision    recall  f1-score   support

         0.0       0.67      1.00      0.80         2
         1.0       0.00      0.00      0.00         2
         2.0       0.67      1.00      0.80         2

    accuracy                           0.67         6
   macro avg       0.44      0.67      0.53         6
weighted avg       0.44      0.67      0.53         6

2022-10-17 14:59:12,483 - trainer - INFO - {
  "dev_loss": 0.9401527047157288,
  "dev_accuracy": 0.6666666666666666,
  "dev_best_score_for_accuracy": 0.6666666666666666
}
2022-10-17 14:59:12,483 - trainer - INFO -    save the model with best score so far
2022-10-17 14:59:12,485 - trainer - INFO -    Check 3 checkpoints already saved
2022-10-17 14:59:12,485 - trainer - INFO -    There are more than keep_ck_num as specified, then remove the oldest saved checkpoint
2022-10-17 14:59:12,485 - trainer - INFO -   Remove checkpoint tmp/mlp_tes1\ck_18
2022-10-17 14:59:12,487 - trainer - INFO -   Save checkpoint to tmp/mlp_tes1
2022-10-17 14:59:12,490 - trainer - INFO - save model to path: tmp/mlp_tes1
2022-10-17 14:59:12,490 - trainer - INFO -   no_improve_count: 0
2022-10-17 14:59:12,491 - trainer - INFO -   patience: 200
2022-10-17 14:59:12,492 - trainer - INFO -    Check 2 checkpoints already saved
2022-10-17 14:59:12,492 - trainer - INFO -   Save checkpoint to tmp/mlp_tes1\ck_24
2022-10-17 14:59:12,496 - trainer - INFO - save model to path: tmp/mlp_tes1\ck_24
2022-10-17 14:59:12,497 - trainer - INFO - 
*****************[epoch: 24, global step: 25] eval training set at end of epoch***************
2022-10-17 14:59:12,501 - trainer - INFO -               precision    recall  f1-score   support

           0       0.33      1.00      0.50         2
           1       0.00      0.00      0.00         2
           2       0.00      0.00      0.00         2

    accuracy                           0.33         6
   macro avg       0.11      0.33      0.17         6
weighted avg       0.11      0.33      0.17         6

2022-10-17 14:59:12,502 - trainer - INFO - {
  "train_accuracy_score": 0.3333333333333333,
  "train_loss": 1.0570706129074097
}
2022-10-17 14:59:12,503 - trainer - INFO - start training epoch 25
2022-10-17 14:59:12,503 - trainer - INFO - training using device=cuda
2022-10-17 14:59:12,504 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:12,504 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:12,514 - trainer - INFO - 
*****************[epoch: 25, global step: 26] eval training set at end of epoch***************
2022-10-17 14:59:12,518 - trainer - INFO -               precision    recall  f1-score   support

           0       1.00      1.00      1.00         2
           1       0.00      0.00      0.00         2
           2       0.50      1.00      0.67         2

    accuracy                           0.67         6
   macro avg       0.50      0.67      0.56         6
weighted avg       0.50      0.67      0.56         6

2022-10-17 14:59:12,519 - trainer - INFO - {
  "train_accuracy_score": 0.6666666666666666,
  "train_loss": 0.9439880847930908
}
2022-10-17 14:59:12,520 - trainer - INFO - start training epoch 26
2022-10-17 14:59:12,521 - trainer - INFO - training using device=cuda
2022-10-17 14:59:12,521 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:12,522 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:12,532 - trainer - INFO - 
*****************[epoch: 26, global step: 26] eval training set based on eval_every=2***************
2022-10-17 14:59:12,537 - trainer - INFO -               precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.00      0.00      0.00         2
           2       0.33      1.00      0.50         2

    accuracy                           0.33         6
   macro avg       0.11      0.33      0.17         6
weighted avg       0.11      0.33      0.17         6

2022-10-17 14:59:12,539 - trainer - INFO - {
  "train_accuracy_score": 0.3333333333333333,
  "train_loss": 0.9707346856594086
}
2022-10-17 14:59:12,561 - trainer - INFO - 
*****************[epoch: 26, global step: 26] eval development set based on eval_every=2***************
2022-10-17 14:59:12,565 - trainer - INFO -               precision    recall  f1-score   support

         0.0       1.00      0.50      0.67         2
         1.0       0.00      0.00      0.00         2
         2.0       0.40      1.00      0.57         2

    accuracy                           0.50         6
   macro avg       0.47      0.50      0.41         6
weighted avg       0.47      0.50      0.41         6

2022-10-17 14:59:12,566 - trainer - INFO - {
  "dev_loss": 0.9361472129821777,
  "dev_accuracy": 0.5,
  "dev_best_score_for_accuracy": 0.6666666666666666
}
2022-10-17 14:59:12,567 - trainer - INFO -   no_improve_count: 1
2022-10-17 14:59:12,567 - trainer - INFO -   patience: 200
2022-10-17 14:59:12,569 - trainer - INFO -    Check 3 checkpoints already saved
2022-10-17 14:59:12,569 - trainer - INFO -    There are more than keep_ck_num as specified, then remove the oldest saved checkpoint
2022-10-17 14:59:12,570 - trainer - INFO -   Remove checkpoint tmp/mlp_tes1\ck_20
2022-10-17 14:59:12,572 - trainer - INFO -   Save checkpoint to tmp/mlp_tes1\ck_26
2022-10-17 14:59:12,577 - trainer - INFO - save model to path: tmp/mlp_tes1\ck_26
2022-10-17 14:59:12,577 - trainer - INFO - 
*****************[epoch: 26, global step: 27] eval training set at end of epoch***************
2022-10-17 14:59:12,582 - trainer - INFO -               precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.00      0.00      0.00         2
           2       0.33      1.00      0.50         2

    accuracy                           0.33         6
   macro avg       0.11      0.33      0.17         6
weighted avg       0.11      0.33      0.17         6

2022-10-17 14:59:12,583 - trainer - INFO - {
  "train_accuracy_score": 0.3333333333333333,
  "train_loss": 0.9974812865257263
}
2022-10-17 14:59:12,585 - trainer - INFO - start training epoch 27
2022-10-17 14:59:12,586 - trainer - INFO - training using device=cuda
2022-10-17 14:59:12,587 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:12,587 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:12,598 - trainer - INFO - 
*****************[epoch: 27, global step: 28] eval training set at end of epoch***************
2022-10-17 14:59:12,605 - trainer - INFO -               precision    recall  f1-score   support

           0       1.00      0.50      0.67         2
           1       0.00      0.00      0.00         2
           2       0.40      1.00      0.57         2

    accuracy                           0.50         6
   macro avg       0.47      0.50      0.41         6
weighted avg       0.47      0.50      0.41         6

2022-10-17 14:59:12,606 - trainer - INFO - {
  "train_accuracy_score": 0.5,
  "train_loss": 0.937701940536499
}
2022-10-17 14:59:12,607 - trainer - INFO - start training epoch 28
2022-10-17 14:59:12,607 - trainer - INFO - training using device=cuda
2022-10-17 14:59:12,607 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:12,608 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:12,620 - trainer - INFO - 
*****************[epoch: 28, global step: 28] eval training set based on eval_every=2***************
2022-10-17 14:59:12,623 - trainer - INFO -               precision    recall  f1-score   support

           0       0.50      1.00      0.67         2
           1       0.00      0.00      0.00         2
           2       1.00      1.00      1.00         2

    accuracy                           0.67         6
   macro avg       0.50      0.67      0.56         6
weighted avg       0.50      0.67      0.56         6

2022-10-17 14:59:12,624 - trainer - INFO - {
  "train_accuracy_score": 0.6666666666666666,
  "train_loss": 0.9305834472179413
}
2022-10-17 14:59:12,636 - trainer - INFO - 
*****************[epoch: 28, global step: 28] eval development set based on eval_every=2***************
2022-10-17 14:59:12,640 - trainer - INFO -               precision    recall  f1-score   support

         0.0       0.50      1.00      0.67         2
         1.0       0.00      0.00      0.00         2
         2.0       1.00      1.00      1.00         2

    accuracy                           0.67         6
   macro avg       0.50      0.67      0.56         6
weighted avg       0.50      0.67      0.56         6

2022-10-17 14:59:12,640 - trainer - INFO - {
  "dev_loss": 0.8948853015899658,
  "dev_accuracy": 0.6666666666666666,
  "dev_best_score_for_accuracy": 0.6666666666666666
}
2022-10-17 14:59:12,641 - trainer - INFO -   no_improve_count: 2
2022-10-17 14:59:12,642 - trainer - INFO -   patience: 200
2022-10-17 14:59:12,643 - trainer - INFO -    Check 3 checkpoints already saved
2022-10-17 14:59:12,643 - trainer - INFO -    There are more than keep_ck_num as specified, then remove the oldest saved checkpoint
2022-10-17 14:59:12,645 - trainer - INFO -   Remove checkpoint tmp/mlp_tes1\ck_22
2022-10-17 14:59:12,647 - trainer - INFO -   Save checkpoint to tmp/mlp_tes1\ck_28
2022-10-17 14:59:12,653 - trainer - INFO - save model to path: tmp/mlp_tes1\ck_28
2022-10-17 14:59:12,654 - trainer - INFO - 
*****************[epoch: 28, global step: 29] eval training set at end of epoch***************
2022-10-17 14:59:12,658 - trainer - INFO -               precision    recall  f1-score   support

           0       0.50      1.00      0.67         2
           1       0.00      0.00      0.00         2
           2       1.00      1.00      1.00         2

    accuracy                           0.67         6
   macro avg       0.50      0.67      0.56         6
weighted avg       0.50      0.67      0.56         6

2022-10-17 14:59:12,659 - trainer - INFO - {
  "train_accuracy_score": 0.6666666666666666,
  "train_loss": 0.9234649538993835
}
2022-10-17 14:59:12,661 - trainer - INFO - start training epoch 29
2022-10-17 14:59:12,662 - trainer - INFO - training using device=cuda
2022-10-17 14:59:12,663 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:12,663 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:12,673 - trainer - INFO - 
*****************[epoch: 29, global step: 30] eval training set at end of epoch***************
2022-10-17 14:59:12,677 - trainer - INFO -               precision    recall  f1-score   support

           0       0.50      1.00      0.67         2
           1       0.00      0.00      0.00         2
           2       1.00      1.00      1.00         2

    accuracy                           0.67         6
   macro avg       0.50      0.67      0.56         6
weighted avg       0.50      0.67      0.56         6

2022-10-17 14:59:12,678 - trainer - INFO - {
  "train_accuracy_score": 0.6666666666666666,
  "train_loss": 0.8990644812583923
}
2022-10-17 14:59:12,679 - trainer - INFO - start training epoch 30
2022-10-17 14:59:12,680 - trainer - INFO - training using device=cuda
2022-10-17 14:59:12,680 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:12,680 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:12,687 - trainer - INFO - 
*****************[epoch: 30, global step: 30] eval training set based on eval_every=2***************
2022-10-17 14:59:12,690 - trainer - INFO -               precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.00      0.00      0.00         2
           2       0.33      1.00      0.50         2

    accuracy                           0.33         6
   macro avg       0.11      0.33      0.17         6
weighted avg       0.11      0.33      0.17         6

2022-10-17 14:59:12,691 - trainer - INFO - {
  "train_accuracy_score": 0.3333333333333333,
  "train_loss": 0.9284469783306122
}
2022-10-17 14:59:12,709 - trainer - INFO - 
*****************[epoch: 30, global step: 30] eval development set based on eval_every=2***************
2022-10-17 14:59:12,714 - trainer - INFO -               precision    recall  f1-score   support

         0.0       1.00      0.50      0.67         2
         1.0       0.00      0.00      0.00         2
         2.0       0.40      1.00      0.57         2

    accuracy                           0.50         6
   macro avg       0.47      0.50      0.41         6
weighted avg       0.47      0.50      0.41         6

2022-10-17 14:59:12,715 - trainer - INFO - {
  "dev_loss": 0.8932308554649353,
  "dev_accuracy": 0.5,
  "dev_best_score_for_accuracy": 0.6666666666666666
}
2022-10-17 14:59:12,716 - trainer - INFO -   no_improve_count: 3
2022-10-17 14:59:12,717 - trainer - INFO -   patience: 200
2022-10-17 14:59:12,718 - trainer - INFO -    Check 3 checkpoints already saved
2022-10-17 14:59:12,718 - trainer - INFO -    There are more than keep_ck_num as specified, then remove the oldest saved checkpoint
2022-10-17 14:59:12,718 - trainer - INFO -   Remove checkpoint tmp/mlp_tes1\ck_24
2022-10-17 14:59:12,720 - trainer - INFO -   Save checkpoint to tmp/mlp_tes1\ck_30
2022-10-17 14:59:12,725 - trainer - INFO - save model to path: tmp/mlp_tes1\ck_30
2022-10-17 14:59:12,731 - trainer - INFO - 
*****************[epoch: 30, global step: 31] eval training set at end of epoch***************
2022-10-17 14:59:12,736 - trainer - INFO -               precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.00      0.00      0.00         2
           2       0.33      1.00      0.50         2

    accuracy                           0.33         6
   macro avg       0.11      0.33      0.17         6
weighted avg       0.11      0.33      0.17         6

2022-10-17 14:59:12,737 - trainer - INFO - {
  "train_accuracy_score": 0.3333333333333333,
  "train_loss": 0.957829475402832
}
2022-10-17 14:59:12,738 - trainer - INFO - start training epoch 31
2022-10-17 14:59:12,738 - trainer - INFO - training using device=cuda
2022-10-17 14:59:12,738 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:12,739 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:12,749 - trainer - INFO - 
*****************[epoch: 31, global step: 32] eval training set at end of epoch***************
2022-10-17 14:59:12,753 - trainer - INFO -               precision    recall  f1-score   support

           0       1.00      0.50      0.67         2
           1       0.00      0.00      0.00         2
           2       0.40      1.00      0.57         2

    accuracy                           0.50         6
   macro avg       0.47      0.50      0.41         6
weighted avg       0.47      0.50      0.41         6

2022-10-17 14:59:12,754 - trainer - INFO - {
  "train_accuracy_score": 0.5,
  "train_loss": 0.8891632556915283
}
2022-10-17 14:59:12,756 - trainer - INFO - start training epoch 32
2022-10-17 14:59:12,756 - trainer - INFO - training using device=cuda
2022-10-17 14:59:12,757 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:12,757 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:12,766 - trainer - INFO - 
*****************[epoch: 32, global step: 32] eval training set based on eval_every=2***************
2022-10-17 14:59:12,769 - trainer - INFO -               precision    recall  f1-score   support

           0       0.50      1.00      0.67         2
           1       0.00      0.00      0.00         2
           2       1.00      1.00      1.00         2

    accuracy                           0.67         6
   macro avg       0.50      0.67      0.56         6
weighted avg       0.50      0.67      0.56         6

2022-10-17 14:59:12,771 - trainer - INFO - {
  "train_accuracy_score": 0.6666666666666666,
  "train_loss": 0.8671789467334747
}
2022-10-17 14:59:12,782 - trainer - INFO - 
*****************[epoch: 32, global step: 32] eval development set based on eval_every=2***************
2022-10-17 14:59:12,785 - trainer - INFO -               precision    recall  f1-score   support

         0.0       0.50      1.00      0.67         2
         1.0       0.00      0.00      0.00         2
         2.0       1.00      1.00      1.00         2

    accuracy                           0.67         6
   macro avg       0.50      0.67      0.56         6
weighted avg       0.50      0.67      0.56         6

2022-10-17 14:59:12,786 - trainer - INFO - {
  "dev_loss": 0.8261206746101379,
  "dev_accuracy": 0.6666666666666666,
  "dev_best_score_for_accuracy": 0.6666666666666666
}
2022-10-17 14:59:12,787 - trainer - INFO -   no_improve_count: 4
2022-10-17 14:59:12,788 - trainer - INFO -   patience: 200
2022-10-17 14:59:12,789 - trainer - INFO -    Check 3 checkpoints already saved
2022-10-17 14:59:12,792 - trainer - INFO -    There are more than keep_ck_num as specified, then remove the oldest saved checkpoint
2022-10-17 14:59:12,793 - trainer - INFO -   Remove checkpoint tmp/mlp_tes1\ck_26
2022-10-17 14:59:12,795 - trainer - INFO -   Save checkpoint to tmp/mlp_tes1\ck_32
2022-10-17 14:59:12,799 - trainer - INFO - save model to path: tmp/mlp_tes1\ck_32
2022-10-17 14:59:12,799 - trainer - INFO - 
*****************[epoch: 32, global step: 33] eval training set at end of epoch***************
2022-10-17 14:59:12,804 - trainer - INFO -               precision    recall  f1-score   support

           0       0.50      1.00      0.67         2
           1       0.00      0.00      0.00         2
           2       1.00      1.00      1.00         2

    accuracy                           0.67         6
   macro avg       0.50      0.67      0.56         6
weighted avg       0.50      0.67      0.56         6

2022-10-17 14:59:12,805 - trainer - INFO - {
  "train_accuracy_score": 0.6666666666666666,
  "train_loss": 0.8451946377754211
}
2022-10-17 14:59:12,806 - trainer - INFO - start training epoch 33
2022-10-17 14:59:12,806 - trainer - INFO - training using device=cuda
2022-10-17 14:59:12,807 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:12,808 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:12,818 - trainer - INFO - 
*****************[epoch: 33, global step: 34] eval training set at end of epoch***************
2022-10-17 14:59:12,823 - trainer - INFO -               precision    recall  f1-score   support

           0       0.50      1.00      0.67         2
           1       0.00      0.00      0.00         2
           2       1.00      1.00      1.00         2

    accuracy                           0.67         6
   macro avg       0.50      0.67      0.56         6
weighted avg       0.50      0.67      0.56         6

2022-10-17 14:59:12,824 - trainer - INFO - {
  "train_accuracy_score": 0.6666666666666666,
  "train_loss": 0.8271016478538513
}
2022-10-17 14:59:12,825 - trainer - INFO - start training epoch 34
2022-10-17 14:59:12,826 - trainer - INFO - training using device=cuda
2022-10-17 14:59:12,828 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:12,829 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:12,838 - trainer - INFO - 
*****************[epoch: 34, global step: 34] eval training set based on eval_every=2***************
2022-10-17 14:59:12,842 - trainer - INFO -               precision    recall  f1-score   support

           0       1.00      0.50      0.67         2
           1       0.00      0.00      0.00         2
           2       0.50      1.00      0.67         2

    accuracy                           0.50         6
   macro avg       0.50      0.50      0.44         6
weighted avg       0.50      0.50      0.44         6

2022-10-17 14:59:12,844 - trainer - INFO - {
  "train_accuracy_score": 0.5,
  "train_loss": 0.8142596185207367
}
2022-10-17 14:59:12,857 - trainer - INFO - 
*****************[epoch: 34, global step: 34] eval development set based on eval_every=2***************
2022-10-17 14:59:12,860 - trainer - INFO -               precision    recall  f1-score   support

         0.0       1.00      0.50      0.67         2
         1.0       0.00      0.00      0.00         2
         2.0       0.50      1.00      0.67         2

    accuracy                           0.50         6
   macro avg       0.50      0.50      0.44         6
weighted avg       0.50      0.50      0.44         6

2022-10-17 14:59:12,860 - trainer - INFO - {
  "dev_loss": 0.827357828617096,
  "dev_accuracy": 0.5,
  "dev_best_score_for_accuracy": 0.6666666666666666
}
2022-10-17 14:59:12,861 - trainer - INFO -   no_improve_count: 5
2022-10-17 14:59:12,862 - trainer - INFO -   patience: 200
2022-10-17 14:59:12,862 - trainer - INFO -    Check 3 checkpoints already saved
2022-10-17 14:59:12,863 - trainer - INFO -    There are more than keep_ck_num as specified, then remove the oldest saved checkpoint
2022-10-17 14:59:12,863 - trainer - INFO -   Remove checkpoint tmp/mlp_tes1\ck_28
2022-10-17 14:59:12,865 - trainer - INFO -   Save checkpoint to tmp/mlp_tes1\ck_34
2022-10-17 14:59:12,870 - trainer - INFO - save model to path: tmp/mlp_tes1\ck_34
2022-10-17 14:59:12,871 - trainer - INFO - 
*****************[epoch: 34, global step: 35] eval training set at end of epoch***************
2022-10-17 14:59:12,874 - trainer - INFO -               precision    recall  f1-score   support

           0       1.00      0.50      0.67         2
           1       0.00      0.00      0.00         2
           2       0.50      1.00      0.67         2

    accuracy                           0.50         6
   macro avg       0.50      0.50      0.44         6
weighted avg       0.50      0.50      0.44         6

2022-10-17 14:59:12,875 - trainer - INFO - {
  "train_accuracy_score": 0.5,
  "train_loss": 0.8014175891876221
}
2022-10-17 14:59:12,876 - trainer - INFO - start training epoch 35
2022-10-17 14:59:12,877 - trainer - INFO - training using device=cuda
2022-10-17 14:59:12,877 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:12,877 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:12,884 - trainer - INFO - 
*****************[epoch: 35, global step: 36] eval training set at end of epoch***************
2022-10-17 14:59:12,887 - trainer - INFO -               precision    recall  f1-score   support

           0       1.00      0.50      0.67         2
           1       0.00      0.00      0.00         2
           2       0.50      1.00      0.67         2

    accuracy                           0.50         6
   macro avg       0.50      0.50      0.44         6
weighted avg       0.50      0.50      0.44         6

2022-10-17 14:59:12,888 - trainer - INFO - {
  "train_accuracy_score": 0.5,
  "train_loss": 0.8090758919715881
}
2022-10-17 14:59:12,888 - trainer - INFO - start training epoch 36
2022-10-17 14:59:12,888 - trainer - INFO - training using device=cuda
2022-10-17 14:59:12,888 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:12,889 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:12,895 - trainer - INFO - 
*****************[epoch: 36, global step: 36] eval training set based on eval_every=2***************
2022-10-17 14:59:12,897 - trainer - INFO -               precision    recall  f1-score   support

           0       0.67      1.00      0.80         2
           1       1.00      0.50      0.67         2
           2       1.00      1.00      1.00         2

    accuracy                           0.83         6
   macro avg       0.89      0.83      0.82         6
weighted avg       0.89      0.83      0.82         6

2022-10-17 14:59:12,898 - trainer - INFO - {
  "train_accuracy_score": 0.8333333333333334,
  "train_loss": 0.7603645920753479
}
2022-10-17 14:59:12,906 - trainer - INFO - 
*****************[epoch: 36, global step: 36] eval development set based on eval_every=2***************
2022-10-17 14:59:12,909 - trainer - INFO -               precision    recall  f1-score   support

         0.0       0.50      1.00      0.67         2
         1.0       0.00      0.00      0.00         2
         2.0       1.00      0.50      0.67         2

    accuracy                           0.50         6
   macro avg       0.50      0.50      0.44         6
weighted avg       0.50      0.50      0.44         6

2022-10-17 14:59:12,910 - trainer - INFO - {
  "dev_loss": 0.7807175517082214,
  "dev_accuracy": 0.5,
  "dev_best_score_for_accuracy": 0.6666666666666666
}
2022-10-17 14:59:12,911 - trainer - INFO -   no_improve_count: 6
2022-10-17 14:59:12,911 - trainer - INFO -   patience: 200
2022-10-17 14:59:12,916 - trainer - INFO -    Check 3 checkpoints already saved
2022-10-17 14:59:12,916 - trainer - INFO -    There are more than keep_ck_num as specified, then remove the oldest saved checkpoint
2022-10-17 14:59:12,916 - trainer - INFO -   Remove checkpoint tmp/mlp_tes1\ck_30
2022-10-17 14:59:12,918 - trainer - INFO -   Save checkpoint to tmp/mlp_tes1\ck_36
2022-10-17 14:59:12,928 - trainer - INFO - save model to path: tmp/mlp_tes1\ck_36
2022-10-17 14:59:12,929 - trainer - INFO - 
*****************[epoch: 36, global step: 37] eval training set at end of epoch***************
2022-10-17 14:59:12,934 - trainer - INFO -               precision    recall  f1-score   support

           0       0.67      1.00      0.80         2
           1       1.00      0.50      0.67         2
           2       1.00      1.00      1.00         2

    accuracy                           0.83         6
   macro avg       0.89      0.83      0.82         6
weighted avg       0.89      0.83      0.82         6

2022-10-17 14:59:12,936 - trainer - INFO - {
  "train_accuracy_score": 0.8333333333333334,
  "train_loss": 0.7116532921791077
}
2022-10-17 14:59:12,937 - trainer - INFO - start training epoch 37
2022-10-17 14:59:12,937 - trainer - INFO - training using device=cuda
2022-10-17 14:59:12,937 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:12,937 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:12,947 - trainer - INFO - 
*****************[epoch: 37, global step: 38] eval training set at end of epoch***************
2022-10-17 14:59:12,949 - trainer - INFO -               precision    recall  f1-score   support

           0       0.50      1.00      0.67         2
           1       0.00      0.00      0.00         2
           2       1.00      0.50      0.67         2

    accuracy                           0.50         6
   macro avg       0.50      0.50      0.44         6
weighted avg       0.50      0.50      0.44         6

2022-10-17 14:59:12,950 - trainer - INFO - {
  "train_accuracy_score": 0.5,
  "train_loss": 0.773291289806366
}
2022-10-17 14:59:12,951 - trainer - INFO - start training epoch 38
2022-10-17 14:59:12,951 - trainer - INFO - training using device=cuda
2022-10-17 14:59:12,951 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:12,952 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:12,957 - trainer - INFO - 
*****************[epoch: 38, global step: 38] eval training set based on eval_every=2***************
2022-10-17 14:59:12,960 - trainer - INFO -               precision    recall  f1-score   support

           0       1.00      1.00      1.00         2
           1       1.00      0.50      0.67         2
           2       0.67      1.00      0.80         2

    accuracy                           0.83         6
   macro avg       0.89      0.83      0.82         6
weighted avg       0.89      0.83      0.82         6

2022-10-17 14:59:12,961 - trainer - INFO - {
  "train_accuracy_score": 0.8333333333333334,
  "train_loss": 0.719531923532486
}
2022-10-17 14:59:12,970 - trainer - INFO - 
*****************[epoch: 38, global step: 38] eval development set based on eval_every=2***************
2022-10-17 14:59:12,972 - trainer - INFO -               precision    recall  f1-score   support

         0.0       1.00      0.50      0.67         2
         1.0       0.50      0.50      0.50         2
         2.0       0.67      1.00      0.80         2

    accuracy                           0.67         6
   macro avg       0.72      0.67      0.66         6
weighted avg       0.72      0.67      0.66         6

2022-10-17 14:59:12,974 - trainer - INFO - {
  "dev_loss": 0.7148022651672363,
  "dev_accuracy": 0.6666666666666666,
  "dev_best_score_for_accuracy": 0.6666666666666666
}
2022-10-17 14:59:12,975 - trainer - INFO -   no_improve_count: 7
2022-10-17 14:59:12,978 - trainer - INFO -   patience: 200
2022-10-17 14:59:12,979 - trainer - INFO -    Check 3 checkpoints already saved
2022-10-17 14:59:12,979 - trainer - INFO -    There are more than keep_ck_num as specified, then remove the oldest saved checkpoint
2022-10-17 14:59:12,979 - trainer - INFO -   Remove checkpoint tmp/mlp_tes1\ck_32
2022-10-17 14:59:12,980 - trainer - INFO -   Save checkpoint to tmp/mlp_tes1\ck_38
2022-10-17 14:59:12,984 - trainer - INFO - save model to path: tmp/mlp_tes1\ck_38
2022-10-17 14:59:12,985 - trainer - INFO - 
*****************[epoch: 38, global step: 39] eval training set at end of epoch***************
2022-10-17 14:59:12,987 - trainer - INFO -               precision    recall  f1-score   support

           0       1.00      1.00      1.00         2
           1       1.00      0.50      0.67         2
           2       0.67      1.00      0.80         2

    accuracy                           0.83         6
   macro avg       0.89      0.83      0.82         6
weighted avg       0.89      0.83      0.82         6

2022-10-17 14:59:12,988 - trainer - INFO - {
  "train_accuracy_score": 0.8333333333333334,
  "train_loss": 0.665772557258606
}
2022-10-17 14:59:12,989 - trainer - INFO - start training epoch 39
2022-10-17 14:59:12,989 - trainer - INFO - training using device=cuda
2022-10-17 14:59:12,989 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:12,990 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:12,997 - trainer - INFO - 
*****************[epoch: 39, global step: 40] eval training set at end of epoch***************
2022-10-17 14:59:12,999 - trainer - INFO -               precision    recall  f1-score   support

           0       1.00      0.50      0.67         2
           1       0.00      0.00      0.00         2
           2       0.50      1.00      0.67         2

    accuracy                           0.50         6
   macro avg       0.50      0.50      0.44         6
weighted avg       0.50      0.50      0.44         6

2022-10-17 14:59:13,000 - trainer - INFO - {
  "train_accuracy_score": 0.5,
  "train_loss": 0.7095906138420105
}
2022-10-17 14:59:13,000 - trainer - INFO - start training epoch 40
2022-10-17 14:59:13,000 - trainer - INFO - training using device=cuda
2022-10-17 14:59:13,000 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:13,001 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:13,007 - trainer - INFO - 
*****************[epoch: 40, global step: 40] eval training set based on eval_every=2***************
2022-10-17 14:59:13,010 - trainer - INFO -               precision    recall  f1-score   support

           0       0.67      1.00      0.80         2
           1       1.00      0.50      0.67         2
           2       1.00      1.00      1.00         2

    accuracy                           0.83         6
   macro avg       0.89      0.83      0.82         6
weighted avg       0.89      0.83      0.82         6

2022-10-17 14:59:13,011 - trainer - INFO - {
  "train_accuracy_score": 0.8333333333333334,
  "train_loss": 0.6596061587333679
}
2022-10-17 14:59:13,022 - trainer - INFO - 
*****************[epoch: 40, global step: 40] eval development set based on eval_every=2***************
2022-10-17 14:59:13,026 - trainer - INFO -               precision    recall  f1-score   support

         0.0       0.67      1.00      0.80         2
         1.0       0.50      0.50      0.50         2
         2.0       1.00      0.50      0.67         2

    accuracy                           0.67         6
   macro avg       0.72      0.67      0.66         6
weighted avg       0.72      0.67      0.66         6

2022-10-17 14:59:13,026 - trainer - INFO - {
  "dev_loss": 0.6349942684173584,
  "dev_accuracy": 0.6666666666666666,
  "dev_best_score_for_accuracy": 0.6666666666666666
}
2022-10-17 14:59:13,027 - trainer - INFO -   no_improve_count: 8
2022-10-17 14:59:13,028 - trainer - INFO -   patience: 200
2022-10-17 14:59:13,028 - trainer - INFO -    Check 3 checkpoints already saved
2022-10-17 14:59:13,029 - trainer - INFO -    There are more than keep_ck_num as specified, then remove the oldest saved checkpoint
2022-10-17 14:59:13,029 - trainer - INFO -   Remove checkpoint tmp/mlp_tes1\ck_34
2022-10-17 14:59:13,030 - trainer - INFO -   Save checkpoint to tmp/mlp_tes1\ck_40
2022-10-17 14:59:13,035 - trainer - INFO - save model to path: tmp/mlp_tes1\ck_40
2022-10-17 14:59:13,036 - trainer - INFO - 
*****************[epoch: 40, global step: 41] eval training set at end of epoch***************
2022-10-17 14:59:13,039 - trainer - INFO -               precision    recall  f1-score   support

           0       0.67      1.00      0.80         2
           1       1.00      0.50      0.67         2
           2       1.00      1.00      1.00         2

    accuracy                           0.83         6
   macro avg       0.89      0.83      0.82         6
weighted avg       0.89      0.83      0.82         6

2022-10-17 14:59:13,040 - trainer - INFO - {
  "train_accuracy_score": 0.8333333333333334,
  "train_loss": 0.6096217036247253
}
2022-10-17 14:59:13,041 - trainer - INFO - start training epoch 41
2022-10-17 14:59:13,041 - trainer - INFO - training using device=cuda
2022-10-17 14:59:13,041 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:13,041 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:13,049 - trainer - INFO - 
*****************[epoch: 41, global step: 42] eval training set at end of epoch***************
2022-10-17 14:59:13,052 - trainer - INFO -               precision    recall  f1-score   support

           0       0.67      1.00      0.80         2
           1       1.00      0.50      0.67         2
           2       1.00      1.00      1.00         2

    accuracy                           0.83         6
   macro avg       0.89      0.83      0.82         6
weighted avg       0.89      0.83      0.82         6

2022-10-17 14:59:13,052 - trainer - INFO - {
  "train_accuracy_score": 0.8333333333333334,
  "train_loss": 0.6394538283348083
}
2022-10-17 14:59:13,053 - trainer - INFO - start training epoch 42
2022-10-17 14:59:13,053 - trainer - INFO - training using device=cuda
2022-10-17 14:59:13,053 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:13,053 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:13,060 - trainer - INFO - 
*****************[epoch: 42, global step: 42] eval training set based on eval_every=2***************
2022-10-17 14:59:13,063 - trainer - INFO -               precision    recall  f1-score   support

           0       1.00      1.00      1.00         2
           1       1.00      0.50      0.67         2
           2       0.67      1.00      0.80         2

    accuracy                           0.83         6
   macro avg       0.89      0.83      0.82         6
weighted avg       0.89      0.83      0.82         6

2022-10-17 14:59:13,064 - trainer - INFO - {
  "train_accuracy_score": 0.8333333333333334,
  "train_loss": 0.603258341550827
}
2022-10-17 14:59:13,074 - trainer - INFO - 
*****************[epoch: 42, global step: 42] eval development set based on eval_every=2***************
2022-10-17 14:59:13,077 - trainer - INFO -               precision    recall  f1-score   support

         0.0       1.00      1.00      1.00         2
         1.0       1.00      0.50      0.67         2
         2.0       0.67      1.00      0.80         2

    accuracy                           0.83         6
   macro avg       0.89      0.83      0.82         6
weighted avg       0.89      0.83      0.82         6

2022-10-17 14:59:13,077 - trainer - INFO - {
  "dev_loss": 0.5388504266738892,
  "dev_accuracy": 0.8333333333333334,
  "dev_best_score_for_accuracy": 0.8333333333333334
}
2022-10-17 14:59:13,078 - trainer - INFO -    save the model with best score so far
2022-10-17 14:59:13,079 - trainer - INFO -    Check 3 checkpoints already saved
2022-10-17 14:59:13,079 - trainer - INFO -    There are more than keep_ck_num as specified, then remove the oldest saved checkpoint
2022-10-17 14:59:13,079 - trainer - INFO -   Remove checkpoint tmp/mlp_tes1\ck_36
2022-10-17 14:59:13,081 - trainer - INFO -   Save checkpoint to tmp/mlp_tes1
2022-10-17 14:59:13,085 - trainer - INFO - save model to path: tmp/mlp_tes1
2022-10-17 14:59:13,086 - trainer - INFO -   no_improve_count: 0
2022-10-17 14:59:13,086 - trainer - INFO -   patience: 200
2022-10-17 14:59:13,087 - trainer - INFO -    Check 2 checkpoints already saved
2022-10-17 14:59:13,087 - trainer - INFO -   Save checkpoint to tmp/mlp_tes1\ck_42
2022-10-17 14:59:13,091 - trainer - INFO - save model to path: tmp/mlp_tes1\ck_42
2022-10-17 14:59:13,092 - trainer - INFO - 
*****************[epoch: 42, global step: 43] eval training set at end of epoch***************
2022-10-17 14:59:13,095 - trainer - INFO -               precision    recall  f1-score   support

           0       1.00      1.00      1.00         2
           1       1.00      0.50      0.67         2
           2       0.67      1.00      0.80         2

    accuracy                           0.83         6
   macro avg       0.89      0.83      0.82         6
weighted avg       0.89      0.83      0.82         6

2022-10-17 14:59:13,096 - trainer - INFO - {
  "train_accuracy_score": 0.8333333333333334,
  "train_loss": 0.5670628547668457
}
2022-10-17 14:59:13,097 - trainer - INFO - start training epoch 43
2022-10-17 14:59:13,097 - trainer - INFO - training using device=cuda
2022-10-17 14:59:13,098 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:13,098 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:13,105 - trainer - INFO - 
*****************[epoch: 43, global step: 44] eval training set at end of epoch***************
2022-10-17 14:59:13,107 - trainer - INFO -               precision    recall  f1-score   support

           0       1.00      1.00      1.00         2
           1       1.00      0.50      0.67         2
           2       0.67      1.00      0.80         2

    accuracy                           0.83         6
   macro avg       0.89      0.83      0.82         6
weighted avg       0.89      0.83      0.82         6

2022-10-17 14:59:13,108 - trainer - INFO - {
  "train_accuracy_score": 0.8333333333333334,
  "train_loss": 0.5450795292854309
}
2022-10-17 14:59:13,108 - trainer - INFO - start training epoch 44
2022-10-17 14:59:13,108 - trainer - INFO - training using device=cuda
2022-10-17 14:59:13,108 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:13,109 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:13,115 - trainer - INFO - 
*****************[epoch: 44, global step: 44] eval training set based on eval_every=2***************
2022-10-17 14:59:13,118 - trainer - INFO -               precision    recall  f1-score   support

           0       0.67      1.00      0.80         2
           1       1.00      0.50      0.67         2
           2       1.00      1.00      1.00         2

    accuracy                           0.83         6
   macro avg       0.89      0.83      0.82         6
weighted avg       0.89      0.83      0.82         6

2022-10-17 14:59:13,119 - trainer - INFO - {
  "train_accuracy_score": 0.8333333333333334,
  "train_loss": 0.5516096651554108
}
2022-10-17 14:59:13,129 - trainer - INFO - 
*****************[epoch: 44, global step: 44] eval development set based on eval_every=2***************
2022-10-17 14:59:13,131 - trainer - INFO -               precision    recall  f1-score   support

         0.0       1.00      1.00      1.00         2
         1.0       1.00      1.00      1.00         2
         2.0       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

2022-10-17 14:59:13,132 - trainer - INFO - {
  "dev_loss": 0.48580190539360046,
  "dev_accuracy": 1.0,
  "dev_best_score_for_accuracy": 1.0
}
2022-10-17 14:59:13,132 - trainer - INFO -    save the model with best score so far
2022-10-17 14:59:13,133 - trainer - INFO -    Check 3 checkpoints already saved
2022-10-17 14:59:13,134 - trainer - INFO -    There are more than keep_ck_num as specified, then remove the oldest saved checkpoint
2022-10-17 14:59:13,134 - trainer - INFO -   Remove checkpoint tmp/mlp_tes1\ck_38
2022-10-17 14:59:13,135 - trainer - INFO -   Save checkpoint to tmp/mlp_tes1
2022-10-17 14:59:13,138 - trainer - INFO - save model to path: tmp/mlp_tes1
2022-10-17 14:59:13,139 - trainer - INFO -   no_improve_count: 0
2022-10-17 14:59:13,139 - trainer - INFO -   patience: 200
2022-10-17 14:59:13,139 - trainer - INFO -    Check 2 checkpoints already saved
2022-10-17 14:59:13,140 - trainer - INFO -   Save checkpoint to tmp/mlp_tes1\ck_44
2022-10-17 14:59:13,144 - trainer - INFO - save model to path: tmp/mlp_tes1\ck_44
2022-10-17 14:59:13,145 - trainer - INFO - 
*****************[epoch: 44, global step: 45] eval training set at end of epoch***************
2022-10-17 14:59:13,149 - trainer - INFO -               precision    recall  f1-score   support

           0       0.67      1.00      0.80         2
           1       1.00      0.50      0.67         2
           2       1.00      1.00      1.00         2

    accuracy                           0.83         6
   macro avg       0.89      0.83      0.82         6
weighted avg       0.89      0.83      0.82         6

2022-10-17 14:59:13,150 - trainer - INFO - {
  "train_accuracy_score": 0.8333333333333334,
  "train_loss": 0.5581398010253906
}
2022-10-17 14:59:13,151 - trainer - INFO - start training epoch 45
2022-10-17 14:59:13,151 - trainer - INFO - training using device=cuda
2022-10-17 14:59:13,151 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:13,151 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:13,159 - trainer - INFO - 
*****************[epoch: 45, global step: 46] eval training set at end of epoch***************
2022-10-17 14:59:13,162 - trainer - INFO -               precision    recall  f1-score   support

           0       1.00      1.00      1.00         2
           1       1.00      1.00      1.00         2
           2       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

2022-10-17 14:59:13,162 - trainer - INFO - {
  "train_accuracy_score": 1.0,
  "train_loss": 0.4744448661804199
}
2022-10-17 14:59:13,163 - trainer - INFO - start training epoch 46
2022-10-17 14:59:13,163 - trainer - INFO - training using device=cuda
2022-10-17 14:59:13,163 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:13,163 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:13,170 - trainer - INFO - 
*****************[epoch: 46, global step: 46] eval training set based on eval_every=2***************
2022-10-17 14:59:13,173 - trainer - INFO -               precision    recall  f1-score   support

           0       1.00      1.00      1.00         2
           1       1.00      0.50      0.67         2
           2       0.67      1.00      0.80         2

    accuracy                           0.83         6
   macro avg       0.89      0.83      0.82         6
weighted avg       0.89      0.83      0.82         6

2022-10-17 14:59:13,174 - trainer - INFO - {
  "train_accuracy_score": 0.8333333333333334,
  "train_loss": 0.502155214548111
}
2022-10-17 14:59:13,189 - trainer - INFO - 
*****************[epoch: 46, global step: 46] eval development set based on eval_every=2***************
2022-10-17 14:59:13,195 - trainer - INFO -               precision    recall  f1-score   support

         0.0       0.67      1.00      0.80         2
         1.0       1.00      0.50      0.67         2
         2.0       1.00      1.00      1.00         2

    accuracy                           0.83         6
   macro avg       0.89      0.83      0.82         6
weighted avg       0.89      0.83      0.82         6

2022-10-17 14:59:13,196 - trainer - INFO - {
  "dev_loss": 0.4819631576538086,
  "dev_accuracy": 0.8333333333333334,
  "dev_best_score_for_accuracy": 1.0
}
2022-10-17 14:59:13,196 - trainer - INFO -   no_improve_count: 1
2022-10-17 14:59:13,197 - trainer - INFO -   patience: 200
2022-10-17 14:59:13,198 - trainer - INFO -    Check 3 checkpoints already saved
2022-10-17 14:59:13,198 - trainer - INFO -    There are more than keep_ck_num as specified, then remove the oldest saved checkpoint
2022-10-17 14:59:13,198 - trainer - INFO -   Remove checkpoint tmp/mlp_tes1\ck_40
2022-10-17 14:59:13,200 - trainer - INFO -   Save checkpoint to tmp/mlp_tes1\ck_46
2022-10-17 14:59:13,204 - trainer - INFO - save model to path: tmp/mlp_tes1\ck_46
2022-10-17 14:59:13,205 - trainer - INFO - 
*****************[epoch: 46, global step: 47] eval training set at end of epoch***************
2022-10-17 14:59:13,209 - trainer - INFO -               precision    recall  f1-score   support

           0       1.00      1.00      1.00         2
           1       1.00      0.50      0.67         2
           2       0.67      1.00      0.80         2

    accuracy                           0.83         6
   macro avg       0.89      0.83      0.82         6
weighted avg       0.89      0.83      0.82         6

2022-10-17 14:59:13,210 - trainer - INFO - {
  "train_accuracy_score": 0.8333333333333334,
  "train_loss": 0.529865562915802
}
2022-10-17 14:59:13,211 - trainer - INFO - start training epoch 47
2022-10-17 14:59:13,211 - trainer - INFO - training using device=cuda
2022-10-17 14:59:13,211 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:13,212 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:13,218 - trainer - INFO - 
*****************[epoch: 47, global step: 48] eval training set at end of epoch***************
2022-10-17 14:59:13,221 - trainer - INFO -               precision    recall  f1-score   support

           0       0.67      1.00      0.80         2
           1       1.00      0.50      0.67         2
           2       1.00      1.00      1.00         2

    accuracy                           0.83         6
   macro avg       0.89      0.83      0.82         6
weighted avg       0.89      0.83      0.82         6

2022-10-17 14:59:13,224 - trainer - INFO - {
  "train_accuracy_score": 0.8333333333333334,
  "train_loss": 0.4743777811527252
}
2022-10-17 14:59:13,224 - trainer - INFO - start training epoch 48
2022-10-17 14:59:13,225 - trainer - INFO - training using device=cuda
2022-10-17 14:59:13,225 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:13,225 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:13,232 - trainer - INFO - 
*****************[epoch: 48, global step: 48] eval training set based on eval_every=2***************
2022-10-17 14:59:13,235 - trainer - INFO -               precision    recall  f1-score   support

           0       1.00      1.00      1.00         2
           1       1.00      1.00      1.00         2
           2       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

2022-10-17 14:59:13,236 - trainer - INFO - {
  "train_accuracy_score": 1.0,
  "train_loss": 0.44424334168434143
}
2022-10-17 14:59:13,245 - trainer - INFO - 
*****************[epoch: 48, global step: 48] eval development set based on eval_every=2***************
2022-10-17 14:59:13,248 - trainer - INFO -               precision    recall  f1-score   support

         0.0       1.00      1.00      1.00         2
         1.0       1.00      0.50      0.67         2
         2.0       0.67      1.00      0.80         2

    accuracy                           0.83         6
   macro avg       0.89      0.83      0.82         6
weighted avg       0.89      0.83      0.82         6

2022-10-17 14:59:13,249 - trainer - INFO - {
  "dev_loss": 0.47260692715644836,
  "dev_accuracy": 0.8333333333333334,
  "dev_best_score_for_accuracy": 1.0
}
2022-10-17 14:59:13,249 - trainer - INFO -   no_improve_count: 2
2022-10-17 14:59:13,249 - trainer - INFO -   patience: 200
2022-10-17 14:59:13,251 - trainer - INFO -    Check 3 checkpoints already saved
2022-10-17 14:59:13,251 - trainer - INFO -    There are more than keep_ck_num as specified, then remove the oldest saved checkpoint
2022-10-17 14:59:13,253 - trainer - INFO -   Remove checkpoint tmp/mlp_tes1\ck_42
2022-10-17 14:59:13,254 - trainer - INFO -   Save checkpoint to tmp/mlp_tes1\ck_48
2022-10-17 14:59:13,260 - trainer - INFO - save model to path: tmp/mlp_tes1\ck_48
2022-10-17 14:59:13,261 - trainer - INFO - 
*****************[epoch: 48, global step: 49] eval training set at end of epoch***************
2022-10-17 14:59:13,264 - trainer - INFO -               precision    recall  f1-score   support

           0       1.00      1.00      1.00         2
           1       1.00      1.00      1.00         2
           2       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

2022-10-17 14:59:13,264 - trainer - INFO - {
  "train_accuracy_score": 1.0,
  "train_loss": 0.41410890221595764
}
2022-10-17 14:59:13,265 - trainer - INFO - start training epoch 49
2022-10-17 14:59:13,265 - trainer - INFO - training using device=cuda
2022-10-17 14:59:13,265 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:13,265 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:13,273 - trainer - INFO - 
*****************[epoch: 49, global step: 50] eval training set at end of epoch***************
2022-10-17 14:59:13,275 - trainer - INFO -               precision    recall  f1-score   support

           0       1.00      0.50      0.67         2
           1       0.50      0.50      0.50         2
           2       0.67      1.00      0.80         2

    accuracy                           0.67         6
   macro avg       0.72      0.67      0.66         6
weighted avg       0.72      0.67      0.66         6

2022-10-17 14:59:13,276 - trainer - INFO - {
  "train_accuracy_score": 0.6666666666666666,
  "train_loss": 0.47260603308677673
}
2022-10-17 14:59:13,276 - trainer - INFO - start training epoch 50
2022-10-17 14:59:13,276 - trainer - INFO - training using device=cuda
2022-10-17 14:59:13,277 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:13,277 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:13,285 - trainer - INFO - 
*****************[epoch: 50, global step: 50] eval training set based on eval_every=2***************
2022-10-17 14:59:13,290 - trainer - INFO -               precision    recall  f1-score   support

           0       0.67      1.00      0.80         2
           1       1.00      0.50      0.67         2
           2       1.00      1.00      1.00         2

    accuracy                           0.83         6
   macro avg       0.89      0.83      0.82         6
weighted avg       0.89      0.83      0.82         6

2022-10-17 14:59:13,290 - trainer - INFO - {
  "train_accuracy_score": 0.8333333333333334,
  "train_loss": 0.439639076590538
}
2022-10-17 14:59:13,301 - trainer - INFO - 
*****************[epoch: 50, global step: 50] eval development set based on eval_every=2***************
2022-10-17 14:59:13,304 - trainer - INFO -               precision    recall  f1-score   support

         0.0       1.00      1.00      1.00         2
         1.0       1.00      1.00      1.00         2
         2.0       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

2022-10-17 14:59:13,305 - trainer - INFO - {
  "dev_loss": 0.3383929431438446,
  "dev_accuracy": 1.0,
  "dev_best_score_for_accuracy": 1.0
}
2022-10-17 14:59:13,305 - trainer - INFO -   no_improve_count: 3
2022-10-17 14:59:13,306 - trainer - INFO -   patience: 200
2022-10-17 14:59:13,306 - trainer - INFO -    Check 3 checkpoints already saved
2022-10-17 14:59:13,307 - trainer - INFO -    There are more than keep_ck_num as specified, then remove the oldest saved checkpoint
2022-10-17 14:59:13,307 - trainer - INFO -   Remove checkpoint tmp/mlp_tes1\ck_44
2022-10-17 14:59:13,308 - trainer - INFO -   Save checkpoint to tmp/mlp_tes1\ck_50
2022-10-17 14:59:13,312 - trainer - INFO - save model to path: tmp/mlp_tes1\ck_50
2022-10-17 14:59:13,313 - trainer - INFO - 
*****************[epoch: 50, global step: 51] eval training set at end of epoch***************
2022-10-17 14:59:13,316 - trainer - INFO -               precision    recall  f1-score   support

           0       0.67      1.00      0.80         2
           1       1.00      0.50      0.67         2
           2       1.00      1.00      1.00         2

    accuracy                           0.83         6
   macro avg       0.89      0.83      0.82         6
weighted avg       0.89      0.83      0.82         6

2022-10-17 14:59:13,317 - trainer - INFO - {
  "train_accuracy_score": 0.8333333333333334,
  "train_loss": 0.4066721200942993
}
2022-10-17 14:59:13,318 - trainer - INFO - start training epoch 51
2022-10-17 14:59:13,318 - trainer - INFO - training using device=cuda
2022-10-17 14:59:13,318 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:13,319 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:13,326 - trainer - INFO - 
*****************[epoch: 51, global step: 52] eval training set at end of epoch***************
2022-10-17 14:59:13,329 - trainer - INFO -               precision    recall  f1-score   support

           0       1.00      1.00      1.00         2
           1       1.00      1.00      1.00         2
           2       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

2022-10-17 14:59:13,330 - trainer - INFO - {
  "train_accuracy_score": 1.0,
  "train_loss": 0.3440515995025635
}
2022-10-17 14:59:13,331 - trainer - INFO - start training epoch 52
2022-10-17 14:59:13,331 - trainer - INFO - training using device=cuda
2022-10-17 14:59:13,331 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:13,331 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:13,337 - trainer - INFO - 
*****************[epoch: 52, global step: 52] eval training set based on eval_every=2***************
2022-10-17 14:59:13,340 - trainer - INFO -               precision    recall  f1-score   support

           0       1.00      0.50      0.67         2
           1       0.50      0.50      0.50         2
           2       0.67      1.00      0.80         2

    accuracy                           0.67         6
   macro avg       0.72      0.67      0.66         6
weighted avg       0.72      0.67      0.66         6

2022-10-17 14:59:13,340 - trainer - INFO - {
  "train_accuracy_score": 0.6666666666666666,
  "train_loss": 0.37423793971538544
}
2022-10-17 14:59:13,352 - trainer - INFO - 
*****************[epoch: 52, global step: 52] eval development set based on eval_every=2***************
2022-10-17 14:59:13,354 - trainer - INFO -               precision    recall  f1-score   support

         0.0       0.67      1.00      0.80         2
         1.0       0.50      0.50      0.50         2
         2.0       1.00      0.50      0.67         2

    accuracy                           0.67         6
   macro avg       0.72      0.67      0.66         6
weighted avg       0.72      0.67      0.66         6

2022-10-17 14:59:13,355 - trainer - INFO - {
  "dev_loss": 0.3809002935886383,
  "dev_accuracy": 0.6666666666666666,
  "dev_best_score_for_accuracy": 1.0
}
2022-10-17 14:59:13,356 - trainer - INFO -   no_improve_count: 4
2022-10-17 14:59:13,356 - trainer - INFO -   patience: 200
2022-10-17 14:59:13,357 - trainer - INFO -    Check 3 checkpoints already saved
2022-10-17 14:59:13,358 - trainer - INFO -    There are more than keep_ck_num as specified, then remove the oldest saved checkpoint
2022-10-17 14:59:13,358 - trainer - INFO -   Remove checkpoint tmp/mlp_tes1\ck_46
2022-10-17 14:59:13,359 - trainer - INFO -   Save checkpoint to tmp/mlp_tes1\ck_52
2022-10-17 14:59:13,363 - trainer - INFO - save model to path: tmp/mlp_tes1\ck_52
2022-10-17 14:59:13,364 - trainer - INFO - 
*****************[epoch: 52, global step: 53] eval training set at end of epoch***************
2022-10-17 14:59:13,366 - trainer - INFO -               precision    recall  f1-score   support

           0       1.00      0.50      0.67         2
           1       0.50      0.50      0.50         2
           2       0.67      1.00      0.80         2

    accuracy                           0.67         6
   macro avg       0.72      0.67      0.66         6
weighted avg       0.72      0.67      0.66         6

2022-10-17 14:59:13,367 - trainer - INFO - {
  "train_accuracy_score": 0.6666666666666666,
  "train_loss": 0.4044242799282074
}
2022-10-17 14:59:13,367 - trainer - INFO - start training epoch 53
2022-10-17 14:59:13,368 - trainer - INFO - training using device=cuda
2022-10-17 14:59:13,368 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:13,368 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:13,375 - trainer - INFO - 
*****************[epoch: 53, global step: 54] eval training set at end of epoch***************
2022-10-17 14:59:13,378 - trainer - INFO -               precision    recall  f1-score   support

           0       0.67      1.00      0.80         2
           1       0.50      0.50      0.50         2
           2       1.00      0.50      0.67         2

    accuracy                           0.67         6
   macro avg       0.72      0.67      0.66         6
weighted avg       0.72      0.67      0.66         6

2022-10-17 14:59:13,381 - trainer - INFO - {
  "train_accuracy_score": 0.6666666666666666,
  "train_loss": 0.38086989521980286
}
2022-10-17 14:59:13,381 - trainer - INFO - start training epoch 54
2022-10-17 14:59:13,381 - trainer - INFO - training using device=cuda
2022-10-17 14:59:13,381 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:13,382 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:13,389 - trainer - INFO - 
*****************[epoch: 54, global step: 54] eval training set based on eval_every=2***************
2022-10-17 14:59:13,392 - trainer - INFO -               precision    recall  f1-score   support

           0       1.00      1.00      1.00         2
           1       1.00      1.00      1.00         2
           2       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

2022-10-17 14:59:13,393 - trainer - INFO - {
  "train_accuracy_score": 1.0,
  "train_loss": 0.33298322558403015
}
2022-10-17 14:59:13,402 - trainer - INFO - 
*****************[epoch: 54, global step: 54] eval development set based on eval_every=2***************
2022-10-17 14:59:13,404 - trainer - INFO -               precision    recall  f1-score   support

         0.0       1.00      1.00      1.00         2
         1.0       1.00      1.00      1.00         2
         2.0       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

2022-10-17 14:59:13,405 - trainer - INFO - {
  "dev_loss": 0.3054957985877991,
  "dev_accuracy": 1.0,
  "dev_best_score_for_accuracy": 1.0
}
2022-10-17 14:59:13,406 - trainer - INFO -   no_improve_count: 5
2022-10-17 14:59:13,407 - trainer - INFO -   patience: 200
2022-10-17 14:59:13,410 - trainer - INFO -    Check 3 checkpoints already saved
2022-10-17 14:59:13,411 - trainer - INFO -    There are more than keep_ck_num as specified, then remove the oldest saved checkpoint
2022-10-17 14:59:13,411 - trainer - INFO -   Remove checkpoint tmp/mlp_tes1\ck_48
2022-10-17 14:59:13,412 - trainer - INFO -   Save checkpoint to tmp/mlp_tes1\ck_54
2022-10-17 14:59:13,416 - trainer - INFO - save model to path: tmp/mlp_tes1\ck_54
2022-10-17 14:59:13,416 - trainer - INFO - 
*****************[epoch: 54, global step: 55] eval training set at end of epoch***************
2022-10-17 14:59:13,419 - trainer - INFO -               precision    recall  f1-score   support

           0       1.00      1.00      1.00         2
           1       1.00      1.00      1.00         2
           2       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

2022-10-17 14:59:13,420 - trainer - INFO - {
  "train_accuracy_score": 1.0,
  "train_loss": 0.28509655594825745
}
2022-10-17 14:59:13,420 - trainer - INFO - start training epoch 55
2022-10-17 14:59:13,421 - trainer - INFO - training using device=cuda
2022-10-17 14:59:13,422 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:13,422 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:13,430 - trainer - INFO - 
*****************[epoch: 55, global step: 56] eval training set at end of epoch***************
2022-10-17 14:59:13,433 - trainer - INFO -               precision    recall  f1-score   support

           0       1.00      1.00      1.00         2
           1       1.00      0.50      0.67         2
           2       0.67      1.00      0.80         2

    accuracy                           0.83         6
   macro avg       0.89      0.83      0.82         6
weighted avg       0.89      0.83      0.82         6

2022-10-17 14:59:13,434 - trainer - INFO - {
  "train_accuracy_score": 0.8333333333333334,
  "train_loss": 0.3095302879810333
}
2022-10-17 14:59:13,434 - trainer - INFO - start training epoch 56
2022-10-17 14:59:13,434 - trainer - INFO - training using device=cuda
2022-10-17 14:59:13,435 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:13,435 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:13,442 - trainer - INFO - 
*****************[epoch: 56, global step: 56] eval training set based on eval_every=2***************
2022-10-17 14:59:13,445 - trainer - INFO -               precision    recall  f1-score   support

           0       0.67      1.00      0.80         2
           1       0.50      0.50      0.50         2
           2       1.00      0.50      0.67         2

    accuracy                           0.67         6
   macro avg       0.72      0.67      0.66         6
weighted avg       0.72      0.67      0.66         6

2022-10-17 14:59:13,446 - trainer - INFO - {
  "train_accuracy_score": 0.6666666666666666,
  "train_loss": 0.3238197863101959
}
2022-10-17 14:59:13,458 - trainer - INFO - 
*****************[epoch: 56, global step: 56] eval development set based on eval_every=2***************
2022-10-17 14:59:13,460 - trainer - INFO -               precision    recall  f1-score   support

         0.0       1.00      1.00      1.00         2
         1.0       1.00      1.00      1.00         2
         2.0       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

2022-10-17 14:59:13,461 - trainer - INFO - {
  "dev_loss": 0.27169105410575867,
  "dev_accuracy": 1.0,
  "dev_best_score_for_accuracy": 1.0
}
2022-10-17 14:59:13,462 - trainer - INFO -   no_improve_count: 6
2022-10-17 14:59:13,462 - trainer - INFO -   patience: 200
2022-10-17 14:59:13,464 - trainer - INFO -    Check 3 checkpoints already saved
2022-10-17 14:59:13,464 - trainer - INFO -    There are more than keep_ck_num as specified, then remove the oldest saved checkpoint
2022-10-17 14:59:13,464 - trainer - INFO -   Remove checkpoint tmp/mlp_tes1\ck_50
2022-10-17 14:59:13,466 - trainer - INFO -   Save checkpoint to tmp/mlp_tes1\ck_56
2022-10-17 14:59:13,470 - trainer - INFO - save model to path: tmp/mlp_tes1\ck_56
2022-10-17 14:59:13,474 - trainer - INFO - 
*****************[epoch: 56, global step: 57] eval training set at end of epoch***************
2022-10-17 14:59:13,478 - trainer - INFO -               precision    recall  f1-score   support

           0       0.67      1.00      0.80         2
           1       0.50      0.50      0.50         2
           2       1.00      0.50      0.67         2

    accuracy                           0.67         6
   macro avg       0.72      0.67      0.66         6
weighted avg       0.72      0.67      0.66         6

2022-10-17 14:59:13,479 - trainer - INFO - {
  "train_accuracy_score": 0.6666666666666666,
  "train_loss": 0.3381092846393585
}
2022-10-17 14:59:13,479 - trainer - INFO - start training epoch 57
2022-10-17 14:59:13,480 - trainer - INFO - training using device=cuda
2022-10-17 14:59:13,480 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:13,480 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:13,488 - trainer - INFO - 
*****************[epoch: 57, global step: 58] eval training set at end of epoch***************
2022-10-17 14:59:13,490 - trainer - INFO -               precision    recall  f1-score   support

           0       1.00      1.00      1.00         2
           1       1.00      1.00      1.00         2
           2       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

2022-10-17 14:59:13,491 - trainer - INFO - {
  "train_accuracy_score": 1.0,
  "train_loss": 0.2784516215324402
}
2022-10-17 14:59:13,491 - trainer - INFO - start training epoch 58
2022-10-17 14:59:13,492 - trainer - INFO - training using device=cuda
2022-10-17 14:59:13,492 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:13,492 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:13,500 - trainer - INFO - 
*****************[epoch: 58, global step: 58] eval training set based on eval_every=2***************
2022-10-17 14:59:13,502 - trainer - INFO -               precision    recall  f1-score   support

           0       1.00      1.00      1.00         2
           1       1.00      1.00      1.00         2
           2       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

2022-10-17 14:59:13,503 - trainer - INFO - {
  "train_accuracy_score": 1.0,
  "train_loss": 0.24976664036512375
}
2022-10-17 14:59:13,514 - trainer - INFO - 
*****************[epoch: 58, global step: 58] eval development set based on eval_every=2***************
2022-10-17 14:59:13,517 - trainer - INFO -               precision    recall  f1-score   support

         0.0       1.00      1.00      1.00         2
         1.0       1.00      1.00      1.00         2
         2.0       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

2022-10-17 14:59:13,518 - trainer - INFO - {
  "dev_loss": 0.2540819048881531,
  "dev_accuracy": 1.0,
  "dev_best_score_for_accuracy": 1.0
}
2022-10-17 14:59:13,519 - trainer - INFO -   no_improve_count: 7
2022-10-17 14:59:13,519 - trainer - INFO -   patience: 200
2022-10-17 14:59:13,520 - trainer - INFO -    Check 3 checkpoints already saved
2022-10-17 14:59:13,521 - trainer - INFO -    There are more than keep_ck_num as specified, then remove the oldest saved checkpoint
2022-10-17 14:59:13,521 - trainer - INFO -   Remove checkpoint tmp/mlp_tes1\ck_52
2022-10-17 14:59:13,522 - trainer - INFO -   Save checkpoint to tmp/mlp_tes1\ck_58
2022-10-17 14:59:13,526 - trainer - INFO - save model to path: tmp/mlp_tes1\ck_58
2022-10-17 14:59:13,527 - trainer - INFO - 
*****************[epoch: 58, global step: 59] eval training set at end of epoch***************
2022-10-17 14:59:13,531 - trainer - INFO -               precision    recall  f1-score   support

           0       1.00      1.00      1.00         2
           1       1.00      1.00      1.00         2
           2       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

2022-10-17 14:59:13,532 - trainer - INFO - {
  "train_accuracy_score": 1.0,
  "train_loss": 0.2210816591978073
}
2022-10-17 14:59:13,532 - trainer - INFO - start training epoch 59
2022-10-17 14:59:13,533 - trainer - INFO - training using device=cuda
2022-10-17 14:59:13,533 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:13,533 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:13,542 - trainer - INFO - 
*****************[epoch: 59, global step: 60] eval training set at end of epoch***************
2022-10-17 14:59:13,544 - trainer - INFO -               precision    recall  f1-score   support

           0       1.00      1.00      1.00         2
           1       1.00      1.00      1.00         2
           2       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

2022-10-17 14:59:13,545 - trainer - INFO - {
  "train_accuracy_score": 1.0,
  "train_loss": 0.25887417793273926
}
2022-10-17 14:59:13,546 - trainer - INFO - start training epoch 60
2022-10-17 14:59:13,547 - trainer - INFO - training using device=cuda
2022-10-17 14:59:13,548 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:13,549 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:13,558 - trainer - INFO - 
*****************[epoch: 60, global step: 60] eval training set based on eval_every=2***************
2022-10-17 14:59:13,561 - trainer - INFO -               precision    recall  f1-score   support

           0       1.00      1.00      1.00         2
           1       1.00      0.50      0.67         2
           2       0.67      1.00      0.80         2

    accuracy                           0.83         6
   macro avg       0.89      0.83      0.82         6
weighted avg       0.89      0.83      0.82         6

2022-10-17 14:59:13,562 - trainer - INFO - {
  "train_accuracy_score": 0.8333333333333334,
  "train_loss": 0.28473688662052155
}
2022-10-17 14:59:13,573 - trainer - INFO - 
*****************[epoch: 60, global step: 60] eval development set based on eval_every=2***************
2022-10-17 14:59:13,575 - trainer - INFO -               precision    recall  f1-score   support

         0.0       1.00      1.00      1.00         2
         1.0       1.00      1.00      1.00         2
         2.0       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

2022-10-17 14:59:13,576 - trainer - INFO - {
  "dev_loss": 0.2750212252140045,
  "dev_accuracy": 1.0,
  "dev_best_score_for_accuracy": 1.0
}
2022-10-17 14:59:13,577 - trainer - INFO -   no_improve_count: 8
2022-10-17 14:59:13,577 - trainer - INFO -   patience: 200
2022-10-17 14:59:13,578 - trainer - INFO -    Check 3 checkpoints already saved
2022-10-17 14:59:13,579 - trainer - INFO -    There are more than keep_ck_num as specified, then remove the oldest saved checkpoint
2022-10-17 14:59:13,579 - trainer - INFO -   Remove checkpoint tmp/mlp_tes1\ck_54
2022-10-17 14:59:13,580 - trainer - INFO -   Save checkpoint to tmp/mlp_tes1\ck_60
2022-10-17 14:59:13,584 - trainer - INFO - save model to path: tmp/mlp_tes1\ck_60
2022-10-17 14:59:13,584 - trainer - INFO - 
*****************[epoch: 60, global step: 61] eval training set at end of epoch***************
2022-10-17 14:59:13,587 - trainer - INFO -               precision    recall  f1-score   support

           0       1.00      1.00      1.00         2
           1       1.00      0.50      0.67         2
           2       0.67      1.00      0.80         2

    accuracy                           0.83         6
   macro avg       0.89      0.83      0.82         6
weighted avg       0.89      0.83      0.82         6

2022-10-17 14:59:13,588 - trainer - INFO - {
  "train_accuracy_score": 0.8333333333333334,
  "train_loss": 0.31059959530830383
}
2022-10-17 14:59:13,588 - trainer - INFO - start training epoch 61
2022-10-17 14:59:13,588 - trainer - INFO - training using device=cuda
2022-10-17 14:59:13,588 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:13,589 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:13,597 - trainer - INFO - 
*****************[epoch: 61, global step: 62] eval training set at end of epoch***************
2022-10-17 14:59:13,600 - trainer - INFO -               precision    recall  f1-score   support

           0       1.00      1.00      1.00         2
           1       1.00      1.00      1.00         2
           2       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

2022-10-17 14:59:13,601 - trainer - INFO - {
  "train_accuracy_score": 1.0,
  "train_loss": 0.27142462134361267
}
2022-10-17 14:59:13,601 - trainer - INFO - start training epoch 62
2022-10-17 14:59:13,601 - trainer - INFO - training using device=cuda
2022-10-17 14:59:13,601 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:13,602 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:13,608 - trainer - INFO - 
*****************[epoch: 62, global step: 62] eval training set based on eval_every=2***************
2022-10-17 14:59:13,612 - trainer - INFO -               precision    recall  f1-score   support

           0       1.00      1.00      1.00         2
           1       1.00      1.00      1.00         2
           2       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

2022-10-17 14:59:13,613 - trainer - INFO - {
  "train_accuracy_score": 1.0,
  "train_loss": 0.23031765967607498
}
2022-10-17 14:59:13,622 - trainer - INFO - 
*****************[epoch: 62, global step: 62] eval development set based on eval_every=2***************
2022-10-17 14:59:13,625 - trainer - INFO -               precision    recall  f1-score   support

         0.0       1.00      1.00      1.00         2
         1.0       1.00      1.00      1.00         2
         2.0       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

2022-10-17 14:59:13,627 - trainer - INFO - {
  "dev_loss": 0.17194987833499908,
  "dev_accuracy": 1.0,
  "dev_best_score_for_accuracy": 1.0
}
2022-10-17 14:59:13,627 - trainer - INFO -   no_improve_count: 9
2022-10-17 14:59:13,628 - trainer - INFO -   patience: 200
2022-10-17 14:59:13,629 - trainer - INFO -    Check 3 checkpoints already saved
2022-10-17 14:59:13,629 - trainer - INFO -    There are more than keep_ck_num as specified, then remove the oldest saved checkpoint
2022-10-17 14:59:13,629 - trainer - INFO -   Remove checkpoint tmp/mlp_tes1\ck_56
2022-10-17 14:59:13,631 - trainer - INFO -   Save checkpoint to tmp/mlp_tes1\ck_62
2022-10-17 14:59:13,635 - trainer - INFO - save model to path: tmp/mlp_tes1\ck_62
2022-10-17 14:59:13,636 - trainer - INFO - 
*****************[epoch: 62, global step: 63] eval training set at end of epoch***************
2022-10-17 14:59:13,639 - trainer - INFO -               precision    recall  f1-score   support

           0       1.00      1.00      1.00         2
           1       1.00      1.00      1.00         2
           2       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

2022-10-17 14:59:13,640 - trainer - INFO - {
  "train_accuracy_score": 1.0,
  "train_loss": 0.1892106980085373
}
2022-10-17 14:59:13,641 - trainer - INFO - start training epoch 63
2022-10-17 14:59:13,641 - trainer - INFO - training using device=cuda
2022-10-17 14:59:13,641 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:13,641 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:13,649 - trainer - INFO - 
*****************[epoch: 63, global step: 64] eval training set at end of epoch***************
2022-10-17 14:59:13,652 - trainer - INFO -               precision    recall  f1-score   support

           0       1.00      1.00      1.00         2
           1       1.00      1.00      1.00         2
           2       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

2022-10-17 14:59:13,652 - trainer - INFO - {
  "train_accuracy_score": 1.0,
  "train_loss": 0.1746031492948532
}
2022-10-17 14:59:13,653 - trainer - INFO - start training epoch 64
2022-10-17 14:59:13,653 - trainer - INFO - training using device=cuda
2022-10-17 14:59:13,653 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:13,654 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:13,666 - trainer - INFO - 
*****************[epoch: 64, global step: 64] eval training set based on eval_every=2***************
2022-10-17 14:59:13,668 - trainer - INFO -               precision    recall  f1-score   support

           0       1.00      1.00      1.00         2
           1       1.00      1.00      1.00         2
           2       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

2022-10-17 14:59:13,670 - trainer - INFO - {
  "train_accuracy_score": 1.0,
  "train_loss": 0.20023317635059357
}
2022-10-17 14:59:13,680 - trainer - INFO - 
*****************[epoch: 64, global step: 64] eval development set based on eval_every=2***************
2022-10-17 14:59:13,682 - trainer - INFO -               precision    recall  f1-score   support

         0.0       1.00      1.00      1.00         2
         1.0       1.00      0.50      0.67         2
         2.0       0.67      1.00      0.80         2

    accuracy                           0.83         6
   macro avg       0.89      0.83      0.82         6
weighted avg       0.89      0.83      0.82         6

2022-10-17 14:59:13,683 - trainer - INFO - {
  "dev_loss": 0.2505732476711273,
  "dev_accuracy": 0.8333333333333334,
  "dev_best_score_for_accuracy": 1.0
}
2022-10-17 14:59:13,683 - trainer - INFO -   no_improve_count: 10
2022-10-17 14:59:13,683 - trainer - INFO -   patience: 200
2022-10-17 14:59:13,684 - trainer - INFO -    Check 3 checkpoints already saved
2022-10-17 14:59:13,685 - trainer - INFO -    There are more than keep_ck_num as specified, then remove the oldest saved checkpoint
2022-10-17 14:59:13,685 - trainer - INFO -   Remove checkpoint tmp/mlp_tes1\ck_58
2022-10-17 14:59:13,686 - trainer - INFO -   Save checkpoint to tmp/mlp_tes1\ck_64
2022-10-17 14:59:13,690 - trainer - INFO - save model to path: tmp/mlp_tes1\ck_64
2022-10-17 14:59:13,690 - trainer - INFO - 
*****************[epoch: 64, global step: 65] eval training set at end of epoch***************
2022-10-17 14:59:13,693 - trainer - INFO -               precision    recall  f1-score   support

           0       1.00      1.00      1.00         2
           1       1.00      1.00      1.00         2
           2       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

2022-10-17 14:59:13,694 - trainer - INFO - {
  "train_accuracy_score": 1.0,
  "train_loss": 0.22586320340633392
}
2022-10-17 14:59:13,695 - trainer - INFO - start training epoch 65
2022-10-17 14:59:13,695 - trainer - INFO - training using device=cuda
2022-10-17 14:59:13,695 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:13,695 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:13,706 - trainer - INFO - 
*****************[epoch: 65, global step: 66] eval training set at end of epoch***************
2022-10-17 14:59:13,710 - trainer - INFO -               precision    recall  f1-score   support

           0       1.00      1.00      1.00         2
           1       1.00      0.50      0.67         2
           2       0.67      1.00      0.80         2

    accuracy                           0.83         6
   macro avg       0.89      0.83      0.82         6
weighted avg       0.89      0.83      0.82         6

2022-10-17 14:59:13,711 - trainer - INFO - {
  "train_accuracy_score": 0.8333333333333334,
  "train_loss": 0.2523150146007538
}
2022-10-17 14:59:13,711 - trainer - INFO - start training epoch 66
2022-10-17 14:59:13,712 - trainer - INFO - training using device=cuda
2022-10-17 14:59:13,712 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:13,712 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:13,720 - trainer - INFO - 
*****************[epoch: 66, global step: 66] eval training set based on eval_every=2***************
2022-10-17 14:59:13,723 - trainer - INFO -               precision    recall  f1-score   support

           0       1.00      1.00      1.00         2
           1       1.00      1.00      1.00         2
           2       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

2022-10-17 14:59:13,723 - trainer - INFO - {
  "train_accuracy_score": 1.0,
  "train_loss": 0.21836594492197037
}
2022-10-17 14:59:13,735 - trainer - INFO - 
*****************[epoch: 66, global step: 66] eval development set based on eval_every=2***************
2022-10-17 14:59:13,737 - trainer - INFO -               precision    recall  f1-score   support

         0.0       1.00      1.00      1.00         2
         1.0       1.00      1.00      1.00         2
         2.0       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

2022-10-17 14:59:13,738 - trainer - INFO - {
  "dev_loss": 0.13011519610881805,
  "dev_accuracy": 1.0,
  "dev_best_score_for_accuracy": 1.0
}
2022-10-17 14:59:13,739 - trainer - INFO -   no_improve_count: 11
2022-10-17 14:59:13,739 - trainer - INFO -   patience: 200
2022-10-17 14:59:13,740 - trainer - INFO -    Check 3 checkpoints already saved
2022-10-17 14:59:13,740 - trainer - INFO -    There are more than keep_ck_num as specified, then remove the oldest saved checkpoint
2022-10-17 14:59:13,740 - trainer - INFO -   Remove checkpoint tmp/mlp_tes1\ck_60
2022-10-17 14:59:13,742 - trainer - INFO -   Save checkpoint to tmp/mlp_tes1\ck_66
2022-10-17 14:59:13,745 - trainer - INFO - save model to path: tmp/mlp_tes1\ck_66
2022-10-17 14:59:13,746 - trainer - INFO - 
*****************[epoch: 66, global step: 67] eval training set at end of epoch***************
2022-10-17 14:59:13,749 - trainer - INFO -               precision    recall  f1-score   support

           0       1.00      1.00      1.00         2
           1       1.00      1.00      1.00         2
           2       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

2022-10-17 14:59:13,750 - trainer - INFO - {
  "train_accuracy_score": 1.0,
  "train_loss": 0.18441687524318695
}
2022-10-17 14:59:13,750 - trainer - INFO - start training epoch 67
2022-10-17 14:59:13,750 - trainer - INFO - training using device=cuda
2022-10-17 14:59:13,751 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:13,751 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:13,758 - trainer - INFO - 
*****************[epoch: 67, global step: 68] eval training set at end of epoch***************
2022-10-17 14:59:13,761 - trainer - INFO -               precision    recall  f1-score   support

           0       1.00      1.00      1.00         2
           1       1.00      1.00      1.00         2
           2       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

2022-10-17 14:59:13,761 - trainer - INFO - {
  "train_accuracy_score": 1.0,
  "train_loss": 0.13125361502170563
}
2022-10-17 14:59:13,762 - trainer - INFO - start training epoch 68
2022-10-17 14:59:13,762 - trainer - INFO - training using device=cuda
2022-10-17 14:59:13,763 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:13,764 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:13,775 - trainer - INFO - 
*****************[epoch: 68, global step: 68] eval training set based on eval_every=2***************
2022-10-17 14:59:13,779 - trainer - INFO -               precision    recall  f1-score   support

           0       1.00      1.00      1.00         2
           1       1.00      1.00      1.00         2
           2       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

2022-10-17 14:59:13,780 - trainer - INFO - {
  "train_accuracy_score": 1.0,
  "train_loss": 0.1425160989165306
}
2022-10-17 14:59:13,792 - trainer - INFO - 
*****************[epoch: 68, global step: 68] eval development set based on eval_every=2***************
2022-10-17 14:59:13,796 - trainer - INFO -               precision    recall  f1-score   support

         0.0       1.00      1.00      1.00         2
         1.0       1.00      1.00      1.00         2
         2.0       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

2022-10-17 14:59:13,796 - trainer - INFO - {
  "dev_loss": 0.1870938390493393,
  "dev_accuracy": 1.0,
  "dev_best_score_for_accuracy": 1.0
}
2022-10-17 14:59:13,797 - trainer - INFO -   no_improve_count: 12
2022-10-17 14:59:13,798 - trainer - INFO -   patience: 200
2022-10-17 14:59:13,799 - trainer - INFO -    Check 3 checkpoints already saved
2022-10-17 14:59:13,799 - trainer - INFO -    There are more than keep_ck_num as specified, then remove the oldest saved checkpoint
2022-10-17 14:59:13,799 - trainer - INFO -   Remove checkpoint tmp/mlp_tes1\ck_62
2022-10-17 14:59:13,801 - trainer - INFO -   Save checkpoint to tmp/mlp_tes1\ck_68
2022-10-17 14:59:13,804 - trainer - INFO - save model to path: tmp/mlp_tes1\ck_68
2022-10-17 14:59:13,805 - trainer - INFO - 
*****************[epoch: 68, global step: 69] eval training set at end of epoch***************
2022-10-17 14:59:13,808 - trainer - INFO -               precision    recall  f1-score   support

           0       1.00      1.00      1.00         2
           1       1.00      1.00      1.00         2
           2       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

2022-10-17 14:59:13,809 - trainer - INFO - {
  "train_accuracy_score": 1.0,
  "train_loss": 0.1537785828113556
}
2022-10-17 14:59:13,809 - trainer - INFO - start training epoch 69
2022-10-17 14:59:13,810 - trainer - INFO - training using device=cuda
2022-10-17 14:59:13,811 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:13,812 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:13,823 - trainer - INFO - 
*****************[epoch: 69, global step: 70] eval training set at end of epoch***************
2022-10-17 14:59:13,827 - trainer - INFO -               precision    recall  f1-score   support

           0       1.00      1.00      1.00         2
           1       1.00      1.00      1.00         2
           2       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

2022-10-17 14:59:13,828 - trainer - INFO - {
  "train_accuracy_score": 1.0,
  "train_loss": 0.1849946230649948
}
2022-10-17 14:59:13,828 - trainer - INFO - start training epoch 70
2022-10-17 14:59:13,828 - trainer - INFO - training using device=cuda
2022-10-17 14:59:13,829 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:13,829 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:13,835 - trainer - INFO - 
*****************[epoch: 70, global step: 70] eval training set based on eval_every=2***************
2022-10-17 14:59:13,837 - trainer - INFO -               precision    recall  f1-score   support

           0       1.00      1.00      1.00         2
           1       1.00      1.00      1.00         2
           2       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

2022-10-17 14:59:13,839 - trainer - INFO - {
  "train_accuracy_score": 1.0,
  "train_loss": 0.18070785701274872
}
2022-10-17 14:59:13,848 - trainer - INFO - 
*****************[epoch: 70, global step: 70] eval development set based on eval_every=2***************
2022-10-17 14:59:13,851 - trainer - INFO -               precision    recall  f1-score   support

         0.0       1.00      1.00      1.00         2
         1.0       1.00      1.00      1.00         2
         2.0       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

2022-10-17 14:59:13,852 - trainer - INFO - {
  "dev_loss": 0.1227455660700798,
  "dev_accuracy": 1.0,
  "dev_best_score_for_accuracy": 1.0
}
2022-10-17 14:59:13,852 - trainer - INFO -   no_improve_count: 13
2022-10-17 14:59:13,852 - trainer - INFO -   patience: 200
2022-10-17 14:59:13,853 - trainer - INFO -    Check 3 checkpoints already saved
2022-10-17 14:59:13,854 - trainer - INFO -    There are more than keep_ck_num as specified, then remove the oldest saved checkpoint
2022-10-17 14:59:13,854 - trainer - INFO -   Remove checkpoint tmp/mlp_tes1\ck_64
2022-10-17 14:59:13,855 - trainer - INFO -   Save checkpoint to tmp/mlp_tes1\ck_70
2022-10-17 14:59:13,860 - trainer - INFO - save model to path: tmp/mlp_tes1\ck_70
2022-10-17 14:59:13,861 - trainer - INFO - 
*****************[epoch: 70, global step: 71] eval training set at end of epoch***************
2022-10-17 14:59:13,863 - trainer - INFO -               precision    recall  f1-score   support

           0       1.00      1.00      1.00         2
           1       1.00      1.00      1.00         2
           2       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

2022-10-17 14:59:13,864 - trainer - INFO - {
  "train_accuracy_score": 1.0,
  "train_loss": 0.17642109096050262
}
2022-10-17 14:59:13,865 - trainer - INFO - start training epoch 71
2022-10-17 14:59:13,865 - trainer - INFO - training using device=cuda
2022-10-17 14:59:13,865 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:13,866 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:13,873 - trainer - INFO - 
*****************[epoch: 71, global step: 72] eval training set at end of epoch***************
2022-10-17 14:59:13,876 - trainer - INFO -               precision    recall  f1-score   support

           0       1.00      1.00      1.00         2
           1       1.00      1.00      1.00         2
           2       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

2022-10-17 14:59:13,877 - trainer - INFO - {
  "train_accuracy_score": 1.0,
  "train_loss": 0.12184492498636246
}
2022-10-17 14:59:13,877 - trainer - INFO - start training epoch 72
2022-10-17 14:59:13,878 - trainer - INFO - training using device=cuda
2022-10-17 14:59:13,878 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:13,878 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:13,884 - trainer - INFO - 
*****************[epoch: 72, global step: 72] eval training set based on eval_every=2***************
2022-10-17 14:59:13,886 - trainer - INFO -               precision    recall  f1-score   support

           0       1.00      1.00      1.00         2
           1       1.00      1.00      1.00         2
           2       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

2022-10-17 14:59:13,887 - trainer - INFO - {
  "train_accuracy_score": 1.0,
  "train_loss": 0.11234119534492493
}
2022-10-17 14:59:13,901 - trainer - INFO - 
*****************[epoch: 72, global step: 72] eval development set based on eval_every=2***************
2022-10-17 14:59:13,903 - trainer - INFO -               precision    recall  f1-score   support

         0.0       1.00      1.00      1.00         2
         1.0       1.00      1.00      1.00         2
         2.0       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

2022-10-17 14:59:13,904 - trainer - INFO - {
  "dev_loss": 0.13305185735225677,
  "dev_accuracy": 1.0,
  "dev_best_score_for_accuracy": 1.0
}
2022-10-17 14:59:13,904 - trainer - INFO -   no_improve_count: 14
2022-10-17 14:59:13,905 - trainer - INFO -   patience: 200
2022-10-17 14:59:13,906 - trainer - INFO -    Check 3 checkpoints already saved
2022-10-17 14:59:13,906 - trainer - INFO -    There are more than keep_ck_num as specified, then remove the oldest saved checkpoint
2022-10-17 14:59:13,906 - trainer - INFO -   Remove checkpoint tmp/mlp_tes1\ck_66
2022-10-17 14:59:13,907 - trainer - INFO -   Save checkpoint to tmp/mlp_tes1\ck_72
2022-10-17 14:59:13,911 - trainer - INFO - save model to path: tmp/mlp_tes1\ck_72
2022-10-17 14:59:13,912 - trainer - INFO - 
*****************[epoch: 72, global step: 73] eval training set at end of epoch***************
2022-10-17 14:59:13,914 - trainer - INFO -               precision    recall  f1-score   support

           0       1.00      1.00      1.00         2
           1       1.00      1.00      1.00         2
           2       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

2022-10-17 14:59:13,915 - trainer - INFO - {
  "train_accuracy_score": 1.0,
  "train_loss": 0.1028374657034874
}
2022-10-17 14:59:13,916 - trainer - INFO - start training epoch 73
2022-10-17 14:59:13,918 - trainer - INFO - training using device=cuda
2022-10-17 14:59:13,919 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:13,919 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:13,932 - trainer - INFO - 
*****************[epoch: 73, global step: 74] eval training set at end of epoch***************
2022-10-17 14:59:13,935 - trainer - INFO -               precision    recall  f1-score   support

           0       1.00      1.00      1.00         2
           1       1.00      1.00      1.00         2
           2       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

2022-10-17 14:59:13,936 - trainer - INFO - {
  "train_accuracy_score": 1.0,
  "train_loss": 0.12997816503047943
}
2022-10-17 14:59:13,937 - trainer - INFO - start training epoch 74
2022-10-17 14:59:13,937 - trainer - INFO - training using device=cuda
2022-10-17 14:59:13,937 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:13,937 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:13,945 - trainer - INFO - 
*****************[epoch: 74, global step: 74] eval training set based on eval_every=2***************
2022-10-17 14:59:13,948 - trainer - INFO -               precision    recall  f1-score   support

           0       1.00      1.00      1.00         2
           1       1.00      1.00      1.00         2
           2       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

2022-10-17 14:59:13,949 - trainer - INFO - {
  "train_accuracy_score": 1.0,
  "train_loss": 0.13505633920431137
}
2022-10-17 14:59:13,958 - trainer - INFO - 
*****************[epoch: 74, global step: 74] eval development set based on eval_every=2***************
2022-10-17 14:59:13,961 - trainer - INFO -               precision    recall  f1-score   support

         0.0       1.00      1.00      1.00         2
         1.0       1.00      1.00      1.00         2
         2.0       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

2022-10-17 14:59:13,961 - trainer - INFO - {
  "dev_loss": 0.11565085500478745,
  "dev_accuracy": 1.0,
  "dev_best_score_for_accuracy": 1.0
}
2022-10-17 14:59:13,962 - trainer - INFO -   no_improve_count: 15
2022-10-17 14:59:13,962 - trainer - INFO -   patience: 200
2022-10-17 14:59:13,963 - trainer - INFO -    Check 3 checkpoints already saved
2022-10-17 14:59:13,964 - trainer - INFO -    There are more than keep_ck_num as specified, then remove the oldest saved checkpoint
2022-10-17 14:59:13,964 - trainer - INFO -   Remove checkpoint tmp/mlp_tes1\ck_68
2022-10-17 14:59:13,968 - trainer - INFO -   Save checkpoint to tmp/mlp_tes1\ck_74
2022-10-17 14:59:13,972 - trainer - INFO - save model to path: tmp/mlp_tes1\ck_74
2022-10-17 14:59:13,973 - trainer - INFO - 
*****************[epoch: 74, global step: 75] eval training set at end of epoch***************
2022-10-17 14:59:13,975 - trainer - INFO -               precision    recall  f1-score   support

           0       1.00      1.00      1.00         2
           1       1.00      1.00      1.00         2
           2       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

2022-10-17 14:59:13,976 - trainer - INFO - {
  "train_accuracy_score": 1.0,
  "train_loss": 0.1401345133781433
}
2022-10-17 14:59:13,977 - trainer - INFO - start training epoch 75
2022-10-17 14:59:13,977 - trainer - INFO - training using device=cuda
2022-10-17 14:59:13,978 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:13,978 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:13,985 - trainer - INFO - 
*****************[epoch: 75, global step: 76] eval training set at end of epoch***************
2022-10-17 14:59:13,987 - trainer - INFO -               precision    recall  f1-score   support

           0       1.00      1.00      1.00         2
           1       1.00      1.00      1.00         2
           2       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

2022-10-17 14:59:13,988 - trainer - INFO - {
  "train_accuracy_score": 1.0,
  "train_loss": 0.11854121834039688
}
2022-10-17 14:59:13,989 - trainer - INFO - start training epoch 76
2022-10-17 14:59:13,989 - trainer - INFO - training using device=cuda
2022-10-17 14:59:13,989 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:13,989 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:13,997 - trainer - INFO - 
*****************[epoch: 76, global step: 76] eval training set based on eval_every=2***************
2022-10-17 14:59:14,001 - trainer - INFO -               precision    recall  f1-score   support

           0       1.00      1.00      1.00         2
           1       1.00      1.00      1.00         2
           2       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

2022-10-17 14:59:14,002 - trainer - INFO - {
  "train_accuracy_score": 1.0,
  "train_loss": 0.10125980153679848
}
2022-10-17 14:59:14,013 - trainer - INFO - 
*****************[epoch: 76, global step: 76] eval development set based on eval_every=2***************
2022-10-17 14:59:14,015 - trainer - INFO -               precision    recall  f1-score   support

         0.0       1.00      1.00      1.00         2
         1.0       1.00      1.00      1.00         2
         2.0       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

2022-10-17 14:59:14,016 - trainer - INFO - {
  "dev_loss": 0.087383933365345,
  "dev_accuracy": 1.0,
  "dev_best_score_for_accuracy": 1.0
}
2022-10-17 14:59:14,016 - trainer - INFO -   no_improve_count: 16
2022-10-17 14:59:14,016 - trainer - INFO -   patience: 200
2022-10-17 14:59:14,017 - trainer - INFO -    Check 3 checkpoints already saved
2022-10-17 14:59:14,017 - trainer - INFO -    There are more than keep_ck_num as specified, then remove the oldest saved checkpoint
2022-10-17 14:59:14,018 - trainer - INFO -   Remove checkpoint tmp/mlp_tes1\ck_70
2022-10-17 14:59:14,019 - trainer - INFO -   Save checkpoint to tmp/mlp_tes1\ck_76
2022-10-17 14:59:14,022 - trainer - INFO - save model to path: tmp/mlp_tes1\ck_76
2022-10-17 14:59:14,023 - trainer - INFO - 
*****************[epoch: 76, global step: 77] eval training set at end of epoch***************
2022-10-17 14:59:14,025 - trainer - INFO -               precision    recall  f1-score   support

           0       1.00      1.00      1.00         2
           1       1.00      1.00      1.00         2
           2       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

2022-10-17 14:59:14,026 - trainer - INFO - {
  "train_accuracy_score": 1.0,
  "train_loss": 0.08397838473320007
}
2022-10-17 14:59:14,027 - trainer - INFO - start training epoch 77
2022-10-17 14:59:14,027 - trainer - INFO - training using device=cuda
2022-10-17 14:59:14,028 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:14,029 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:14,038 - trainer - INFO - 
*****************[epoch: 77, global step: 78] eval training set at end of epoch***************
2022-10-17 14:59:14,041 - trainer - INFO -               precision    recall  f1-score   support

           0       1.00      1.00      1.00         2
           1       1.00      1.00      1.00         2
           2       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

2022-10-17 14:59:14,042 - trainer - INFO - {
  "train_accuracy_score": 1.0,
  "train_loss": 0.08536285161972046
}
2022-10-17 14:59:14,043 - trainer - INFO - start training epoch 78
2022-10-17 14:59:14,043 - trainer - INFO - training using device=cuda
2022-10-17 14:59:14,043 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:14,044 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:14,050 - trainer - INFO - 
*****************[epoch: 78, global step: 78] eval training set based on eval_every=2***************
2022-10-17 14:59:14,052 - trainer - INFO -               precision    recall  f1-score   support

           0       1.00      1.00      1.00         2
           1       1.00      1.00      1.00         2
           2       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

2022-10-17 14:59:14,053 - trainer - INFO - {
  "train_accuracy_score": 1.0,
  "train_loss": 0.09470603242516518
}
2022-10-17 14:59:14,062 - trainer - INFO - 
*****************[epoch: 78, global step: 78] eval development set based on eval_every=2***************
2022-10-17 14:59:14,064 - trainer - INFO -               precision    recall  f1-score   support

         0.0       1.00      1.00      1.00         2
         1.0       1.00      1.00      1.00         2
         2.0       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

2022-10-17 14:59:14,065 - trainer - INFO - {
  "dev_loss": 0.09761449694633484,
  "dev_accuracy": 1.0,
  "dev_best_score_for_accuracy": 1.0
}
2022-10-17 14:59:14,065 - trainer - INFO -   no_improve_count: 17
2022-10-17 14:59:14,066 - trainer - INFO -   patience: 200
2022-10-17 14:59:14,067 - trainer - INFO -    Check 3 checkpoints already saved
2022-10-17 14:59:14,067 - trainer - INFO -    There are more than keep_ck_num as specified, then remove the oldest saved checkpoint
2022-10-17 14:59:14,067 - trainer - INFO -   Remove checkpoint tmp/mlp_tes1\ck_72
2022-10-17 14:59:14,068 - trainer - INFO -   Save checkpoint to tmp/mlp_tes1\ck_78
2022-10-17 14:59:14,071 - trainer - INFO - save model to path: tmp/mlp_tes1\ck_78
2022-10-17 14:59:14,072 - trainer - INFO - 
*****************[epoch: 78, global step: 79] eval training set at end of epoch***************
2022-10-17 14:59:14,075 - trainer - INFO -               precision    recall  f1-score   support

           0       1.00      1.00      1.00         2
           1       1.00      1.00      1.00         2
           2       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

2022-10-17 14:59:14,077 - trainer - INFO - {
  "train_accuracy_score": 1.0,
  "train_loss": 0.1040492132306099
}
2022-10-17 14:59:14,078 - trainer - INFO - start training epoch 79
2022-10-17 14:59:14,078 - trainer - INFO - training using device=cuda
2022-10-17 14:59:14,078 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:14,078 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:14,086 - trainer - INFO - 
*****************[epoch: 79, global step: 80] eval training set at end of epoch***************
2022-10-17 14:59:14,091 - trainer - INFO -               precision    recall  f1-score   support

           0       1.00      1.00      1.00         2
           1       1.00      1.00      1.00         2
           2       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

2022-10-17 14:59:14,092 - trainer - INFO - {
  "train_accuracy_score": 1.0,
  "train_loss": 0.09727507829666138
}
2022-10-17 14:59:14,092 - trainer - INFO - start training epoch 80
2022-10-17 14:59:14,092 - trainer - INFO - training using device=cuda
2022-10-17 14:59:14,093 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:14,093 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:14,100 - trainer - INFO - 
*****************[epoch: 80, global step: 80] eval training set based on eval_every=2***************
2022-10-17 14:59:14,104 - trainer - INFO -               precision    recall  f1-score   support

           0       1.00      1.00      1.00         2
           1       1.00      1.00      1.00         2
           2       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

2022-10-17 14:59:14,105 - trainer - INFO - {
  "train_accuracy_score": 1.0,
  "train_loss": 0.08539367094635963
}
2022-10-17 14:59:14,118 - trainer - INFO - 
*****************[epoch: 80, global step: 80] eval development set based on eval_every=2***************
2022-10-17 14:59:14,121 - trainer - INFO -               precision    recall  f1-score   support

         0.0       1.00      1.00      1.00         2
         1.0       1.00      1.00      1.00         2
         2.0       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

2022-10-17 14:59:14,121 - trainer - INFO - {
  "dev_loss": 0.06308379769325256,
  "dev_accuracy": 1.0,
  "dev_best_score_for_accuracy": 1.0
}
2022-10-17 14:59:14,122 - trainer - INFO -   no_improve_count: 18
2022-10-17 14:59:14,123 - trainer - INFO -   patience: 200
2022-10-17 14:59:14,124 - trainer - INFO -    Check 3 checkpoints already saved
2022-10-17 14:59:14,124 - trainer - INFO -    There are more than keep_ck_num as specified, then remove the oldest saved checkpoint
2022-10-17 14:59:14,124 - trainer - INFO -   Remove checkpoint tmp/mlp_tes1\ck_74
2022-10-17 14:59:14,126 - trainer - INFO -   Save checkpoint to tmp/mlp_tes1\ck_80
2022-10-17 14:59:14,130 - trainer - INFO - save model to path: tmp/mlp_tes1\ck_80
2022-10-17 14:59:14,131 - trainer - INFO - 
*****************[epoch: 80, global step: 81] eval training set at end of epoch***************
2022-10-17 14:59:14,133 - trainer - INFO -               precision    recall  f1-score   support

           0       1.00      1.00      1.00         2
           1       1.00      1.00      1.00         2
           2       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

2022-10-17 14:59:14,134 - trainer - INFO - {
  "train_accuracy_score": 1.0,
  "train_loss": 0.07351226359605789
}
2022-10-17 14:59:14,135 - trainer - INFO - start training epoch 81
2022-10-17 14:59:14,135 - trainer - INFO - training using device=cuda
2022-10-17 14:59:14,135 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:14,136 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:14,143 - trainer - INFO - 
*****************[epoch: 81, global step: 82] eval training set at end of epoch***************
2022-10-17 14:59:14,145 - trainer - INFO -               precision    recall  f1-score   support

           0       1.00      1.00      1.00         2
           1       1.00      1.00      1.00         2
           2       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

2022-10-17 14:59:14,146 - trainer - INFO - {
  "train_accuracy_score": 1.0,
  "train_loss": 0.06345017999410629
}
2022-10-17 14:59:14,146 - trainer - INFO - start training epoch 82
2022-10-17 14:59:14,146 - trainer - INFO - training using device=cuda
2022-10-17 14:59:14,146 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:14,147 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:14,153 - trainer - INFO - 
*****************[epoch: 82, global step: 82] eval training set based on eval_every=2***************
2022-10-17 14:59:14,155 - trainer - INFO -               precision    recall  f1-score   support

           0       1.00      1.00      1.00         2
           1       1.00      1.00      1.00         2
           2       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

2022-10-17 14:59:14,156 - trainer - INFO - {
  "train_accuracy_score": 1.0,
  "train_loss": 0.06914327293634415
}
2022-10-17 14:59:14,166 - trainer - INFO - 
*****************[epoch: 82, global step: 82] eval development set based on eval_every=2***************
2022-10-17 14:59:14,169 - trainer - INFO -               precision    recall  f1-score   support

         0.0       1.00      1.00      1.00         2
         1.0       1.00      1.00      1.00         2
         2.0       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

2022-10-17 14:59:14,170 - trainer - INFO - {
  "dev_loss": 0.07827158272266388,
  "dev_accuracy": 1.0,
  "dev_best_score_for_accuracy": 1.0
}
2022-10-17 14:59:14,170 - trainer - INFO -   no_improve_count: 19
2022-10-17 14:59:14,171 - trainer - INFO -   patience: 200
2022-10-17 14:59:14,172 - trainer - INFO -    Check 3 checkpoints already saved
2022-10-17 14:59:14,172 - trainer - INFO -    There are more than keep_ck_num as specified, then remove the oldest saved checkpoint
2022-10-17 14:59:14,172 - trainer - INFO -   Remove checkpoint tmp/mlp_tes1\ck_76
2022-10-17 14:59:14,173 - trainer - INFO -   Save checkpoint to tmp/mlp_tes1\ck_82
2022-10-17 14:59:14,177 - trainer - INFO - save model to path: tmp/mlp_tes1\ck_82
2022-10-17 14:59:14,178 - trainer - INFO - 
*****************[epoch: 82, global step: 83] eval training set at end of epoch***************
2022-10-17 14:59:14,180 - trainer - INFO -               precision    recall  f1-score   support

           0       1.00      1.00      1.00         2
           1       1.00      1.00      1.00         2
           2       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

2022-10-17 14:59:14,182 - trainer - INFO - {
  "train_accuracy_score": 1.0,
  "train_loss": 0.074836365878582
}
2022-10-17 14:59:14,185 - trainer - INFO - start training epoch 83
2022-10-17 14:59:14,185 - trainer - INFO - training using device=cuda
2022-10-17 14:59:14,185 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:14,186 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:14,193 - trainer - INFO - 
*****************[epoch: 83, global step: 84] eval training set at end of epoch***************
2022-10-17 14:59:14,197 - trainer - INFO -               precision    recall  f1-score   support

           0       1.00      1.00      1.00         2
           1       1.00      1.00      1.00         2
           2       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

2022-10-17 14:59:14,198 - trainer - INFO - {
  "train_accuracy_score": 1.0,
  "train_loss": 0.07622101157903671
}
2022-10-17 14:59:14,198 - trainer - INFO - start training epoch 84
2022-10-17 14:59:14,198 - trainer - INFO - training using device=cuda
2022-10-17 14:59:14,198 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:14,199 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:14,204 - trainer - INFO - 
*****************[epoch: 84, global step: 84] eval training set based on eval_every=2***************
2022-10-17 14:59:14,207 - trainer - INFO -               precision    recall  f1-score   support

           0       1.00      1.00      1.00         2
           1       1.00      1.00      1.00         2
           2       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

2022-10-17 14:59:14,208 - trainer - INFO - {
  "train_accuracy_score": 1.0,
  "train_loss": 0.06759196147322655
}
2022-10-17 14:59:14,217 - trainer - INFO - 
*****************[epoch: 84, global step: 84] eval development set based on eval_every=2***************
2022-10-17 14:59:14,220 - trainer - INFO -               precision    recall  f1-score   support

         0.0       1.00      1.00      1.00         2
         1.0       1.00      1.00      1.00         2
         2.0       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

2022-10-17 14:59:14,220 - trainer - INFO - {
  "dev_loss": 0.05265456438064575,
  "dev_accuracy": 1.0,
  "dev_best_score_for_accuracy": 1.0
}
2022-10-17 14:59:14,221 - trainer - INFO -   no_improve_count: 20
2022-10-17 14:59:14,221 - trainer - INFO -   patience: 200
2022-10-17 14:59:14,222 - trainer - INFO -    Check 3 checkpoints already saved
2022-10-17 14:59:14,222 - trainer - INFO -    There are more than keep_ck_num as specified, then remove the oldest saved checkpoint
2022-10-17 14:59:14,223 - trainer - INFO -   Remove checkpoint tmp/mlp_tes1\ck_78
2022-10-17 14:59:14,224 - trainer - INFO -   Save checkpoint to tmp/mlp_tes1\ck_84
2022-10-17 14:59:14,228 - trainer - INFO - save model to path: tmp/mlp_tes1\ck_84
2022-10-17 14:59:14,230 - trainer - INFO - 
*****************[epoch: 84, global step: 85] eval training set at end of epoch***************
2022-10-17 14:59:14,233 - trainer - INFO -               precision    recall  f1-score   support

           0       1.00      1.00      1.00         2
           1       1.00      1.00      1.00         2
           2       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

2022-10-17 14:59:14,234 - trainer - INFO - {
  "train_accuracy_score": 1.0,
  "train_loss": 0.05896291136741638
}
2022-10-17 14:59:14,235 - trainer - INFO - start training epoch 85
2022-10-17 14:59:14,235 - trainer - INFO - training using device=cuda
2022-10-17 14:59:14,235 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:14,236 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:14,244 - trainer - INFO - 
*****************[epoch: 85, global step: 86] eval training set at end of epoch***************
2022-10-17 14:59:14,247 - trainer - INFO -               precision    recall  f1-score   support

           0       1.00      1.00      1.00         2
           1       1.00      1.00      1.00         2
           2       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

2022-10-17 14:59:14,248 - trainer - INFO - {
  "train_accuracy_score": 1.0,
  "train_loss": 0.05149015784263611
}
2022-10-17 14:59:14,248 - trainer - INFO - start training epoch 86
2022-10-17 14:59:14,248 - trainer - INFO - training using device=cuda
2022-10-17 14:59:14,249 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:14,249 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:14,255 - trainer - INFO - 
*****************[epoch: 86, global step: 86] eval training set based on eval_every=2***************
2022-10-17 14:59:14,257 - trainer - INFO -               precision    recall  f1-score   support

           0       1.00      1.00      1.00         2
           1       1.00      1.00      1.00         2
           2       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

2022-10-17 14:59:14,258 - trainer - INFO - {
  "train_accuracy_score": 1.0,
  "train_loss": 0.05529526807367802
}
2022-10-17 14:59:14,268 - trainer - INFO - 
*****************[epoch: 86, global step: 86] eval development set based on eval_every=2***************
2022-10-17 14:59:14,271 - trainer - INFO -               precision    recall  f1-score   support

         0.0       1.00      1.00      1.00         2
         1.0       1.00      1.00      1.00         2
         2.0       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

2022-10-17 14:59:14,271 - trainer - INFO - {
  "dev_loss": 0.056452032178640366,
  "dev_accuracy": 1.0,
  "dev_best_score_for_accuracy": 1.0
}
2022-10-17 14:59:14,272 - trainer - INFO -   no_improve_count: 21
2022-10-17 14:59:14,272 - trainer - INFO -   patience: 200
2022-10-17 14:59:14,274 - trainer - INFO -    Check 3 checkpoints already saved
2022-10-17 14:59:14,274 - trainer - INFO -    There are more than keep_ck_num as specified, then remove the oldest saved checkpoint
2022-10-17 14:59:14,274 - trainer - INFO -   Remove checkpoint tmp/mlp_tes1\ck_80
2022-10-17 14:59:14,279 - trainer - INFO -   Save checkpoint to tmp/mlp_tes1\ck_86
2022-10-17 14:59:14,283 - trainer - INFO - save model to path: tmp/mlp_tes1\ck_86
2022-10-17 14:59:14,283 - trainer - INFO - 
*****************[epoch: 86, global step: 87] eval training set at end of epoch***************
2022-10-17 14:59:14,286 - trainer - INFO -               precision    recall  f1-score   support

           0       1.00      1.00      1.00         2
           1       1.00      1.00      1.00         2
           2       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

2022-10-17 14:59:14,287 - trainer - INFO - {
  "train_accuracy_score": 1.0,
  "train_loss": 0.059100378304719925
}
2022-10-17 14:59:14,287 - trainer - INFO - start training epoch 87
2022-10-17 14:59:14,288 - trainer - INFO - training using device=cuda
2022-10-17 14:59:14,288 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:14,288 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:14,296 - trainer - INFO - 
*****************[epoch: 87, global step: 88] eval training set at end of epoch***************
2022-10-17 14:59:14,299 - trainer - INFO -               precision    recall  f1-score   support

           0       1.00      1.00      1.00         2
           1       1.00      1.00      1.00         2
           2       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

2022-10-17 14:59:14,300 - trainer - INFO - {
  "train_accuracy_score": 1.0,
  "train_loss": 0.0556289367377758
}
2022-10-17 14:59:14,300 - trainer - INFO - start training epoch 88
2022-10-17 14:59:14,300 - trainer - INFO - training using device=cuda
2022-10-17 14:59:14,300 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:14,301 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:14,306 - trainer - INFO - 
*****************[epoch: 88, global step: 88] eval training set based on eval_every=2***************
2022-10-17 14:59:14,309 - trainer - INFO -               precision    recall  f1-score   support

           0       1.00      1.00      1.00         2
           1       1.00      1.00      1.00         2
           2       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

2022-10-17 14:59:14,309 - trainer - INFO - {
  "train_accuracy_score": 1.0,
  "train_loss": 0.04993044398725033
}
2022-10-17 14:59:14,319 - trainer - INFO - 
*****************[epoch: 88, global step: 88] eval development set based on eval_every=2***************
2022-10-17 14:59:14,321 - trainer - INFO -               precision    recall  f1-score   support

         0.0       1.00      1.00      1.00         2
         1.0       1.00      1.00      1.00         2
         2.0       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

2022-10-17 14:59:14,323 - trainer - INFO - {
  "dev_loss": 0.044337037950754166,
  "dev_accuracy": 1.0,
  "dev_best_score_for_accuracy": 1.0
}
2022-10-17 14:59:14,323 - trainer - INFO -   no_improve_count: 22
2022-10-17 14:59:14,326 - trainer - INFO -   patience: 200
2022-10-17 14:59:14,327 - trainer - INFO -    Check 3 checkpoints already saved
2022-10-17 14:59:14,327 - trainer - INFO -    There are more than keep_ck_num as specified, then remove the oldest saved checkpoint
2022-10-17 14:59:14,328 - trainer - INFO -   Remove checkpoint tmp/mlp_tes1\ck_82
2022-10-17 14:59:14,329 - trainer - INFO -   Save checkpoint to tmp/mlp_tes1\ck_88
2022-10-17 14:59:14,333 - trainer - INFO - save model to path: tmp/mlp_tes1\ck_88
2022-10-17 14:59:14,333 - trainer - INFO - 
*****************[epoch: 88, global step: 89] eval training set at end of epoch***************
2022-10-17 14:59:14,336 - trainer - INFO -               precision    recall  f1-score   support

           0       1.00      1.00      1.00         2
           1       1.00      1.00      1.00         2
           2       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

2022-10-17 14:59:14,337 - trainer - INFO - {
  "train_accuracy_score": 1.0,
  "train_loss": 0.044231951236724854
}
2022-10-17 14:59:14,338 - trainer - INFO - start training epoch 89
2022-10-17 14:59:14,338 - trainer - INFO - training using device=cuda
2022-10-17 14:59:14,338 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:14,338 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:14,346 - trainer - INFO - 
*****************[epoch: 89, global step: 90] eval training set at end of epoch***************
2022-10-17 14:59:14,348 - trainer - INFO -               precision    recall  f1-score   support

           0       1.00      1.00      1.00         2
           1       1.00      1.00      1.00         2
           2       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

2022-10-17 14:59:14,349 - trainer - INFO - {
  "train_accuracy_score": 1.0,
  "train_loss": 0.044152747839689255
}
2022-10-17 14:59:14,349 - trainer - INFO - start training epoch 90
2022-10-17 14:59:14,350 - trainer - INFO - training using device=cuda
2022-10-17 14:59:14,350 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:14,350 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:14,356 - trainer - INFO - 
*****************[epoch: 90, global step: 90] eval training set based on eval_every=2***************
2022-10-17 14:59:14,358 - trainer - INFO -               precision    recall  f1-score   support

           0       1.00      1.00      1.00         2
           1       1.00      1.00      1.00         2
           2       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

2022-10-17 14:59:14,359 - trainer - INFO - {
  "train_accuracy_score": 1.0,
  "train_loss": 0.04550347849726677
}
2022-10-17 14:59:14,370 - trainer - INFO - 
*****************[epoch: 90, global step: 90] eval development set based on eval_every=2***************
2022-10-17 14:59:14,373 - trainer - INFO -               precision    recall  f1-score   support

         0.0       1.00      1.00      1.00         2
         1.0       1.00      1.00      1.00         2
         2.0       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

2022-10-17 14:59:14,374 - trainer - INFO - {
  "dev_loss": 0.04019570350646973,
  "dev_accuracy": 1.0,
  "dev_best_score_for_accuracy": 1.0
}
2022-10-17 14:59:14,374 - trainer - INFO -   no_improve_count: 23
2022-10-17 14:59:14,375 - trainer - INFO -   patience: 200
2022-10-17 14:59:14,376 - trainer - INFO -    Check 3 checkpoints already saved
2022-10-17 14:59:14,376 - trainer - INFO -    There are more than keep_ck_num as specified, then remove the oldest saved checkpoint
2022-10-17 14:59:14,376 - trainer - INFO -   Remove checkpoint tmp/mlp_tes1\ck_84
2022-10-17 14:59:14,377 - trainer - INFO -   Save checkpoint to tmp/mlp_tes1\ck_90
2022-10-17 14:59:14,381 - trainer - INFO - save model to path: tmp/mlp_tes1\ck_90
2022-10-17 14:59:14,382 - trainer - INFO - 
*****************[epoch: 90, global step: 91] eval training set at end of epoch***************
2022-10-17 14:59:14,386 - trainer - INFO -               precision    recall  f1-score   support

           0       1.00      1.00      1.00         2
           1       1.00      1.00      1.00         2
           2       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

2022-10-17 14:59:14,387 - trainer - INFO - {
  "train_accuracy_score": 1.0,
  "train_loss": 0.046854209154844284
}
2022-10-17 14:59:14,388 - trainer - INFO - start training epoch 91
2022-10-17 14:59:14,388 - trainer - INFO - training using device=cuda
2022-10-17 14:59:14,388 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:14,389 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:14,397 - trainer - INFO - 
*****************[epoch: 91, global step: 92] eval training set at end of epoch***************
2022-10-17 14:59:14,399 - trainer - INFO -               precision    recall  f1-score   support

           0       1.00      1.00      1.00         2
           1       1.00      1.00      1.00         2
           2       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

2022-10-17 14:59:14,400 - trainer - INFO - {
  "train_accuracy_score": 1.0,
  "train_loss": 0.040163107216358185
}
2022-10-17 14:59:14,400 - trainer - INFO - start training epoch 92
2022-10-17 14:59:14,400 - trainer - INFO - training using device=cuda
2022-10-17 14:59:14,401 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:14,401 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:14,409 - trainer - INFO - 
*****************[epoch: 92, global step: 92] eval training set based on eval_every=2***************
2022-10-17 14:59:14,412 - trainer - INFO -               precision    recall  f1-score   support

           0       1.00      1.00      1.00         2
           1       1.00      1.00      1.00         2
           2       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

2022-10-17 14:59:14,413 - trainer - INFO - {
  "train_accuracy_score": 1.0,
  "train_loss": 0.038038404658436775
}
2022-10-17 14:59:14,424 - trainer - INFO - 
*****************[epoch: 92, global step: 92] eval development set based on eval_every=2***************
2022-10-17 14:59:14,427 - trainer - INFO -               precision    recall  f1-score   support

         0.0       1.00      1.00      1.00         2
         1.0       1.00      1.00      1.00         2
         2.0       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

2022-10-17 14:59:14,428 - trainer - INFO - {
  "dev_loss": 0.04025716334581375,
  "dev_accuracy": 1.0,
  "dev_best_score_for_accuracy": 1.0
}
2022-10-17 14:59:14,429 - trainer - INFO -   no_improve_count: 24
2022-10-17 14:59:14,429 - trainer - INFO -   patience: 200
2022-10-17 14:59:14,430 - trainer - INFO -    Check 3 checkpoints already saved
2022-10-17 14:59:14,430 - trainer - INFO -    There are more than keep_ck_num as specified, then remove the oldest saved checkpoint
2022-10-17 14:59:14,431 - trainer - INFO -   Remove checkpoint tmp/mlp_tes1\ck_86
2022-10-17 14:59:14,432 - trainer - INFO -   Save checkpoint to tmp/mlp_tes1\ck_92
2022-10-17 14:59:14,436 - trainer - INFO - save model to path: tmp/mlp_tes1\ck_92
2022-10-17 14:59:14,437 - trainer - INFO - 
*****************[epoch: 92, global step: 93] eval training set at end of epoch***************
2022-10-17 14:59:14,439 - trainer - INFO -               precision    recall  f1-score   support

           0       1.00      1.00      1.00         2
           1       1.00      1.00      1.00         2
           2       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

2022-10-17 14:59:14,440 - trainer - INFO - {
  "train_accuracy_score": 1.0,
  "train_loss": 0.035913702100515366
}
2022-10-17 14:59:14,440 - trainer - INFO - start training epoch 93
2022-10-17 14:59:14,440 - trainer - INFO - training using device=cuda
2022-10-17 14:59:14,441 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:14,441 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:14,448 - trainer - INFO - 
*****************[epoch: 93, global step: 94] eval training set at end of epoch***************
2022-10-17 14:59:14,451 - trainer - INFO -               precision    recall  f1-score   support

           0       1.00      1.00      1.00         2
           1       1.00      1.00      1.00         2
           2       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

2022-10-17 14:59:14,451 - trainer - INFO - {
  "train_accuracy_score": 1.0,
  "train_loss": 0.03885413333773613
}
2022-10-17 14:59:14,452 - trainer - INFO - start training epoch 94
2022-10-17 14:59:14,452 - trainer - INFO - training using device=cuda
2022-10-17 14:59:14,452 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:14,453 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:14,458 - trainer - INFO - 
*****************[epoch: 94, global step: 94] eval training set based on eval_every=2***************
2022-10-17 14:59:14,461 - trainer - INFO -               precision    recall  f1-score   support

           0       1.00      1.00      1.00         2
           1       1.00      1.00      1.00         2
           2       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

2022-10-17 14:59:14,461 - trainer - INFO - {
  "train_accuracy_score": 1.0,
  "train_loss": 0.03700483590364456
}
2022-10-17 14:59:14,474 - trainer - INFO - 
*****************[epoch: 94, global step: 94] eval development set based on eval_every=2***************
2022-10-17 14:59:14,478 - trainer - INFO -               precision    recall  f1-score   support

         0.0       1.00      1.00      1.00         2
         1.0       1.00      1.00      1.00         2
         2.0       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

2022-10-17 14:59:14,478 - trainer - INFO - {
  "dev_loss": 0.03087639808654785,
  "dev_accuracy": 1.0,
  "dev_best_score_for_accuracy": 1.0
}
2022-10-17 14:59:14,479 - trainer - INFO -   no_improve_count: 25
2022-10-17 14:59:14,479 - trainer - INFO -   patience: 200
2022-10-17 14:59:14,480 - trainer - INFO -    Check 3 checkpoints already saved
2022-10-17 14:59:14,480 - trainer - INFO -    There are more than keep_ck_num as specified, then remove the oldest saved checkpoint
2022-10-17 14:59:14,481 - trainer - INFO -   Remove checkpoint tmp/mlp_tes1\ck_88
2022-10-17 14:59:14,482 - trainer - INFO -   Save checkpoint to tmp/mlp_tes1\ck_94
2022-10-17 14:59:14,485 - trainer - INFO - save model to path: tmp/mlp_tes1\ck_94
2022-10-17 14:59:14,486 - trainer - INFO - 
*****************[epoch: 94, global step: 95] eval training set at end of epoch***************
2022-10-17 14:59:14,489 - trainer - INFO -               precision    recall  f1-score   support

           0       1.00      1.00      1.00         2
           1       1.00      1.00      1.00         2
           2       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

2022-10-17 14:59:14,489 - trainer - INFO - {
  "train_accuracy_score": 1.0,
  "train_loss": 0.035155538469552994
}
2022-10-17 14:59:14,490 - trainer - INFO - start training epoch 95
2022-10-17 14:59:14,490 - trainer - INFO - training using device=cuda
2022-10-17 14:59:14,491 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:14,492 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:14,499 - trainer - INFO - 
*****************[epoch: 95, global step: 96] eval training set at end of epoch***************
2022-10-17 14:59:14,501 - trainer - INFO -               precision    recall  f1-score   support

           0       1.00      1.00      1.00         2
           1       1.00      1.00      1.00         2
           2       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

2022-10-17 14:59:14,502 - trainer - INFO - {
  "train_accuracy_score": 1.0,
  "train_loss": 0.030794663354754448
}
2022-10-17 14:59:14,502 - trainer - INFO - start training epoch 96
2022-10-17 14:59:14,503 - trainer - INFO - training using device=cuda
2022-10-17 14:59:14,503 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:14,503 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:14,510 - trainer - INFO - 
*****************[epoch: 96, global step: 96] eval training set based on eval_every=2***************
2022-10-17 14:59:14,514 - trainer - INFO -               precision    recall  f1-score   support

           0       1.00      1.00      1.00         2
           1       1.00      1.00      1.00         2
           2       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

2022-10-17 14:59:14,515 - trainer - INFO - {
  "train_accuracy_score": 1.0,
  "train_loss": 0.03175035957247019
}
2022-10-17 14:59:14,526 - trainer - INFO - 
*****************[epoch: 96, global step: 96] eval development set based on eval_every=2***************
2022-10-17 14:59:14,529 - trainer - INFO -               precision    recall  f1-score   support

         0.0       1.00      1.00      1.00         2
         1.0       1.00      1.00      1.00         2
         2.0       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

2022-10-17 14:59:14,530 - trainer - INFO - {
  "dev_loss": 0.030215688049793243,
  "dev_accuracy": 1.0,
  "dev_best_score_for_accuracy": 1.0
}
2022-10-17 14:59:14,531 - trainer - INFO -   no_improve_count: 26
2022-10-17 14:59:14,531 - trainer - INFO -   patience: 200
2022-10-17 14:59:14,532 - trainer - INFO -    Check 3 checkpoints already saved
2022-10-17 14:59:14,532 - trainer - INFO -    There are more than keep_ck_num as specified, then remove the oldest saved checkpoint
2022-10-17 14:59:14,532 - trainer - INFO -   Remove checkpoint tmp/mlp_tes1\ck_90
2022-10-17 14:59:14,534 - trainer - INFO -   Save checkpoint to tmp/mlp_tes1\ck_96
2022-10-17 14:59:14,537 - trainer - INFO - save model to path: tmp/mlp_tes1\ck_96
2022-10-17 14:59:14,538 - trainer - INFO - 
*****************[epoch: 96, global step: 97] eval training set at end of epoch***************
2022-10-17 14:59:14,541 - trainer - INFO -               precision    recall  f1-score   support

           0       1.00      1.00      1.00         2
           1       1.00      1.00      1.00         2
           2       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

2022-10-17 14:59:14,542 - trainer - INFO - {
  "train_accuracy_score": 1.0,
  "train_loss": 0.03270605579018593
}
2022-10-17 14:59:14,542 - trainer - INFO - start training epoch 97
2022-10-17 14:59:14,542 - trainer - INFO - training using device=cuda
2022-10-17 14:59:14,542 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:14,543 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:14,550 - trainer - INFO - 
*****************[epoch: 97, global step: 98] eval training set at end of epoch***************
2022-10-17 14:59:14,552 - trainer - INFO -               precision    recall  f1-score   support

           0       1.00      1.00      1.00         2
           1       1.00      1.00      1.00         2
           2       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

2022-10-17 14:59:14,553 - trainer - INFO - {
  "train_accuracy_score": 1.0,
  "train_loss": 0.02994902990758419
}
2022-10-17 14:59:14,554 - trainer - INFO - start training epoch 98
2022-10-17 14:59:14,557 - trainer - INFO - training using device=cuda
2022-10-17 14:59:14,557 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:14,558 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:14,564 - trainer - INFO - 
*****************[epoch: 98, global step: 98] eval training set based on eval_every=2***************
2022-10-17 14:59:14,567 - trainer - INFO -               precision    recall  f1-score   support

           0       1.00      1.00      1.00         2
           1       1.00      1.00      1.00         2
           2       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

2022-10-17 14:59:14,568 - trainer - INFO - {
  "train_accuracy_score": 1.0,
  "train_loss": 0.028416462242603302
}
2022-10-17 14:59:14,578 - trainer - INFO - 
*****************[epoch: 98, global step: 98] eval development set based on eval_every=2***************
2022-10-17 14:59:14,580 - trainer - INFO -               precision    recall  f1-score   support

         0.0       1.00      1.00      1.00         2
         1.0       1.00      1.00      1.00         2
         2.0       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

2022-10-17 14:59:14,581 - trainer - INFO - {
  "dev_loss": 0.02878538705408573,
  "dev_accuracy": 1.0,
  "dev_best_score_for_accuracy": 1.0
}
2022-10-17 14:59:14,581 - trainer - INFO -   no_improve_count: 27
2022-10-17 14:59:14,582 - trainer - INFO -   patience: 200
2022-10-17 14:59:14,582 - trainer - INFO -    Check 3 checkpoints already saved
2022-10-17 14:59:14,583 - trainer - INFO -    There are more than keep_ck_num as specified, then remove the oldest saved checkpoint
2022-10-17 14:59:14,583 - trainer - INFO -   Remove checkpoint tmp/mlp_tes1\ck_92
2022-10-17 14:59:14,584 - trainer - INFO -   Save checkpoint to tmp/mlp_tes1\ck_98
2022-10-17 14:59:14,587 - trainer - INFO - save model to path: tmp/mlp_tes1\ck_98
2022-10-17 14:59:14,588 - trainer - INFO - 
*****************[epoch: 98, global step: 99] eval training set at end of epoch***************
2022-10-17 14:59:14,591 - trainer - INFO -               precision    recall  f1-score   support

           0       1.00      1.00      1.00         2
           1       1.00      1.00      1.00         2
           2       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

2022-10-17 14:59:14,592 - trainer - INFO - {
  "train_accuracy_score": 1.0,
  "train_loss": 0.026883894577622414
}
2022-10-17 14:59:14,592 - trainer - INFO - start training epoch 99
2022-10-17 14:59:14,593 - trainer - INFO - training using device=cuda
2022-10-17 14:59:14,593 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:14,593 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:14,605 - trainer - INFO - 
*****************[epoch: 99, global step: 100] eval training set at end of epoch***************
2022-10-17 14:59:14,607 - trainer - INFO -               precision    recall  f1-score   support

           0       1.00      1.00      1.00         2
           1       1.00      1.00      1.00         2
           2       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

2022-10-17 14:59:14,608 - trainer - INFO - {
  "train_accuracy_score": 1.0,
  "train_loss": 0.028156938031315804
}
2022-10-17 14:59:14,609 - trainer - INFO - start training epoch 100
2022-10-17 14:59:14,609 - trainer - INFO - training using device=cuda
2022-10-17 14:59:14,609 - trainer - INFO - 
*************hyperparam_dict**********

2022-10-17 14:59:14,609 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cuda",
  "patience": 200,
  "save_path": "tmp/mlp_tes1",
  "eval_on": "accuracy",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "ce",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-10-17 14:59:14,616 - trainer - INFO - 
*****************[epoch: 100, global step: 100] eval training set based on eval_every=2***************
2022-10-17 14:59:14,619 - trainer - INFO -               precision    recall  f1-score   support

           0       1.00      1.00      1.00         2
           1       1.00      1.00      1.00         2
           2       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

2022-10-17 14:59:14,620 - trainer - INFO - {
  "train_accuracy_score": 1.0,
  "train_loss": 0.02673187293112278
}
2022-10-17 14:59:14,629 - trainer - INFO - 
*****************[epoch: 100, global step: 100] eval development set based on eval_every=2***************
2022-10-17 14:59:14,632 - trainer - INFO -               precision    recall  f1-score   support

         0.0       1.00      1.00      1.00         2
         1.0       1.00      1.00      1.00         2
         2.0       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

2022-10-17 14:59:14,632 - trainer - INFO - {
  "dev_loss": 0.024391738697886467,
  "dev_accuracy": 1.0,
  "dev_best_score_for_accuracy": 1.0
}
2022-10-17 14:59:14,633 - trainer - INFO -   no_improve_count: 28
2022-10-17 14:59:14,633 - trainer - INFO -   patience: 200
2022-10-17 14:59:14,634 - trainer - INFO -    Check 3 checkpoints already saved
2022-10-17 14:59:14,634 - trainer - INFO -    There are more than keep_ck_num as specified, then remove the oldest saved checkpoint
2022-10-17 14:59:14,634 - trainer - INFO -   Remove checkpoint tmp/mlp_tes1\ck_94
2022-10-17 14:59:14,635 - trainer - INFO -   Save checkpoint to tmp/mlp_tes1\ck_100
2022-10-17 14:59:14,639 - trainer - INFO - save model to path: tmp/mlp_tes1\ck_100
2022-10-17 14:59:14,639 - trainer - INFO - 
*****************[epoch: 100, global step: 101] eval training set at end of epoch***************
2022-10-17 14:59:14,642 - trainer - INFO -               precision    recall  f1-score   support

           0       1.00      1.00      1.00         2
           1       1.00      1.00      1.00         2
           2       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

2022-10-17 14:59:14,642 - trainer - INFO - {
  "train_accuracy_score": 1.0,
  "train_loss": 0.025306807830929756
}
