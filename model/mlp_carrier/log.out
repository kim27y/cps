2022-09-23 13:52:19,634 - trainer - INFO - MLP(
  (linears): ModuleList(
    (0): Linear(in_features=1, out_features=128, bias=True)
    (1): Linear(in_features=128, out_features=64, bias=True)
    (2): Linear(in_features=64, out_features=32, bias=True)
  )
  (activation_layers): ModuleList(
    (0): ReLU(inplace=True)
    (1): ReLU(inplace=True)
    (2): ReLU(inplace=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
  (linear_output): Linear(in_features=32, out_features=1, bias=True)
)
2022-09-23 13:52:19,635 - trainer - INFO -   Total params: 10625
2022-09-23 13:52:19,635 - trainer - INFO -   Trainable params: 10625
2022-09-23 13:52:19,636 - trainer - INFO -   Non-trainable params: 0
2022-09-23 13:52:19,636 - trainer - INFO -   There are 12  training examples
2022-09-23 13:52:19,636 - trainer - INFO -   There are 12 examples for development
2022-09-23 13:52:19,637 - trainer - INFO - start training epoch 1
2022-09-23 13:52:19,637 - trainer - INFO - training using device=cpu
2022-09-23 13:52:19,638 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:19,638 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:19,669 - trainer - INFO - 
*****************[epoch: 1, global step: 2] eval training set at end of epoch***************
2022-09-23 13:52:19,670 - trainer - INFO - {
  "train_loss": 5439.7021484375
}
2022-09-23 13:52:19,670 - trainer - INFO - start training epoch 2
2022-09-23 13:52:19,670 - trainer - INFO - training using device=cpu
2022-09-23 13:52:19,670 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:19,671 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:19,675 - trainer - INFO - 
*****************[epoch: 2, global step: 2] eval training set based on eval_every=2***************
2022-09-23 13:52:19,675 - trainer - INFO - {
  "train_loss": 5084.260498046875
}
2022-09-23 13:52:19,678 - trainer - INFO - 
*****************[epoch: 2, global step: 2] eval development set based on eval_every=2***************
2022-09-23 13:52:19,679 - trainer - INFO - {
  "dev_loss": 3204.491943359375,
  "dev_best_score_for_loss": -3204.491943359375
}
2022-09-23 13:52:19,679 - trainer - INFO -    save the model with best score so far
2022-09-23 13:52:19,680 - trainer - INFO -    Check 0 checkpoints already saved
2022-09-23 13:52:19,680 - trainer - INFO -   Save checkpoint to model/mlp_carrier
2022-09-23 13:52:19,683 - trainer - INFO - save model to path: model/mlp_carrier
2022-09-23 13:52:19,683 - trainer - INFO -   no_improve_count: 0
2022-09-23 13:52:19,683 - trainer - INFO -   patience: 200
2022-09-23 13:52:19,684 - trainer - INFO -    Check 0 checkpoints already saved
2022-09-23 13:52:19,684 - trainer - INFO -   Save checkpoint to model/mlp_carrier\ck_2
2022-09-23 13:52:19,687 - trainer - INFO - save model to path: model/mlp_carrier\ck_2
2022-09-23 13:52:19,687 - trainer - INFO - 
*****************[epoch: 2, global step: 3] eval training set at end of epoch***************
2022-09-23 13:52:19,688 - trainer - INFO - {
  "train_loss": 4728.81884765625
}
2022-09-23 13:52:19,688 - trainer - INFO - start training epoch 3
2022-09-23 13:52:19,688 - trainer - INFO - training using device=cpu
2022-09-23 13:52:19,688 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:19,689 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:19,693 - trainer - INFO - 
*****************[epoch: 3, global step: 4] eval training set at end of epoch***************
2022-09-23 13:52:19,693 - trainer - INFO - {
  "train_loss": 3204.491943359375
}
2022-09-23 13:52:19,693 - trainer - INFO - start training epoch 4
2022-09-23 13:52:19,693 - trainer - INFO - training using device=cpu
2022-09-23 13:52:19,694 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:19,694 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:19,697 - trainer - INFO - 
*****************[epoch: 4, global step: 4] eval training set based on eval_every=2***************
2022-09-23 13:52:19,697 - trainer - INFO - {
  "train_loss": 2128.7787475585938
}
2022-09-23 13:52:19,699 - trainer - INFO - 
*****************[epoch: 4, global step: 4] eval development set based on eval_every=2***************
2022-09-23 13:52:19,699 - trainer - INFO - {
  "dev_loss": 249.60865783691406,
  "dev_best_score_for_loss": -249.60865783691406
}
2022-09-23 13:52:19,700 - trainer - INFO -    save the model with best score so far
2022-09-23 13:52:19,701 - trainer - INFO -    Check 1 checkpoints already saved
2022-09-23 13:52:19,701 - trainer - INFO -   Save checkpoint to model/mlp_carrier
2022-09-23 13:52:19,703 - trainer - INFO - save model to path: model/mlp_carrier
2022-09-23 13:52:19,703 - trainer - INFO -   no_improve_count: 0
2022-09-23 13:52:19,704 - trainer - INFO -   patience: 200
2022-09-23 13:52:19,704 - trainer - INFO -    Check 1 checkpoints already saved
2022-09-23 13:52:19,704 - trainer - INFO -   Save checkpoint to model/mlp_carrier\ck_4
2022-09-23 13:52:19,707 - trainer - INFO - save model to path: model/mlp_carrier\ck_4
2022-09-23 13:52:19,707 - trainer - INFO - 
*****************[epoch: 4, global step: 5] eval training set at end of epoch***************
2022-09-23 13:52:19,708 - trainer - INFO - {
  "train_loss": 1053.0655517578125
}
2022-09-23 13:52:19,708 - trainer - INFO - start training epoch 5
2022-09-23 13:52:19,708 - trainer - INFO - training using device=cpu
2022-09-23 13:52:19,708 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:19,709 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:19,712 - trainer - INFO - 
*****************[epoch: 5, global step: 6] eval training set at end of epoch***************
2022-09-23 13:52:19,712 - trainer - INFO - {
  "train_loss": 249.60865783691406
}
2022-09-23 13:52:19,713 - trainer - INFO - start training epoch 6
2022-09-23 13:52:19,713 - trainer - INFO - training using device=cpu
2022-09-23 13:52:19,713 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:19,713 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:19,716 - trainer - INFO - 
*****************[epoch: 6, global step: 6] eval training set based on eval_every=2***************
2022-09-23 13:52:19,716 - trainer - INFO - {
  "train_loss": 1123.6057815551758
}
2022-09-23 13:52:19,718 - trainer - INFO - 
*****************[epoch: 6, global step: 6] eval development set based on eval_every=2***************
2022-09-23 13:52:19,719 - trainer - INFO - {
  "dev_loss": 708.5825805664062,
  "dev_best_score_for_loss": -249.60865783691406
}
2022-09-23 13:52:19,719 - trainer - INFO -   no_improve_count: 1
2022-09-23 13:52:19,719 - trainer - INFO -   patience: 200
2022-09-23 13:52:19,720 - trainer - INFO -    Check 2 checkpoints already saved
2022-09-23 13:52:19,720 - trainer - INFO -   Save checkpoint to model/mlp_carrier\ck_6
2022-09-23 13:52:19,723 - trainer - INFO - save model to path: model/mlp_carrier\ck_6
2022-09-23 13:52:19,724 - trainer - INFO - 
*****************[epoch: 6, global step: 7] eval training set at end of epoch***************
2022-09-23 13:52:19,724 - trainer - INFO - {
  "train_loss": 1997.6029052734375
}
2022-09-23 13:52:19,724 - trainer - INFO - start training epoch 7
2022-09-23 13:52:19,725 - trainer - INFO - training using device=cpu
2022-09-23 13:52:19,725 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:19,725 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:19,729 - trainer - INFO - 
*****************[epoch: 7, global step: 8] eval training set at end of epoch***************
2022-09-23 13:52:19,729 - trainer - INFO - {
  "train_loss": 708.5827026367188
}
2022-09-23 13:52:19,729 - trainer - INFO - start training epoch 8
2022-09-23 13:52:19,729 - trainer - INFO - training using device=cpu
2022-09-23 13:52:19,730 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:19,730 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:19,733 - trainer - INFO - 
*****************[epoch: 8, global step: 8] eval training set based on eval_every=2***************
2022-09-23 13:52:19,733 - trainer - INFO - {
  "train_loss": 387.4113006591797
}
2022-09-23 13:52:19,735 - trainer - INFO - 
*****************[epoch: 8, global step: 8] eval development set based on eval_every=2***************
2022-09-23 13:52:19,735 - trainer - INFO - {
  "dev_loss": 391.0384826660156,
  "dev_best_score_for_loss": -249.60865783691406
}
2022-09-23 13:52:19,736 - trainer - INFO -   no_improve_count: 2
2022-09-23 13:52:19,736 - trainer - INFO -   patience: 200
2022-09-23 13:52:19,737 - trainer - INFO -    Check 3 checkpoints already saved
2022-09-23 13:52:19,737 - trainer - INFO -    There are more than keep_ck_num as specified, then remove the oldest saved checkpoint
2022-09-23 13:52:19,737 - trainer - INFO -   Remove checkpoint model/mlp_carrier\ck_2
2022-09-23 13:52:19,738 - trainer - INFO -   Save checkpoint to model/mlp_carrier\ck_8
2022-09-23 13:52:19,741 - trainer - INFO - save model to path: model/mlp_carrier\ck_8
2022-09-23 13:52:19,742 - trainer - INFO - 
*****************[epoch: 8, global step: 9] eval training set at end of epoch***************
2022-09-23 13:52:19,742 - trainer - INFO - {
  "train_loss": 66.23989868164062
}
2022-09-23 13:52:19,743 - trainer - INFO - start training epoch 9
2022-09-23 13:52:19,743 - trainer - INFO - training using device=cpu
2022-09-23 13:52:19,743 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:19,743 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:19,747 - trainer - INFO - 
*****************[epoch: 9, global step: 10] eval training set at end of epoch***************
2022-09-23 13:52:19,747 - trainer - INFO - {
  "train_loss": 391.03857421875
}
2022-09-23 13:52:19,748 - trainer - INFO - start training epoch 10
2022-09-23 13:52:19,748 - trainer - INFO - training using device=cpu
2022-09-23 13:52:19,748 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:19,749 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:19,752 - trainer - INFO - 
*****************[epoch: 10, global step: 10] eval training set based on eval_every=2***************
2022-09-23 13:52:19,752 - trainer - INFO - {
  "train_loss": 601.0140686035156
}
2022-09-23 13:52:19,754 - trainer - INFO - 
*****************[epoch: 10, global step: 10] eval development set based on eval_every=2***************
2022-09-23 13:52:19,754 - trainer - INFO - {
  "dev_loss": 953.805419921875,
  "dev_best_score_for_loss": -249.60865783691406
}
2022-09-23 13:52:19,755 - trainer - INFO -   no_improve_count: 3
2022-09-23 13:52:19,755 - trainer - INFO -   patience: 200
2022-09-23 13:52:19,756 - trainer - INFO -    Check 3 checkpoints already saved
2022-09-23 13:52:19,756 - trainer - INFO -    There are more than keep_ck_num as specified, then remove the oldest saved checkpoint
2022-09-23 13:52:19,756 - trainer - INFO -   Remove checkpoint model/mlp_carrier\ck_4
2022-09-23 13:52:19,757 - trainer - INFO -   Save checkpoint to model/mlp_carrier\ck_10
2022-09-23 13:52:19,760 - trainer - INFO - save model to path: model/mlp_carrier\ck_10
2022-09-23 13:52:19,761 - trainer - INFO - 
*****************[epoch: 10, global step: 11] eval training set at end of epoch***************
2022-09-23 13:52:19,761 - trainer - INFO - {
  "train_loss": 810.9895629882812
}
2022-09-23 13:52:19,762 - trainer - INFO - start training epoch 11
2022-09-23 13:52:19,762 - trainer - INFO - training using device=cpu
2022-09-23 13:52:19,762 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:19,762 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:19,765 - trainer - INFO - 
*****************[epoch: 11, global step: 12] eval training set at end of epoch***************
2022-09-23 13:52:19,766 - trainer - INFO - {
  "train_loss": 953.805419921875
}
2022-09-23 13:52:19,766 - trainer - INFO - start training epoch 12
2022-09-23 13:52:19,766 - trainer - INFO - training using device=cpu
2022-09-23 13:52:19,766 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:19,767 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:19,770 - trainer - INFO - 
*****************[epoch: 12, global step: 12] eval training set based on eval_every=2***************
2022-09-23 13:52:19,770 - trainer - INFO - {
  "train_loss": 881.0580139160156
}
2022-09-23 13:52:19,772 - trainer - INFO - 
*****************[epoch: 12, global step: 12] eval development set based on eval_every=2***************
2022-09-23 13:52:19,773 - trainer - INFO - {
  "dev_loss": 481.9309997558594,
  "dev_best_score_for_loss": -249.60865783691406
}
2022-09-23 13:52:19,773 - trainer - INFO -   no_improve_count: 4
2022-09-23 13:52:19,773 - trainer - INFO -   patience: 200
2022-09-23 13:52:19,774 - trainer - INFO -    Check 3 checkpoints already saved
2022-09-23 13:52:19,775 - trainer - INFO -    There are more than keep_ck_num as specified, then remove the oldest saved checkpoint
2022-09-23 13:52:19,775 - trainer - INFO -   Remove checkpoint model/mlp_carrier\ck_6
2022-09-23 13:52:19,776 - trainer - INFO -   Save checkpoint to model/mlp_carrier\ck_12
2022-09-23 13:52:19,779 - trainer - INFO - save model to path: model/mlp_carrier\ck_12
2022-09-23 13:52:19,780 - trainer - INFO - 
*****************[epoch: 12, global step: 13] eval training set at end of epoch***************
2022-09-23 13:52:19,780 - trainer - INFO - {
  "train_loss": 808.3106079101562
}
2022-09-23 13:52:19,781 - trainer - INFO - start training epoch 13
2022-09-23 13:52:19,781 - trainer - INFO - training using device=cpu
2022-09-23 13:52:19,781 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:19,781 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:19,786 - trainer - INFO - 
*****************[epoch: 13, global step: 14] eval training set at end of epoch***************
2022-09-23 13:52:19,787 - trainer - INFO - {
  "train_loss": 481.9309387207031
}
2022-09-23 13:52:19,787 - trainer - INFO - start training epoch 14
2022-09-23 13:52:19,787 - trainer - INFO - training using device=cpu
2022-09-23 13:52:19,787 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:19,788 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:19,792 - trainer - INFO - 
*****************[epoch: 14, global step: 14] eval training set based on eval_every=2***************
2022-09-23 13:52:19,793 - trainer - INFO - {
  "train_loss": 320.37525177001953
}
2022-09-23 13:52:19,795 - trainer - INFO - 
*****************[epoch: 14, global step: 14] eval development set based on eval_every=2***************
2022-09-23 13:52:19,795 - trainer - INFO - {
  "dev_loss": 70.64656829833984,
  "dev_best_score_for_loss": -70.64656829833984
}
2022-09-23 13:52:19,796 - trainer - INFO -    save the model with best score so far
2022-09-23 13:52:19,797 - trainer - INFO -    Check 3 checkpoints already saved
2022-09-23 13:52:19,797 - trainer - INFO -    There are more than keep_ck_num as specified, then remove the oldest saved checkpoint
2022-09-23 13:52:19,798 - trainer - INFO -   Remove checkpoint model/mlp_carrier\ck_8
2022-09-23 13:52:19,799 - trainer - INFO -   Save checkpoint to model/mlp_carrier
2022-09-23 13:52:19,801 - trainer - INFO - save model to path: model/mlp_carrier
2022-09-23 13:52:19,801 - trainer - INFO -   no_improve_count: 0
2022-09-23 13:52:19,802 - trainer - INFO -   patience: 200
2022-09-23 13:52:19,802 - trainer - INFO -    Check 2 checkpoints already saved
2022-09-23 13:52:19,803 - trainer - INFO -   Save checkpoint to model/mlp_carrier\ck_14
2022-09-23 13:52:19,806 - trainer - INFO - save model to path: model/mlp_carrier\ck_14
2022-09-23 13:52:19,806 - trainer - INFO - 
*****************[epoch: 14, global step: 15] eval training set at end of epoch***************
2022-09-23 13:52:19,807 - trainer - INFO - {
  "train_loss": 158.81956481933594
}
2022-09-23 13:52:19,807 - trainer - INFO - start training epoch 15
2022-09-23 13:52:19,807 - trainer - INFO - training using device=cpu
2022-09-23 13:52:19,808 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:19,808 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:19,812 - trainer - INFO - 
*****************[epoch: 15, global step: 16] eval training set at end of epoch***************
2022-09-23 13:52:19,812 - trainer - INFO - {
  "train_loss": 70.64656829833984
}
2022-09-23 13:52:19,813 - trainer - INFO - start training epoch 16
2022-09-23 13:52:19,813 - trainer - INFO - training using device=cpu
2022-09-23 13:52:19,813 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:19,813 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:19,817 - trainer - INFO - 
*****************[epoch: 16, global step: 16] eval training set based on eval_every=2***************
2022-09-23 13:52:19,818 - trainer - INFO - {
  "train_loss": 183.67252731323242
}
2022-09-23 13:52:19,820 - trainer - INFO - 
*****************[epoch: 16, global step: 16] eval development set based on eval_every=2***************
2022-09-23 13:52:19,821 - trainer - INFO - {
  "dev_loss": 510.8365173339844,
  "dev_best_score_for_loss": -70.64656829833984
}
2022-09-23 13:52:19,821 - trainer - INFO -   no_improve_count: 1
2022-09-23 13:52:19,821 - trainer - INFO -   patience: 200
2022-09-23 13:52:19,822 - trainer - INFO -    Check 3 checkpoints already saved
2022-09-23 13:52:19,823 - trainer - INFO -    There are more than keep_ck_num as specified, then remove the oldest saved checkpoint
2022-09-23 13:52:19,823 - trainer - INFO -   Remove checkpoint model/mlp_carrier\ck_10
2022-09-23 13:52:19,824 - trainer - INFO -   Save checkpoint to model/mlp_carrier\ck_16
2022-09-23 13:52:19,828 - trainer - INFO - save model to path: model/mlp_carrier\ck_16
2022-09-23 13:52:19,829 - trainer - INFO - 
*****************[epoch: 16, global step: 17] eval training set at end of epoch***************
2022-09-23 13:52:19,829 - trainer - INFO - {
  "train_loss": 296.698486328125
}
2022-09-23 13:52:19,829 - trainer - INFO - start training epoch 17
2022-09-23 13:52:19,829 - trainer - INFO - training using device=cpu
2022-09-23 13:52:19,830 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:19,830 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:19,834 - trainer - INFO - 
*****************[epoch: 17, global step: 18] eval training set at end of epoch***************
2022-09-23 13:52:19,834 - trainer - INFO - {
  "train_loss": 510.8364562988281
}
2022-09-23 13:52:19,835 - trainer - INFO - start training epoch 18
2022-09-23 13:52:19,835 - trainer - INFO - training using device=cpu
2022-09-23 13:52:19,835 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:19,835 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:19,839 - trainer - INFO - 
*****************[epoch: 18, global step: 18] eval training set based on eval_every=2***************
2022-09-23 13:52:19,839 - trainer - INFO - {
  "train_loss": 453.40570068359375
}
2022-09-23 13:52:19,841 - trainer - INFO - 
*****************[epoch: 18, global step: 18] eval development set based on eval_every=2***************
2022-09-23 13:52:19,841 - trainer - INFO - {
  "dev_loss": 150.4657440185547,
  "dev_best_score_for_loss": -70.64656829833984
}
2022-09-23 13:52:19,842 - trainer - INFO -   no_improve_count: 2
2022-09-23 13:52:19,842 - trainer - INFO -   patience: 200
2022-09-23 13:52:19,843 - trainer - INFO -    Check 3 checkpoints already saved
2022-09-23 13:52:19,843 - trainer - INFO -    There are more than keep_ck_num as specified, then remove the oldest saved checkpoint
2022-09-23 13:52:19,844 - trainer - INFO -   Remove checkpoint model/mlp_carrier\ck_12
2022-09-23 13:52:19,845 - trainer - INFO -   Save checkpoint to model/mlp_carrier\ck_18
2022-09-23 13:52:19,848 - trainer - INFO - save model to path: model/mlp_carrier\ck_18
2022-09-23 13:52:19,848 - trainer - INFO - 
*****************[epoch: 18, global step: 19] eval training set at end of epoch***************
2022-09-23 13:52:19,849 - trainer - INFO - {
  "train_loss": 395.9749450683594
}
2022-09-23 13:52:19,849 - trainer - INFO - start training epoch 19
2022-09-23 13:52:19,850 - trainer - INFO - training using device=cpu
2022-09-23 13:52:19,850 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:19,850 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:19,854 - trainer - INFO - 
*****************[epoch: 19, global step: 20] eval training set at end of epoch***************
2022-09-23 13:52:19,855 - trainer - INFO - {
  "train_loss": 150.46572875976562
}
2022-09-23 13:52:19,855 - trainer - INFO - start training epoch 20
2022-09-23 13:52:19,855 - trainer - INFO - training using device=cpu
2022-09-23 13:52:19,856 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:19,856 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:19,859 - trainer - INFO - 
*****************[epoch: 20, global step: 20] eval training set based on eval_every=2***************
2022-09-23 13:52:19,860 - trainer - INFO - {
  "train_loss": 103.7324161529541
}
2022-09-23 13:52:19,862 - trainer - INFO - 
*****************[epoch: 20, global step: 20] eval development set based on eval_every=2***************
2022-09-23 13:52:19,862 - trainer - INFO - {
  "dev_loss": 130.57064819335938,
  "dev_best_score_for_loss": -70.64656829833984
}
2022-09-23 13:52:19,863 - trainer - INFO -   no_improve_count: 3
2022-09-23 13:52:19,863 - trainer - INFO -   patience: 200
2022-09-23 13:52:19,864 - trainer - INFO -    Check 3 checkpoints already saved
2022-09-23 13:52:19,864 - trainer - INFO -    There are more than keep_ck_num as specified, then remove the oldest saved checkpoint
2022-09-23 13:52:19,864 - trainer - INFO -   Remove checkpoint model/mlp_carrier\ck_14
2022-09-23 13:52:19,865 - trainer - INFO -   Save checkpoint to model/mlp_carrier\ck_20
2022-09-23 13:52:19,868 - trainer - INFO - save model to path: model/mlp_carrier\ck_20
2022-09-23 13:52:19,868 - trainer - INFO - 
*****************[epoch: 20, global step: 21] eval training set at end of epoch***************
2022-09-23 13:52:19,869 - trainer - INFO - {
  "train_loss": 56.99910354614258
}
2022-09-23 13:52:19,869 - trainer - INFO - start training epoch 21
2022-09-23 13:52:19,869 - trainer - INFO - training using device=cpu
2022-09-23 13:52:19,869 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:19,870 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:19,873 - trainer - INFO - 
*****************[epoch: 21, global step: 22] eval training set at end of epoch***************
2022-09-23 13:52:19,873 - trainer - INFO - {
  "train_loss": 130.5706329345703
}
2022-09-23 13:52:19,874 - trainer - INFO - start training epoch 22
2022-09-23 13:52:19,874 - trainer - INFO - training using device=cpu
2022-09-23 13:52:19,874 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:19,875 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:19,878 - trainer - INFO - 
*****************[epoch: 22, global step: 22] eval training set based on eval_every=2***************
2022-09-23 13:52:19,878 - trainer - INFO - {
  "train_loss": 186.9736099243164
}
2022-09-23 13:52:19,881 - trainer - INFO - 
*****************[epoch: 22, global step: 22] eval development set based on eval_every=2***************
2022-09-23 13:52:19,881 - trainer - INFO - {
  "dev_loss": 294.9097900390625,
  "dev_best_score_for_loss": -70.64656829833984
}
2022-09-23 13:52:19,881 - trainer - INFO -   no_improve_count: 4
2022-09-23 13:52:19,882 - trainer - INFO -   patience: 200
2022-09-23 13:52:19,882 - trainer - INFO -    Check 3 checkpoints already saved
2022-09-23 13:52:19,883 - trainer - INFO -    There are more than keep_ck_num as specified, then remove the oldest saved checkpoint
2022-09-23 13:52:19,883 - trainer - INFO -   Remove checkpoint model/mlp_carrier\ck_16
2022-09-23 13:52:19,884 - trainer - INFO -   Save checkpoint to model/mlp_carrier\ck_22
2022-09-23 13:52:19,887 - trainer - INFO - save model to path: model/mlp_carrier\ck_22
2022-09-23 13:52:19,888 - trainer - INFO - 
*****************[epoch: 22, global step: 23] eval training set at end of epoch***************
2022-09-23 13:52:19,888 - trainer - INFO - {
  "train_loss": 243.3765869140625
}
2022-09-23 13:52:19,888 - trainer - INFO - start training epoch 23
2022-09-23 13:52:19,889 - trainer - INFO - training using device=cpu
2022-09-23 13:52:19,889 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:19,889 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:19,893 - trainer - INFO - 
*****************[epoch: 23, global step: 24] eval training set at end of epoch***************
2022-09-23 13:52:19,894 - trainer - INFO - {
  "train_loss": 294.9097900390625
}
2022-09-23 13:52:19,894 - trainer - INFO - start training epoch 24
2022-09-23 13:52:19,894 - trainer - INFO - training using device=cpu
2022-09-23 13:52:19,894 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:19,895 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:19,898 - trainer - INFO - 
*****************[epoch: 24, global step: 24] eval training set based on eval_every=2***************
2022-09-23 13:52:19,898 - trainer - INFO - {
  "train_loss": 275.76673889160156
}
2022-09-23 13:52:19,900 - trainer - INFO - 
*****************[epoch: 24, global step: 24] eval development set based on eval_every=2***************
2022-09-23 13:52:19,901 - trainer - INFO - {
  "dev_loss": 158.98793029785156,
  "dev_best_score_for_loss": -70.64656829833984
}
2022-09-23 13:52:19,901 - trainer - INFO -   no_improve_count: 5
2022-09-23 13:52:19,902 - trainer - INFO -   patience: 200
2022-09-23 13:52:19,902 - trainer - INFO -    Check 3 checkpoints already saved
2022-09-23 13:52:19,903 - trainer - INFO -    There are more than keep_ck_num as specified, then remove the oldest saved checkpoint
2022-09-23 13:52:19,903 - trainer - INFO -   Remove checkpoint model/mlp_carrier\ck_18
2022-09-23 13:52:19,904 - trainer - INFO -   Save checkpoint to model/mlp_carrier\ck_24
2022-09-23 13:52:19,907 - trainer - INFO - save model to path: model/mlp_carrier\ck_24
2022-09-23 13:52:19,908 - trainer - INFO - 
*****************[epoch: 24, global step: 25] eval training set at end of epoch***************
2022-09-23 13:52:19,908 - trainer - INFO - {
  "train_loss": 256.6236877441406
}
2022-09-23 13:52:19,908 - trainer - INFO - start training epoch 25
2022-09-23 13:52:19,909 - trainer - INFO - training using device=cpu
2022-09-23 13:52:19,909 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:19,909 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:19,912 - trainer - INFO - 
*****************[epoch: 25, global step: 26] eval training set at end of epoch***************
2022-09-23 13:52:19,913 - trainer - INFO - {
  "train_loss": 158.98793029785156
}
2022-09-23 13:52:19,913 - trainer - INFO - start training epoch 26
2022-09-23 13:52:19,913 - trainer - INFO - training using device=cpu
2022-09-23 13:52:19,914 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:19,914 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:19,917 - trainer - INFO - 
*****************[epoch: 26, global step: 26] eval training set based on eval_every=2***************
2022-09-23 13:52:19,917 - trainer - INFO - {
  "train_loss": 114.37903213500977
}
2022-09-23 13:52:19,920 - trainer - INFO - 
*****************[epoch: 26, global step: 26] eval development set based on eval_every=2***************
2022-09-23 13:52:19,920 - trainer - INFO - {
  "dev_loss": 56.34663009643555,
  "dev_best_score_for_loss": -56.34663009643555
}
2022-09-23 13:52:19,920 - trainer - INFO -    save the model with best score so far
2022-09-23 13:52:19,921 - trainer - INFO -    Check 3 checkpoints already saved
2022-09-23 13:52:19,922 - trainer - INFO -    There are more than keep_ck_num as specified, then remove the oldest saved checkpoint
2022-09-23 13:52:19,922 - trainer - INFO -   Remove checkpoint model/mlp_carrier\ck_20
2022-09-23 13:52:19,923 - trainer - INFO -   Save checkpoint to model/mlp_carrier
2022-09-23 13:52:19,925 - trainer - INFO - save model to path: model/mlp_carrier
2022-09-23 13:52:19,925 - trainer - INFO -   no_improve_count: 0
2022-09-23 13:52:19,926 - trainer - INFO -   patience: 200
2022-09-23 13:52:19,926 - trainer - INFO -    Check 2 checkpoints already saved
2022-09-23 13:52:19,927 - trainer - INFO -   Save checkpoint to model/mlp_carrier\ck_26
2022-09-23 13:52:19,929 - trainer - INFO - save model to path: model/mlp_carrier\ck_26
2022-09-23 13:52:19,930 - trainer - INFO - 
*****************[epoch: 26, global step: 27] eval training set at end of epoch***************
2022-09-23 13:52:19,930 - trainer - INFO - {
  "train_loss": 69.77013397216797
}
2022-09-23 13:52:19,930 - trainer - INFO - start training epoch 27
2022-09-23 13:52:19,931 - trainer - INFO - training using device=cpu
2022-09-23 13:52:19,931 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:19,931 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:19,935 - trainer - INFO - 
*****************[epoch: 27, global step: 28] eval training set at end of epoch***************
2022-09-23 13:52:19,935 - trainer - INFO - {
  "train_loss": 56.34663009643555
}
2022-09-23 13:52:19,935 - trainer - INFO - start training epoch 28
2022-09-23 13:52:19,935 - trainer - INFO - training using device=cpu
2022-09-23 13:52:19,936 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:19,936 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:19,939 - trainer - INFO - 
*****************[epoch: 28, global step: 28] eval training set based on eval_every=2***************
2022-09-23 13:52:19,940 - trainer - INFO - {
  "train_loss": 89.05093574523926
}
2022-09-23 13:52:19,942 - trainer - INFO - 
*****************[epoch: 28, global step: 28] eval development set based on eval_every=2***************
2022-09-23 13:52:19,942 - trainer - INFO - {
  "dev_loss": 178.36952209472656,
  "dev_best_score_for_loss": -56.34663009643555
}
2022-09-23 13:52:19,943 - trainer - INFO -   no_improve_count: 1
2022-09-23 13:52:19,943 - trainer - INFO -   patience: 200
2022-09-23 13:52:19,944 - trainer - INFO -    Check 3 checkpoints already saved
2022-09-23 13:52:19,944 - trainer - INFO -    There are more than keep_ck_num as specified, then remove the oldest saved checkpoint
2022-09-23 13:52:19,944 - trainer - INFO -   Remove checkpoint model/mlp_carrier\ck_22
2022-09-23 13:52:19,945 - trainer - INFO -   Save checkpoint to model/mlp_carrier\ck_28
2022-09-23 13:52:19,948 - trainer - INFO - save model to path: model/mlp_carrier\ck_28
2022-09-23 13:52:19,948 - trainer - INFO - 
*****************[epoch: 28, global step: 29] eval training set at end of epoch***************
2022-09-23 13:52:19,948 - trainer - INFO - {
  "train_loss": 121.75524139404297
}
2022-09-23 13:52:19,949 - trainer - INFO - start training epoch 29
2022-09-23 13:52:19,949 - trainer - INFO - training using device=cpu
2022-09-23 13:52:19,949 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:19,950 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:19,953 - trainer - INFO - 
*****************[epoch: 29, global step: 30] eval training set at end of epoch***************
2022-09-23 13:52:19,953 - trainer - INFO - {
  "train_loss": 178.3695068359375
}
2022-09-23 13:52:19,954 - trainer - INFO - start training epoch 30
2022-09-23 13:52:19,954 - trainer - INFO - training using device=cpu
2022-09-23 13:52:19,954 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:19,955 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:19,958 - trainer - INFO - 
*****************[epoch: 30, global step: 30] eval training set based on eval_every=2***************
2022-09-23 13:52:19,958 - trainer - INFO - {
  "train_loss": 165.03614044189453
}
2022-09-23 13:52:19,962 - trainer - INFO - 
*****************[epoch: 30, global step: 30] eval development set based on eval_every=2***************
2022-09-23 13:52:19,962 - trainer - INFO - {
  "dev_loss": 80.40223693847656,
  "dev_best_score_for_loss": -56.34663009643555
}
2022-09-23 13:52:19,963 - trainer - INFO -   no_improve_count: 2
2022-09-23 13:52:19,963 - trainer - INFO -   patience: 200
2022-09-23 13:52:19,964 - trainer - INFO -    Check 3 checkpoints already saved
2022-09-23 13:52:19,964 - trainer - INFO -    There are more than keep_ck_num as specified, then remove the oldest saved checkpoint
2022-09-23 13:52:19,965 - trainer - INFO -   Remove checkpoint model/mlp_carrier\ck_24
2022-09-23 13:52:19,966 - trainer - INFO -   Save checkpoint to model/mlp_carrier\ck_30
2022-09-23 13:52:19,970 - trainer - INFO - save model to path: model/mlp_carrier\ck_30
2022-09-23 13:52:19,970 - trainer - INFO - 
*****************[epoch: 30, global step: 31] eval training set at end of epoch***************
2022-09-23 13:52:19,971 - trainer - INFO - {
  "train_loss": 151.70277404785156
}
2022-09-23 13:52:19,971 - trainer - INFO - start training epoch 31
2022-09-23 13:52:19,971 - trainer - INFO - training using device=cpu
2022-09-23 13:52:19,972 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:19,972 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:19,976 - trainer - INFO - 
*****************[epoch: 31, global step: 32] eval training set at end of epoch***************
2022-09-23 13:52:19,976 - trainer - INFO - {
  "train_loss": 80.40223693847656
}
2022-09-23 13:52:19,977 - trainer - INFO - start training epoch 32
2022-09-23 13:52:19,977 - trainer - INFO - training using device=cpu
2022-09-23 13:52:19,977 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:19,978 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:19,982 - trainer - INFO - 
*****************[epoch: 32, global step: 32] eval training set based on eval_every=2***************
2022-09-23 13:52:19,982 - trainer - INFO - {
  "train_loss": 62.66168975830078
}
2022-09-23 13:52:19,985 - trainer - INFO - 
*****************[epoch: 32, global step: 32] eval development set based on eval_every=2***************
2022-09-23 13:52:19,985 - trainer - INFO - {
  "dev_loss": 64.95121002197266,
  "dev_best_score_for_loss": -56.34663009643555
}
2022-09-23 13:52:19,986 - trainer - INFO -   no_improve_count: 3
2022-09-23 13:52:19,986 - trainer - INFO -   patience: 200
2022-09-23 13:52:19,987 - trainer - INFO -    Check 3 checkpoints already saved
2022-09-23 13:52:19,988 - trainer - INFO -    There are more than keep_ck_num as specified, then remove the oldest saved checkpoint
2022-09-23 13:52:19,988 - trainer - INFO -   Remove checkpoint model/mlp_carrier\ck_26
2022-09-23 13:52:19,989 - trainer - INFO -   Save checkpoint to model/mlp_carrier\ck_32
2022-09-23 13:52:19,993 - trainer - INFO - save model to path: model/mlp_carrier\ck_32
2022-09-23 13:52:19,993 - trainer - INFO - 
*****************[epoch: 32, global step: 33] eval training set at end of epoch***************
2022-09-23 13:52:19,994 - trainer - INFO - {
  "train_loss": 44.921142578125
}
2022-09-23 13:52:19,994 - trainer - INFO - start training epoch 33
2022-09-23 13:52:19,994 - trainer - INFO - training using device=cpu
2022-09-23 13:52:19,994 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:19,995 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:19,999 - trainer - INFO - 
*****************[epoch: 33, global step: 34] eval training set at end of epoch***************
2022-09-23 13:52:19,999 - trainer - INFO - {
  "train_loss": 64.95121002197266
}
2022-09-23 13:52:20,000 - trainer - INFO - start training epoch 34
2022-09-23 13:52:20,000 - trainer - INFO - training using device=cpu
2022-09-23 13:52:20,000 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:20,001 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:20,004 - trainer - INFO - 
*****************[epoch: 34, global step: 34] eval training set based on eval_every=2***************
2022-09-23 13:52:20,004 - trainer - INFO - {
  "train_loss": 82.7486572265625
}
2022-09-23 13:52:20,007 - trainer - INFO - 
*****************[epoch: 34, global step: 34] eval development set based on eval_every=2***************
2022-09-23 13:52:20,008 - trainer - INFO - {
  "dev_loss": 114.61621856689453,
  "dev_best_score_for_loss": -56.34663009643555
}
2022-09-23 13:52:20,008 - trainer - INFO -   no_improve_count: 4
2022-09-23 13:52:20,008 - trainer - INFO -   patience: 200
2022-09-23 13:52:20,009 - trainer - INFO -    Check 3 checkpoints already saved
2022-09-23 13:52:20,009 - trainer - INFO -    There are more than keep_ck_num as specified, then remove the oldest saved checkpoint
2022-09-23 13:52:20,010 - trainer - INFO -   Remove checkpoint model/mlp_carrier\ck_28
2022-09-23 13:52:20,011 - trainer - INFO -   Save checkpoint to model/mlp_carrier\ck_34
2022-09-23 13:52:20,013 - trainer - INFO - save model to path: model/mlp_carrier\ck_34
2022-09-23 13:52:20,014 - trainer - INFO - 
*****************[epoch: 34, global step: 35] eval training set at end of epoch***************
2022-09-23 13:52:20,014 - trainer - INFO - {
  "train_loss": 100.54610443115234
}
2022-09-23 13:52:20,015 - trainer - INFO - start training epoch 35
2022-09-23 13:52:20,015 - trainer - INFO - training using device=cpu
2022-09-23 13:52:20,015 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:20,016 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:20,020 - trainer - INFO - 
*****************[epoch: 35, global step: 36] eval training set at end of epoch***************
2022-09-23 13:52:20,020 - trainer - INFO - {
  "train_loss": 114.6162109375
}
2022-09-23 13:52:20,020 - trainer - INFO - start training epoch 36
2022-09-23 13:52:20,020 - trainer - INFO - training using device=cpu
2022-09-23 13:52:20,021 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:20,021 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:20,025 - trainer - INFO - 
*****************[epoch: 36, global step: 36] eval training set based on eval_every=2***************
2022-09-23 13:52:20,025 - trainer - INFO - {
  "train_loss": 104.73320388793945
}
2022-09-23 13:52:20,027 - trainer - INFO - 
*****************[epoch: 36, global step: 36] eval development set based on eval_every=2***************
2022-09-23 13:52:20,028 - trainer - INFO - {
  "dev_loss": 59.30617904663086,
  "dev_best_score_for_loss": -56.34663009643555
}
2022-09-23 13:52:20,028 - trainer - INFO -   no_improve_count: 5
2022-09-23 13:52:20,028 - trainer - INFO -   patience: 200
2022-09-23 13:52:20,029 - trainer - INFO -    Check 3 checkpoints already saved
2022-09-23 13:52:20,030 - trainer - INFO -    There are more than keep_ck_num as specified, then remove the oldest saved checkpoint
2022-09-23 13:52:20,030 - trainer - INFO -   Remove checkpoint model/mlp_carrier\ck_30
2022-09-23 13:52:20,031 - trainer - INFO -   Save checkpoint to model/mlp_carrier\ck_36
2022-09-23 13:52:20,034 - trainer - INFO - save model to path: model/mlp_carrier\ck_36
2022-09-23 13:52:20,034 - trainer - INFO - 
*****************[epoch: 36, global step: 37] eval training set at end of epoch***************
2022-09-23 13:52:20,035 - trainer - INFO - {
  "train_loss": 94.8501968383789
}
2022-09-23 13:52:20,035 - trainer - INFO - start training epoch 37
2022-09-23 13:52:20,035 - trainer - INFO - training using device=cpu
2022-09-23 13:52:20,035 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:20,036 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:20,040 - trainer - INFO - 
*****************[epoch: 37, global step: 38] eval training set at end of epoch***************
2022-09-23 13:52:20,040 - trainer - INFO - {
  "train_loss": 59.306182861328125
}
2022-09-23 13:52:20,040 - trainer - INFO - start training epoch 38
2022-09-23 13:52:20,041 - trainer - INFO - training using device=cpu
2022-09-23 13:52:20,041 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:20,041 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:20,045 - trainer - INFO - 
*****************[epoch: 38, global step: 38] eval training set based on eval_every=2***************
2022-09-23 13:52:20,045 - trainer - INFO - {
  "train_loss": 49.11440086364746
}
2022-09-23 13:52:20,047 - trainer - INFO - 
*****************[epoch: 38, global step: 38] eval development set based on eval_every=2***************
2022-09-23 13:52:20,047 - trainer - INFO - {
  "dev_loss": 49.54543685913086,
  "dev_best_score_for_loss": -49.54543685913086
}
2022-09-23 13:52:20,048 - trainer - INFO -    save the model with best score so far
2022-09-23 13:52:20,049 - trainer - INFO -    Check 3 checkpoints already saved
2022-09-23 13:52:20,049 - trainer - INFO -    There are more than keep_ck_num as specified, then remove the oldest saved checkpoint
2022-09-23 13:52:20,049 - trainer - INFO -   Remove checkpoint model/mlp_carrier\ck_32
2022-09-23 13:52:20,050 - trainer - INFO -   Save checkpoint to model/mlp_carrier
2022-09-23 13:52:20,052 - trainer - INFO - save model to path: model/mlp_carrier
2022-09-23 13:52:20,052 - trainer - INFO -   no_improve_count: 0
2022-09-23 13:52:20,052 - trainer - INFO -   patience: 200
2022-09-23 13:52:20,053 - trainer - INFO -    Check 2 checkpoints already saved
2022-09-23 13:52:20,053 - trainer - INFO -   Save checkpoint to model/mlp_carrier\ck_38
2022-09-23 13:52:20,056 - trainer - INFO - save model to path: model/mlp_carrier\ck_38
2022-09-23 13:52:20,057 - trainer - INFO - 
*****************[epoch: 38, global step: 39] eval training set at end of epoch***************
2022-09-23 13:52:20,057 - trainer - INFO - {
  "train_loss": 38.9226188659668
}
2022-09-23 13:52:20,058 - trainer - INFO - start training epoch 39
2022-09-23 13:52:20,058 - trainer - INFO - training using device=cpu
2022-09-23 13:52:20,058 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:20,058 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:20,062 - trainer - INFO - 
*****************[epoch: 39, global step: 40] eval training set at end of epoch***************
2022-09-23 13:52:20,062 - trainer - INFO - {
  "train_loss": 49.54543685913086
}
2022-09-23 13:52:20,062 - trainer - INFO - start training epoch 40
2022-09-23 13:52:20,063 - trainer - INFO - training using device=cpu
2022-09-23 13:52:20,063 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:20,063 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:20,066 - trainer - INFO - 
*****************[epoch: 40, global step: 40] eval training set based on eval_every=2***************
2022-09-23 13:52:20,067 - trainer - INFO - {
  "train_loss": 61.14782905578613
}
2022-09-23 13:52:20,069 - trainer - INFO - 
*****************[epoch: 40, global step: 40] eval development set based on eval_every=2***************
2022-09-23 13:52:20,069 - trainer - INFO - {
  "dev_loss": 75.56769561767578,
  "dev_best_score_for_loss": -49.54543685913086
}
2022-09-23 13:52:20,069 - trainer - INFO -   no_improve_count: 1
2022-09-23 13:52:20,070 - trainer - INFO -   patience: 200
2022-09-23 13:52:20,070 - trainer - INFO -    Check 3 checkpoints already saved
2022-09-23 13:52:20,071 - trainer - INFO -    There are more than keep_ck_num as specified, then remove the oldest saved checkpoint
2022-09-23 13:52:20,071 - trainer - INFO -   Remove checkpoint model/mlp_carrier\ck_34
2022-09-23 13:52:20,072 - trainer - INFO -   Save checkpoint to model/mlp_carrier\ck_40
2022-09-23 13:52:20,075 - trainer - INFO - save model to path: model/mlp_carrier\ck_40
2022-09-23 13:52:20,075 - trainer - INFO - 
*****************[epoch: 40, global step: 41] eval training set at end of epoch***************
2022-09-23 13:52:20,076 - trainer - INFO - {
  "train_loss": 72.7502212524414
}
2022-09-23 13:52:20,076 - trainer - INFO - start training epoch 41
2022-09-23 13:52:20,076 - trainer - INFO - training using device=cpu
2022-09-23 13:52:20,076 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:20,077 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:20,080 - trainer - INFO - 
*****************[epoch: 41, global step: 42] eval training set at end of epoch***************
2022-09-23 13:52:20,081 - trainer - INFO - {
  "train_loss": 75.56770324707031
}
2022-09-23 13:52:20,081 - trainer - INFO - start training epoch 42
2022-09-23 13:52:20,081 - trainer - INFO - training using device=cpu
2022-09-23 13:52:20,081 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:20,082 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:20,085 - trainer - INFO - 
*****************[epoch: 42, global step: 42] eval training set based on eval_every=2***************
2022-09-23 13:52:20,085 - trainer - INFO - {
  "train_loss": 64.80331230163574
}
2022-09-23 13:52:20,087 - trainer - INFO - 
*****************[epoch: 42, global step: 42] eval development set based on eval_every=2***************
2022-09-23 13:52:20,088 - trainer - INFO - {
  "dev_loss": 34.920352935791016,
  "dev_best_score_for_loss": -34.920352935791016
}
2022-09-23 13:52:20,088 - trainer - INFO -    save the model with best score so far
2022-09-23 13:52:20,089 - trainer - INFO -    Check 3 checkpoints already saved
2022-09-23 13:52:20,090 - trainer - INFO -    There are more than keep_ck_num as specified, then remove the oldest saved checkpoint
2022-09-23 13:52:20,090 - trainer - INFO -   Remove checkpoint model/mlp_carrier\ck_36
2022-09-23 13:52:20,091 - trainer - INFO -   Save checkpoint to model/mlp_carrier
2022-09-23 13:52:20,093 - trainer - INFO - save model to path: model/mlp_carrier
2022-09-23 13:52:20,093 - trainer - INFO -   no_improve_count: 0
2022-09-23 13:52:20,094 - trainer - INFO -   patience: 200
2022-09-23 13:52:20,094 - trainer - INFO -    Check 2 checkpoints already saved
2022-09-23 13:52:20,095 - trainer - INFO -   Save checkpoint to model/mlp_carrier\ck_42
2022-09-23 13:52:20,097 - trainer - INFO - save model to path: model/mlp_carrier\ck_42
2022-09-23 13:52:20,098 - trainer - INFO - 
*****************[epoch: 42, global step: 43] eval training set at end of epoch***************
2022-09-23 13:52:20,098 - trainer - INFO - {
  "train_loss": 54.03892135620117
}
2022-09-23 13:52:20,099 - trainer - INFO - start training epoch 43
2022-09-23 13:52:20,099 - trainer - INFO - training using device=cpu
2022-09-23 13:52:20,099 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:20,099 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:20,103 - trainer - INFO - 
*****************[epoch: 43, global step: 44] eval training set at end of epoch***************
2022-09-23 13:52:20,103 - trainer - INFO - {
  "train_loss": 34.920352935791016
}
2022-09-23 13:52:20,103 - trainer - INFO - start training epoch 44
2022-09-23 13:52:20,104 - trainer - INFO - training using device=cpu
2022-09-23 13:52:20,104 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:20,104 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:20,108 - trainer - INFO - 
*****************[epoch: 44, global step: 44] eval training set based on eval_every=2***************
2022-09-23 13:52:20,108 - trainer - INFO - {
  "train_loss": 35.40810012817383
}
2022-09-23 13:52:20,110 - trainer - INFO - 
*****************[epoch: 44, global step: 44] eval development set based on eval_every=2***************
2022-09-23 13:52:20,110 - trainer - INFO - {
  "dev_loss": 48.41911697387695,
  "dev_best_score_for_loss": -34.920352935791016
}
2022-09-23 13:52:20,111 - trainer - INFO -   no_improve_count: 1
2022-09-23 13:52:20,111 - trainer - INFO -   patience: 200
2022-09-23 13:52:20,112 - trainer - INFO -    Check 3 checkpoints already saved
2022-09-23 13:52:20,112 - trainer - INFO -    There are more than keep_ck_num as specified, then remove the oldest saved checkpoint
2022-09-23 13:52:20,112 - trainer - INFO -   Remove checkpoint model/mlp_carrier\ck_38
2022-09-23 13:52:20,113 - trainer - INFO -   Save checkpoint to model/mlp_carrier\ck_44
2022-09-23 13:52:20,116 - trainer - INFO - save model to path: model/mlp_carrier\ck_44
2022-09-23 13:52:20,116 - trainer - INFO - 
*****************[epoch: 44, global step: 45] eval training set at end of epoch***************
2022-09-23 13:52:20,117 - trainer - INFO - {
  "train_loss": 35.89584732055664
}
2022-09-23 13:52:20,117 - trainer - INFO - start training epoch 45
2022-09-23 13:52:20,117 - trainer - INFO - training using device=cpu
2022-09-23 13:52:20,118 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:20,118 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:20,122 - trainer - INFO - 
*****************[epoch: 45, global step: 46] eval training set at end of epoch***************
2022-09-23 13:52:20,122 - trainer - INFO - {
  "train_loss": 48.419124603271484
}
2022-09-23 13:52:20,122 - trainer - INFO - start training epoch 46
2022-09-23 13:52:20,122 - trainer - INFO - training using device=cpu
2022-09-23 13:52:20,123 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:20,123 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:20,128 - trainer - INFO - 
*****************[epoch: 46, global step: 46] eval training set based on eval_every=2***************
2022-09-23 13:52:20,128 - trainer - INFO - {
  "train_loss": 51.434112548828125
}
2022-09-23 13:52:20,132 - trainer - INFO - 
*****************[epoch: 46, global step: 46] eval development set based on eval_every=2***************
2022-09-23 13:52:20,132 - trainer - INFO - {
  "dev_loss": 46.46560287475586,
  "dev_best_score_for_loss": -34.920352935791016
}
2022-09-23 13:52:20,133 - trainer - INFO -   no_improve_count: 2
2022-09-23 13:52:20,133 - trainer - INFO -   patience: 200
2022-09-23 13:52:20,134 - trainer - INFO -    Check 3 checkpoints already saved
2022-09-23 13:52:20,135 - trainer - INFO -    There are more than keep_ck_num as specified, then remove the oldest saved checkpoint
2022-09-23 13:52:20,135 - trainer - INFO -   Remove checkpoint model/mlp_carrier\ck_40
2022-09-23 13:52:20,136 - trainer - INFO -   Save checkpoint to model/mlp_carrier\ck_46
2022-09-23 13:52:20,139 - trainer - INFO - save model to path: model/mlp_carrier\ck_46
2022-09-23 13:52:20,140 - trainer - INFO - 
*****************[epoch: 46, global step: 47] eval training set at end of epoch***************
2022-09-23 13:52:20,140 - trainer - INFO - {
  "train_loss": 54.449100494384766
}
2022-09-23 13:52:20,140 - trainer - INFO - start training epoch 47
2022-09-23 13:52:20,141 - trainer - INFO - training using device=cpu
2022-09-23 13:52:20,141 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:20,141 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:20,146 - trainer - INFO - 
*****************[epoch: 47, global step: 48] eval training set at end of epoch***************
2022-09-23 13:52:20,146 - trainer - INFO - {
  "train_loss": 46.46560287475586
}
2022-09-23 13:52:20,147 - trainer - INFO - start training epoch 48
2022-09-23 13:52:20,147 - trainer - INFO - training using device=cpu
2022-09-23 13:52:20,147 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:20,148 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:20,151 - trainer - INFO - 
*****************[epoch: 48, global step: 48] eval training set based on eval_every=2***************
2022-09-23 13:52:20,152 - trainer - INFO - {
  "train_loss": 39.54353332519531
}
2022-09-23 13:52:20,155 - trainer - INFO - 
*****************[epoch: 48, global step: 48] eval development set based on eval_every=2***************
2022-09-23 13:52:20,155 - trainer - INFO - {
  "dev_loss": 27.00533103942871,
  "dev_best_score_for_loss": -27.00533103942871
}
2022-09-23 13:52:20,155 - trainer - INFO -    save the model with best score so far
2022-09-23 13:52:20,156 - trainer - INFO -    Check 3 checkpoints already saved
2022-09-23 13:52:20,157 - trainer - INFO -    There are more than keep_ck_num as specified, then remove the oldest saved checkpoint
2022-09-23 13:52:20,157 - trainer - INFO -   Remove checkpoint model/mlp_carrier\ck_42
2022-09-23 13:52:20,158 - trainer - INFO -   Save checkpoint to model/mlp_carrier
2022-09-23 13:52:20,160 - trainer - INFO - save model to path: model/mlp_carrier
2022-09-23 13:52:20,160 - trainer - INFO -   no_improve_count: 0
2022-09-23 13:52:20,160 - trainer - INFO -   patience: 200
2022-09-23 13:52:20,161 - trainer - INFO -    Check 2 checkpoints already saved
2022-09-23 13:52:20,161 - trainer - INFO -   Save checkpoint to model/mlp_carrier\ck_48
2022-09-23 13:52:20,164 - trainer - INFO - save model to path: model/mlp_carrier\ck_48
2022-09-23 13:52:20,165 - trainer - INFO - 
*****************[epoch: 48, global step: 49] eval training set at end of epoch***************
2022-09-23 13:52:20,165 - trainer - INFO - {
  "train_loss": 32.621463775634766
}
2022-09-23 13:52:20,166 - trainer - INFO - start training epoch 49
2022-09-23 13:52:20,166 - trainer - INFO - training using device=cpu
2022-09-23 13:52:20,166 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:20,166 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:20,171 - trainer - INFO - 
*****************[epoch: 49, global step: 50] eval training set at end of epoch***************
2022-09-23 13:52:20,171 - trainer - INFO - {
  "train_loss": 27.005332946777344
}
2022-09-23 13:52:20,172 - trainer - INFO - start training epoch 50
2022-09-23 13:52:20,172 - trainer - INFO - training using device=cpu
2022-09-23 13:52:20,172 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:20,173 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:20,176 - trainer - INFO - 
*****************[epoch: 50, global step: 50] eval training set based on eval_every=2***************
2022-09-23 13:52:20,176 - trainer - INFO - {
  "train_loss": 30.06861686706543
}
2022-09-23 13:52:20,179 - trainer - INFO - 
*****************[epoch: 50, global step: 50] eval development set based on eval_every=2***************
2022-09-23 13:52:20,179 - trainer - INFO - {
  "dev_loss": 39.51409149169922,
  "dev_best_score_for_loss": -27.00533103942871
}
2022-09-23 13:52:20,179 - trainer - INFO -   no_improve_count: 1
2022-09-23 13:52:20,180 - trainer - INFO -   patience: 200
2022-09-23 13:52:20,180 - trainer - INFO -    Check 3 checkpoints already saved
2022-09-23 13:52:20,181 - trainer - INFO -    There are more than keep_ck_num as specified, then remove the oldest saved checkpoint
2022-09-23 13:52:20,181 - trainer - INFO -   Remove checkpoint model/mlp_carrier\ck_44
2022-09-23 13:52:20,182 - trainer - INFO -   Save checkpoint to model/mlp_carrier\ck_50
2022-09-23 13:52:20,184 - trainer - INFO - save model to path: model/mlp_carrier\ck_50
2022-09-23 13:52:20,185 - trainer - INFO - 
*****************[epoch: 50, global step: 51] eval training set at end of epoch***************
2022-09-23 13:52:20,185 - trainer - INFO - {
  "train_loss": 33.131900787353516
}
2022-09-23 13:52:20,185 - trainer - INFO - start training epoch 51
2022-09-23 13:52:20,186 - trainer - INFO - training using device=cpu
2022-09-23 13:52:20,186 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:20,186 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:20,189 - trainer - INFO - 
*****************[epoch: 51, global step: 52] eval training set at end of epoch***************
2022-09-23 13:52:20,190 - trainer - INFO - {
  "train_loss": 39.51409149169922
}
2022-09-23 13:52:20,190 - trainer - INFO - start training epoch 52
2022-09-23 13:52:20,190 - trainer - INFO - training using device=cpu
2022-09-23 13:52:20,190 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:20,191 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:20,194 - trainer - INFO - 
*****************[epoch: 52, global step: 52] eval training set based on eval_every=2***************
2022-09-23 13:52:20,195 - trainer - INFO - {
  "train_loss": 37.51691246032715
}
2022-09-23 13:52:20,197 - trainer - INFO - 
*****************[epoch: 52, global step: 52] eval development set based on eval_every=2***************
2022-09-23 13:52:20,197 - trainer - INFO - {
  "dev_loss": 25.981773376464844,
  "dev_best_score_for_loss": -25.981773376464844
}
2022-09-23 13:52:20,197 - trainer - INFO -    save the model with best score so far
2022-09-23 13:52:20,198 - trainer - INFO -    Check 3 checkpoints already saved
2022-09-23 13:52:20,199 - trainer - INFO -    There are more than keep_ck_num as specified, then remove the oldest saved checkpoint
2022-09-23 13:52:20,199 - trainer - INFO -   Remove checkpoint model/mlp_carrier\ck_46
2022-09-23 13:52:20,200 - trainer - INFO -   Save checkpoint to model/mlp_carrier
2022-09-23 13:52:20,201 - trainer - INFO - save model to path: model/mlp_carrier
2022-09-23 13:52:20,202 - trainer - INFO -   no_improve_count: 0
2022-09-23 13:52:20,202 - trainer - INFO -   patience: 200
2022-09-23 13:52:20,203 - trainer - INFO -    Check 2 checkpoints already saved
2022-09-23 13:52:20,203 - trainer - INFO -   Save checkpoint to model/mlp_carrier\ck_52
2022-09-23 13:52:20,206 - trainer - INFO - save model to path: model/mlp_carrier\ck_52
2022-09-23 13:52:20,207 - trainer - INFO - 
*****************[epoch: 52, global step: 53] eval training set at end of epoch***************
2022-09-23 13:52:20,207 - trainer - INFO - {
  "train_loss": 35.51973342895508
}
2022-09-23 13:52:20,208 - trainer - INFO - start training epoch 53
2022-09-23 13:52:20,208 - trainer - INFO - training using device=cpu
2022-09-23 13:52:20,208 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:20,209 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:20,212 - trainer - INFO - 
*****************[epoch: 53, global step: 54] eval training set at end of epoch***************
2022-09-23 13:52:20,212 - trainer - INFO - {
  "train_loss": 25.981775283813477
}
2022-09-23 13:52:20,213 - trainer - INFO - start training epoch 54
2022-09-23 13:52:20,213 - trainer - INFO - training using device=cpu
2022-09-23 13:52:20,213 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:20,214 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:20,216 - trainer - INFO - 
*****************[epoch: 54, global step: 54] eval training set based on eval_every=2***************
2022-09-23 13:52:20,217 - trainer - INFO - {
  "train_loss": 24.06718158721924
}
2022-09-23 13:52:20,219 - trainer - INFO - 
*****************[epoch: 54, global step: 54] eval development set based on eval_every=2***************
2022-09-23 13:52:20,219 - trainer - INFO - {
  "dev_loss": 25.73687744140625,
  "dev_best_score_for_loss": -25.73687744140625
}
2022-09-23 13:52:20,220 - trainer - INFO -    save the model with best score so far
2022-09-23 13:52:20,221 - trainer - INFO -    Check 3 checkpoints already saved
2022-09-23 13:52:20,221 - trainer - INFO -    There are more than keep_ck_num as specified, then remove the oldest saved checkpoint
2022-09-23 13:52:20,221 - trainer - INFO -   Remove checkpoint model/mlp_carrier\ck_48
2022-09-23 13:52:20,222 - trainer - INFO -   Save checkpoint to model/mlp_carrier
2022-09-23 13:52:20,225 - trainer - INFO - save model to path: model/mlp_carrier
2022-09-23 13:52:20,225 - trainer - INFO -   no_improve_count: 0
2022-09-23 13:52:20,225 - trainer - INFO -   patience: 200
2022-09-23 13:52:20,226 - trainer - INFO -    Check 2 checkpoints already saved
2022-09-23 13:52:20,226 - trainer - INFO -   Save checkpoint to model/mlp_carrier\ck_54
2022-09-23 13:52:20,229 - trainer - INFO - save model to path: model/mlp_carrier\ck_54
2022-09-23 13:52:20,229 - trainer - INFO - 
*****************[epoch: 54, global step: 55] eval training set at end of epoch***************
2022-09-23 13:52:20,230 - trainer - INFO - {
  "train_loss": 22.152587890625
}
2022-09-23 13:52:20,230 - trainer - INFO - start training epoch 55
2022-09-23 13:52:20,230 - trainer - INFO - training using device=cpu
2022-09-23 13:52:20,230 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:20,231 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:20,234 - trainer - INFO - 
*****************[epoch: 55, global step: 56] eval training set at end of epoch***************
2022-09-23 13:52:20,234 - trainer - INFO - {
  "train_loss": 25.736875534057617
}
2022-09-23 13:52:20,235 - trainer - INFO - start training epoch 56
2022-09-23 13:52:20,235 - trainer - INFO - training using device=cpu
2022-09-23 13:52:20,235 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:20,235 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:20,238 - trainer - INFO - 
*****************[epoch: 56, global step: 56] eval training set based on eval_every=2***************
2022-09-23 13:52:20,239 - trainer - INFO - {
  "train_loss": 27.399084091186523
}
2022-09-23 13:52:20,241 - trainer - INFO - 
*****************[epoch: 56, global step: 56] eval development set based on eval_every=2***************
2022-09-23 13:52:20,241 - trainer - INFO - {
  "dev_loss": 26.390783309936523,
  "dev_best_score_for_loss": -25.73687744140625
}
2022-09-23 13:52:20,241 - trainer - INFO -   no_improve_count: 1
2022-09-23 13:52:20,242 - trainer - INFO -   patience: 200
2022-09-23 13:52:20,243 - trainer - INFO -    Check 3 checkpoints already saved
2022-09-23 13:52:20,243 - trainer - INFO -    There are more than keep_ck_num as specified, then remove the oldest saved checkpoint
2022-09-23 13:52:20,243 - trainer - INFO -   Remove checkpoint model/mlp_carrier\ck_50
2022-09-23 13:52:20,244 - trainer - INFO -   Save checkpoint to model/mlp_carrier\ck_56
2022-09-23 13:52:20,246 - trainer - INFO - save model to path: model/mlp_carrier\ck_56
2022-09-23 13:52:20,247 - trainer - INFO - 
*****************[epoch: 56, global step: 57] eval training set at end of epoch***************
2022-09-23 13:52:20,247 - trainer - INFO - {
  "train_loss": 29.06129264831543
}
2022-09-23 13:52:20,247 - trainer - INFO - start training epoch 57
2022-09-23 13:52:20,248 - trainer - INFO - training using device=cpu
2022-09-23 13:52:20,248 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:20,248 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:20,251 - trainer - INFO - 
*****************[epoch: 57, global step: 58] eval training set at end of epoch***************
2022-09-23 13:52:20,252 - trainer - INFO - {
  "train_loss": 26.390777587890625
}
2022-09-23 13:52:20,252 - trainer - INFO - start training epoch 58
2022-09-23 13:52:20,252 - trainer - INFO - training using device=cpu
2022-09-23 13:52:20,252 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:20,253 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:20,256 - trainer - INFO - 
*****************[epoch: 58, global step: 58] eval training set based on eval_every=2***************
2022-09-23 13:52:20,256 - trainer - INFO - {
  "train_loss": 23.371703147888184
}
2022-09-23 13:52:20,258 - trainer - INFO - 
*****************[epoch: 58, global step: 58] eval development set based on eval_every=2***************
2022-09-23 13:52:20,259 - trainer - INFO - {
  "dev_loss": 17.57708740234375,
  "dev_best_score_for_loss": -17.57708740234375
}
2022-09-23 13:52:20,259 - trainer - INFO -    save the model with best score so far
2022-09-23 13:52:20,260 - trainer - INFO -    Check 3 checkpoints already saved
2022-09-23 13:52:20,261 - trainer - INFO -    There are more than keep_ck_num as specified, then remove the oldest saved checkpoint
2022-09-23 13:52:20,261 - trainer - INFO -   Remove checkpoint model/mlp_carrier\ck_52
2022-09-23 13:52:20,262 - trainer - INFO -   Save checkpoint to model/mlp_carrier
2022-09-23 13:52:20,264 - trainer - INFO - save model to path: model/mlp_carrier
2022-09-23 13:52:20,264 - trainer - INFO -   no_improve_count: 0
2022-09-23 13:52:20,264 - trainer - INFO -   patience: 200
2022-09-23 13:52:20,265 - trainer - INFO -    Check 2 checkpoints already saved
2022-09-23 13:52:20,265 - trainer - INFO -   Save checkpoint to model/mlp_carrier\ck_58
2022-09-23 13:52:20,267 - trainer - INFO - save model to path: model/mlp_carrier\ck_58
2022-09-23 13:52:20,268 - trainer - INFO - 
*****************[epoch: 58, global step: 59] eval training set at end of epoch***************
2022-09-23 13:52:20,268 - trainer - INFO - {
  "train_loss": 20.352628707885742
}
2022-09-23 13:52:20,268 - trainer - INFO - start training epoch 59
2022-09-23 13:52:20,269 - trainer - INFO - training using device=cpu
2022-09-23 13:52:20,269 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:20,269 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:20,272 - trainer - INFO - 
*****************[epoch: 59, global step: 60] eval training set at end of epoch***************
2022-09-23 13:52:20,273 - trainer - INFO - {
  "train_loss": 17.577089309692383
}
2022-09-23 13:52:20,273 - trainer - INFO - start training epoch 60
2022-09-23 13:52:20,274 - trainer - INFO - training using device=cpu
2022-09-23 13:52:20,274 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:20,274 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:20,277 - trainer - INFO - 
*****************[epoch: 60, global step: 60] eval training set based on eval_every=2***************
2022-09-23 13:52:20,278 - trainer - INFO - {
  "train_loss": 18.654253005981445
}
2022-09-23 13:52:20,280 - trainer - INFO - 
*****************[epoch: 60, global step: 60] eval development set based on eval_every=2***************
2022-09-23 13:52:20,280 - trainer - INFO - {
  "dev_loss": 21.480363845825195,
  "dev_best_score_for_loss": -17.57708740234375
}
2022-09-23 13:52:20,280 - trainer - INFO -   no_improve_count: 1
2022-09-23 13:52:20,281 - trainer - INFO -   patience: 200
2022-09-23 13:52:20,282 - trainer - INFO -    Check 3 checkpoints already saved
2022-09-23 13:52:20,282 - trainer - INFO -    There are more than keep_ck_num as specified, then remove the oldest saved checkpoint
2022-09-23 13:52:20,282 - trainer - INFO -   Remove checkpoint model/mlp_carrier\ck_54
2022-09-23 13:52:20,283 - trainer - INFO -   Save checkpoint to model/mlp_carrier\ck_60
2022-09-23 13:52:20,286 - trainer - INFO - save model to path: model/mlp_carrier\ck_60
2022-09-23 13:52:20,287 - trainer - INFO - 
*****************[epoch: 60, global step: 61] eval training set at end of epoch***************
2022-09-23 13:52:20,287 - trainer - INFO - {
  "train_loss": 19.731416702270508
}
2022-09-23 13:52:20,287 - trainer - INFO - start training epoch 61
2022-09-23 13:52:20,288 - trainer - INFO - training using device=cpu
2022-09-23 13:52:20,288 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:20,288 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:20,292 - trainer - INFO - 
*****************[epoch: 61, global step: 62] eval training set at end of epoch***************
2022-09-23 13:52:20,292 - trainer - INFO - {
  "train_loss": 21.480363845825195
}
2022-09-23 13:52:20,293 - trainer - INFO - start training epoch 62
2022-09-23 13:52:20,293 - trainer - INFO - training using device=cpu
2022-09-23 13:52:20,293 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:20,293 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:20,297 - trainer - INFO - 
*****************[epoch: 62, global step: 62] eval training set based on eval_every=2***************
2022-09-23 13:52:20,297 - trainer - INFO - {
  "train_loss": 20.133041381835938
}
2022-09-23 13:52:20,299 - trainer - INFO - 
*****************[epoch: 62, global step: 62] eval development set based on eval_every=2***************
2022-09-23 13:52:20,299 - trainer - INFO - {
  "dev_loss": 14.735396385192871,
  "dev_best_score_for_loss": -14.735396385192871
}
2022-09-23 13:52:20,300 - trainer - INFO -    save the model with best score so far
2022-09-23 13:52:20,301 - trainer - INFO -    Check 3 checkpoints already saved
2022-09-23 13:52:20,301 - trainer - INFO -    There are more than keep_ck_num as specified, then remove the oldest saved checkpoint
2022-09-23 13:52:20,301 - trainer - INFO -   Remove checkpoint model/mlp_carrier\ck_56
2022-09-23 13:52:20,302 - trainer - INFO -   Save checkpoint to model/mlp_carrier
2022-09-23 13:52:20,304 - trainer - INFO - save model to path: model/mlp_carrier
2022-09-23 13:52:20,304 - trainer - INFO -   no_improve_count: 0
2022-09-23 13:52:20,305 - trainer - INFO -   patience: 200
2022-09-23 13:52:20,305 - trainer - INFO -    Check 2 checkpoints already saved
2022-09-23 13:52:20,305 - trainer - INFO -   Save checkpoint to model/mlp_carrier\ck_62
2022-09-23 13:52:20,308 - trainer - INFO - save model to path: model/mlp_carrier\ck_62
2022-09-23 13:52:20,309 - trainer - INFO - 
*****************[epoch: 62, global step: 63] eval training set at end of epoch***************
2022-09-23 13:52:20,309 - trainer - INFO - {
  "train_loss": 18.78571891784668
}
2022-09-23 13:52:20,310 - trainer - INFO - start training epoch 63
2022-09-23 13:52:20,310 - trainer - INFO - training using device=cpu
2022-09-23 13:52:20,310 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:20,310 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:20,314 - trainer - INFO - 
*****************[epoch: 63, global step: 64] eval training set at end of epoch***************
2022-09-23 13:52:20,314 - trainer - INFO - {
  "train_loss": 14.735397338867188
}
2022-09-23 13:52:20,315 - trainer - INFO - start training epoch 64
2022-09-23 13:52:20,315 - trainer - INFO - training using device=cpu
2022-09-23 13:52:20,315 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:20,315 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:20,318 - trainer - INFO - 
*****************[epoch: 64, global step: 64] eval training set based on eval_every=2***************
2022-09-23 13:52:20,319 - trainer - INFO - {
  "train_loss": 14.301602840423584
}
2022-09-23 13:52:20,321 - trainer - INFO - 
*****************[epoch: 64, global step: 64] eval development set based on eval_every=2***************
2022-09-23 13:52:20,321 - trainer - INFO - {
  "dev_loss": 15.412384033203125,
  "dev_best_score_for_loss": -14.735396385192871
}
2022-09-23 13:52:20,322 - trainer - INFO -   no_improve_count: 1
2022-09-23 13:52:20,322 - trainer - INFO -   patience: 200
2022-09-23 13:52:20,323 - trainer - INFO -    Check 3 checkpoints already saved
2022-09-23 13:52:20,323 - trainer - INFO -    There are more than keep_ck_num as specified, then remove the oldest saved checkpoint
2022-09-23 13:52:20,323 - trainer - INFO -   Remove checkpoint model/mlp_carrier\ck_58
2022-09-23 13:52:20,324 - trainer - INFO -   Save checkpoint to model/mlp_carrier\ck_64
2022-09-23 13:52:20,329 - trainer - INFO - save model to path: model/mlp_carrier\ck_64
2022-09-23 13:52:20,330 - trainer - INFO - 
*****************[epoch: 64, global step: 65] eval training set at end of epoch***************
2022-09-23 13:52:20,330 - trainer - INFO - {
  "train_loss": 13.86780834197998
}
2022-09-23 13:52:20,330 - trainer - INFO - start training epoch 65
2022-09-23 13:52:20,331 - trainer - INFO - training using device=cpu
2022-09-23 13:52:20,331 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:20,331 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:20,336 - trainer - INFO - 
*****************[epoch: 65, global step: 66] eval training set at end of epoch***************
2022-09-23 13:52:20,336 - trainer - INFO - {
  "train_loss": 15.412383079528809
}
2022-09-23 13:52:20,336 - trainer - INFO - start training epoch 66
2022-09-23 13:52:20,337 - trainer - INFO - training using device=cpu
2022-09-23 13:52:20,337 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:20,337 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:20,341 - trainer - INFO - 
*****************[epoch: 66, global step: 66] eval training set based on eval_every=2***************
2022-09-23 13:52:20,342 - trainer - INFO - {
  "train_loss": 15.42719554901123
}
2022-09-23 13:52:20,345 - trainer - INFO - 
*****************[epoch: 66, global step: 66] eval development set based on eval_every=2***************
2022-09-23 13:52:20,345 - trainer - INFO - {
  "dev_loss": 12.893898963928223,
  "dev_best_score_for_loss": -12.893898963928223
}
2022-09-23 13:52:20,346 - trainer - INFO -    save the model with best score so far
2022-09-23 13:52:20,347 - trainer - INFO -    Check 3 checkpoints already saved
2022-09-23 13:52:20,347 - trainer - INFO -    There are more than keep_ck_num as specified, then remove the oldest saved checkpoint
2022-09-23 13:52:20,347 - trainer - INFO -   Remove checkpoint model/mlp_carrier\ck_60
2022-09-23 13:52:20,349 - trainer - INFO -   Save checkpoint to model/mlp_carrier
2022-09-23 13:52:20,351 - trainer - INFO - save model to path: model/mlp_carrier
2022-09-23 13:52:20,351 - trainer - INFO -   no_improve_count: 0
2022-09-23 13:52:20,351 - trainer - INFO -   patience: 200
2022-09-23 13:52:20,352 - trainer - INFO -    Check 2 checkpoints already saved
2022-09-23 13:52:20,352 - trainer - INFO -   Save checkpoint to model/mlp_carrier\ck_66
2022-09-23 13:52:20,356 - trainer - INFO - save model to path: model/mlp_carrier\ck_66
2022-09-23 13:52:20,357 - trainer - INFO - 
*****************[epoch: 66, global step: 67] eval training set at end of epoch***************
2022-09-23 13:52:20,357 - trainer - INFO - {
  "train_loss": 15.442008018493652
}
2022-09-23 13:52:20,357 - trainer - INFO - start training epoch 67
2022-09-23 13:52:20,357 - trainer - INFO - training using device=cpu
2022-09-23 13:52:20,358 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:20,358 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:20,362 - trainer - INFO - 
*****************[epoch: 67, global step: 68] eval training set at end of epoch***************
2022-09-23 13:52:20,362 - trainer - INFO - {
  "train_loss": 12.893898010253906
}
2022-09-23 13:52:20,363 - trainer - INFO - start training epoch 68
2022-09-23 13:52:20,363 - trainer - INFO - training using device=cpu
2022-09-23 13:52:20,363 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:20,363 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:20,367 - trainer - INFO - 
*****************[epoch: 68, global step: 68] eval training set based on eval_every=2***************
2022-09-23 13:52:20,367 - trainer - INFO - {
  "train_loss": 11.742702960968018
}
2022-09-23 13:52:20,370 - trainer - INFO - 
*****************[epoch: 68, global step: 68] eval development set based on eval_every=2***************
2022-09-23 13:52:20,371 - trainer - INFO - {
  "dev_loss": 10.682861328125,
  "dev_best_score_for_loss": -10.682861328125
}
2022-09-23 13:52:20,371 - trainer - INFO -    save the model with best score so far
2022-09-23 13:52:20,373 - trainer - INFO -    Check 3 checkpoints already saved
2022-09-23 13:52:20,373 - trainer - INFO -    There are more than keep_ck_num as specified, then remove the oldest saved checkpoint
2022-09-23 13:52:20,373 - trainer - INFO -   Remove checkpoint model/mlp_carrier\ck_62
2022-09-23 13:52:20,374 - trainer - INFO -   Save checkpoint to model/mlp_carrier
2022-09-23 13:52:20,377 - trainer - INFO - save model to path: model/mlp_carrier
2022-09-23 13:52:20,377 - trainer - INFO -   no_improve_count: 0
2022-09-23 13:52:20,377 - trainer - INFO -   patience: 200
2022-09-23 13:52:20,378 - trainer - INFO -    Check 2 checkpoints already saved
2022-09-23 13:52:20,378 - trainer - INFO -   Save checkpoint to model/mlp_carrier\ck_68
2022-09-23 13:52:20,381 - trainer - INFO - save model to path: model/mlp_carrier\ck_68
2022-09-23 13:52:20,382 - trainer - INFO - 
*****************[epoch: 68, global step: 69] eval training set at end of epoch***************
2022-09-23 13:52:20,382 - trainer - INFO - {
  "train_loss": 10.591507911682129
}
2022-09-23 13:52:20,383 - trainer - INFO - start training epoch 69
2022-09-23 13:52:20,383 - trainer - INFO - training using device=cpu
2022-09-23 13:52:20,383 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:20,383 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:20,387 - trainer - INFO - 
*****************[epoch: 69, global step: 70] eval training set at end of epoch***************
2022-09-23 13:52:20,388 - trainer - INFO - {
  "train_loss": 10.682862281799316
}
2022-09-23 13:52:20,388 - trainer - INFO - start training epoch 70
2022-09-23 13:52:20,389 - trainer - INFO - training using device=cpu
2022-09-23 13:52:20,389 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:20,389 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:20,393 - trainer - INFO - 
*****************[epoch: 70, global step: 70] eval training set based on eval_every=2***************
2022-09-23 13:52:20,393 - trainer - INFO - {
  "train_loss": 11.06823205947876
}
2022-09-23 13:52:20,395 - trainer - INFO - 
*****************[epoch: 70, global step: 70] eval development set based on eval_every=2***************
2022-09-23 13:52:20,395 - trainer - INFO - {
  "dev_loss": 10.403717994689941,
  "dev_best_score_for_loss": -10.403717994689941
}
2022-09-23 13:52:20,396 - trainer - INFO -    save the model with best score so far
2022-09-23 13:52:20,397 - trainer - INFO -    Check 3 checkpoints already saved
2022-09-23 13:52:20,397 - trainer - INFO -    There are more than keep_ck_num as specified, then remove the oldest saved checkpoint
2022-09-23 13:52:20,397 - trainer - INFO -   Remove checkpoint model/mlp_carrier\ck_64
2022-09-23 13:52:20,398 - trainer - INFO -   Save checkpoint to model/mlp_carrier
2022-09-23 13:52:20,400 - trainer - INFO - save model to path: model/mlp_carrier
2022-09-23 13:52:20,400 - trainer - INFO -   no_improve_count: 0
2022-09-23 13:52:20,400 - trainer - INFO -   patience: 200
2022-09-23 13:52:20,401 - trainer - INFO -    Check 2 checkpoints already saved
2022-09-23 13:52:20,401 - trainer - INFO -   Save checkpoint to model/mlp_carrier\ck_70
2022-09-23 13:52:20,404 - trainer - INFO - save model to path: model/mlp_carrier\ck_70
2022-09-23 13:52:20,405 - trainer - INFO - 
*****************[epoch: 70, global step: 71] eval training set at end of epoch***************
2022-09-23 13:52:20,405 - trainer - INFO - {
  "train_loss": 11.453601837158203
}
2022-09-23 13:52:20,405 - trainer - INFO - start training epoch 71
2022-09-23 13:52:20,406 - trainer - INFO - training using device=cpu
2022-09-23 13:52:20,406 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:20,406 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:20,411 - trainer - INFO - 
*****************[epoch: 71, global step: 72] eval training set at end of epoch***************
2022-09-23 13:52:20,411 - trainer - INFO - {
  "train_loss": 10.403717994689941
}
2022-09-23 13:52:20,411 - trainer - INFO - start training epoch 72
2022-09-23 13:52:20,412 - trainer - INFO - training using device=cpu
2022-09-23 13:52:20,412 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:20,412 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:20,416 - trainer - INFO - 
*****************[epoch: 72, global step: 72] eval training set based on eval_every=2***************
2022-09-23 13:52:20,417 - trainer - INFO - {
  "train_loss": 9.379880905151367
}
2022-09-23 13:52:20,419 - trainer - INFO - 
*****************[epoch: 72, global step: 72] eval development set based on eval_every=2***************
2022-09-23 13:52:20,419 - trainer - INFO - {
  "dev_loss": 7.631161212921143,
  "dev_best_score_for_loss": -7.631161212921143
}
2022-09-23 13:52:20,420 - trainer - INFO -    save the model with best score so far
2022-09-23 13:52:20,421 - trainer - INFO -    Check 3 checkpoints already saved
2022-09-23 13:52:20,421 - trainer - INFO -    There are more than keep_ck_num as specified, then remove the oldest saved checkpoint
2022-09-23 13:52:20,421 - trainer - INFO -   Remove checkpoint model/mlp_carrier\ck_66
2022-09-23 13:52:20,423 - trainer - INFO -   Save checkpoint to model/mlp_carrier
2022-09-23 13:52:20,425 - trainer - INFO - save model to path: model/mlp_carrier
2022-09-23 13:52:20,425 - trainer - INFO -   no_improve_count: 0
2022-09-23 13:52:20,425 - trainer - INFO -   patience: 200
2022-09-23 13:52:20,426 - trainer - INFO -    Check 2 checkpoints already saved
2022-09-23 13:52:20,426 - trainer - INFO -   Save checkpoint to model/mlp_carrier\ck_72
2022-09-23 13:52:20,428 - trainer - INFO - save model to path: model/mlp_carrier\ck_72
2022-09-23 13:52:20,429 - trainer - INFO - 
*****************[epoch: 72, global step: 73] eval training set at end of epoch***************
2022-09-23 13:52:20,429 - trainer - INFO - {
  "train_loss": 8.356043815612793
}
2022-09-23 13:52:20,429 - trainer - INFO - start training epoch 73
2022-09-23 13:52:20,430 - trainer - INFO - training using device=cpu
2022-09-23 13:52:20,430 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:20,430 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:20,433 - trainer - INFO - 
*****************[epoch: 73, global step: 74] eval training set at end of epoch***************
2022-09-23 13:52:20,434 - trainer - INFO - {
  "train_loss": 7.631162166595459
}
2022-09-23 13:52:20,434 - trainer - INFO - start training epoch 74
2022-09-23 13:52:20,434 - trainer - INFO - training using device=cpu
2022-09-23 13:52:20,435 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:20,435 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:20,438 - trainer - INFO - 
*****************[epoch: 74, global step: 74] eval training set based on eval_every=2***************
2022-09-23 13:52:20,439 - trainer - INFO - {
  "train_loss": 7.868385553359985
}
2022-09-23 13:52:20,441 - trainer - INFO - 
*****************[epoch: 74, global step: 74] eval development set based on eval_every=2***************
2022-09-23 13:52:20,442 - trainer - INFO - {
  "dev_loss": 7.84975004196167,
  "dev_best_score_for_loss": -7.631161212921143
}
2022-09-23 13:52:20,442 - trainer - INFO -   no_improve_count: 1
2022-09-23 13:52:20,443 - trainer - INFO -   patience: 200
2022-09-23 13:52:20,443 - trainer - INFO -    Check 3 checkpoints already saved
2022-09-23 13:52:20,444 - trainer - INFO -    There are more than keep_ck_num as specified, then remove the oldest saved checkpoint
2022-09-23 13:52:20,444 - trainer - INFO -   Remove checkpoint model/mlp_carrier\ck_68
2022-09-23 13:52:20,445 - trainer - INFO -   Save checkpoint to model/mlp_carrier\ck_74
2022-09-23 13:52:20,448 - trainer - INFO - save model to path: model/mlp_carrier\ck_74
2022-09-23 13:52:20,448 - trainer - INFO - 
*****************[epoch: 74, global step: 75] eval training set at end of epoch***************
2022-09-23 13:52:20,449 - trainer - INFO - {
  "train_loss": 8.105608940124512
}
2022-09-23 13:52:20,449 - trainer - INFO - start training epoch 75
2022-09-23 13:52:20,449 - trainer - INFO - training using device=cpu
2022-09-23 13:52:20,449 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:20,450 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:20,453 - trainer - INFO - 
*****************[epoch: 75, global step: 76] eval training set at end of epoch***************
2022-09-23 13:52:20,453 - trainer - INFO - {
  "train_loss": 7.84975004196167
}
2022-09-23 13:52:20,454 - trainer - INFO - start training epoch 76
2022-09-23 13:52:20,454 - trainer - INFO - training using device=cpu
2022-09-23 13:52:20,454 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:20,455 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:20,458 - trainer - INFO - 
*****************[epoch: 76, global step: 76] eval training set based on eval_every=2***************
2022-09-23 13:52:20,458 - trainer - INFO - {
  "train_loss": 7.155666828155518
}
2022-09-23 13:52:20,460 - trainer - INFO - 
*****************[epoch: 76, global step: 76] eval development set based on eval_every=2***************
2022-09-23 13:52:20,460 - trainer - INFO - {
  "dev_loss": 5.466304779052734,
  "dev_best_score_for_loss": -5.466304779052734
}
2022-09-23 13:52:20,461 - trainer - INFO -    save the model with best score so far
2022-09-23 13:52:20,462 - trainer - INFO -    Check 3 checkpoints already saved
2022-09-23 13:52:20,462 - trainer - INFO -    There are more than keep_ck_num as specified, then remove the oldest saved checkpoint
2022-09-23 13:52:20,462 - trainer - INFO -   Remove checkpoint model/mlp_carrier\ck_70
2022-09-23 13:52:20,463 - trainer - INFO -   Save checkpoint to model/mlp_carrier
2022-09-23 13:52:20,465 - trainer - INFO - save model to path: model/mlp_carrier
2022-09-23 13:52:20,466 - trainer - INFO -   no_improve_count: 0
2022-09-23 13:52:20,466 - trainer - INFO -   patience: 200
2022-09-23 13:52:20,467 - trainer - INFO -    Check 2 checkpoints already saved
2022-09-23 13:52:20,467 - trainer - INFO -   Save checkpoint to model/mlp_carrier\ck_76
2022-09-23 13:52:20,469 - trainer - INFO - save model to path: model/mlp_carrier\ck_76
2022-09-23 13:52:20,470 - trainer - INFO - 
*****************[epoch: 76, global step: 77] eval training set at end of epoch***************
2022-09-23 13:52:20,470 - trainer - INFO - {
  "train_loss": 6.461583614349365
}
2022-09-23 13:52:20,471 - trainer - INFO - start training epoch 77
2022-09-23 13:52:20,471 - trainer - INFO - training using device=cpu
2022-09-23 13:52:20,471 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:20,471 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:20,475 - trainer - INFO - 
*****************[epoch: 77, global step: 78] eval training set at end of epoch***************
2022-09-23 13:52:20,475 - trainer - INFO - {
  "train_loss": 5.466304302215576
}
2022-09-23 13:52:20,475 - trainer - INFO - start training epoch 78
2022-09-23 13:52:20,476 - trainer - INFO - training using device=cpu
2022-09-23 13:52:20,476 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:20,476 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:20,479 - trainer - INFO - 
*****************[epoch: 78, global step: 78] eval training set based on eval_every=2***************
2022-09-23 13:52:20,480 - trainer - INFO - {
  "train_loss": 5.522160530090332
}
2022-09-23 13:52:20,482 - trainer - INFO - 
*****************[epoch: 78, global step: 78] eval development set based on eval_every=2***************
2022-09-23 13:52:20,482 - trainer - INFO - {
  "dev_loss": 5.594963073730469,
  "dev_best_score_for_loss": -5.466304779052734
}
2022-09-23 13:52:20,482 - trainer - INFO -   no_improve_count: 1
2022-09-23 13:52:20,483 - trainer - INFO -   patience: 200
2022-09-23 13:52:20,484 - trainer - INFO -    Check 3 checkpoints already saved
2022-09-23 13:52:20,484 - trainer - INFO -    There are more than keep_ck_num as specified, then remove the oldest saved checkpoint
2022-09-23 13:52:20,484 - trainer - INFO -   Remove checkpoint model/mlp_carrier\ck_72
2022-09-23 13:52:20,485 - trainer - INFO -   Save checkpoint to model/mlp_carrier\ck_78
2022-09-23 13:52:20,487 - trainer - INFO - save model to path: model/mlp_carrier\ck_78
2022-09-23 13:52:20,488 - trainer - INFO - 
*****************[epoch: 78, global step: 79] eval training set at end of epoch***************
2022-09-23 13:52:20,488 - trainer - INFO - {
  "train_loss": 5.578016757965088
}
2022-09-23 13:52:20,489 - trainer - INFO - start training epoch 79
2022-09-23 13:52:20,489 - trainer - INFO - training using device=cpu
2022-09-23 13:52:20,489 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:20,490 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:20,493 - trainer - INFO - 
*****************[epoch: 79, global step: 80] eval training set at end of epoch***************
2022-09-23 13:52:20,493 - trainer - INFO - {
  "train_loss": 5.594963073730469
}
2022-09-23 13:52:20,494 - trainer - INFO - start training epoch 80
2022-09-23 13:52:20,494 - trainer - INFO - training using device=cpu
2022-09-23 13:52:20,495 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:20,495 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:20,498 - trainer - INFO - 
*****************[epoch: 80, global step: 80] eval training set based on eval_every=2***************
2022-09-23 13:52:20,498 - trainer - INFO - {
  "train_loss": 5.151559352874756
}
2022-09-23 13:52:20,501 - trainer - INFO - 
*****************[epoch: 80, global step: 80] eval development set based on eval_every=2***************
2022-09-23 13:52:20,501 - trainer - INFO - {
  "dev_loss": 3.8584349155426025,
  "dev_best_score_for_loss": -3.8584349155426025
}
2022-09-23 13:52:20,501 - trainer - INFO -    save the model with best score so far
2022-09-23 13:52:20,502 - trainer - INFO -    Check 3 checkpoints already saved
2022-09-23 13:52:20,503 - trainer - INFO -    There are more than keep_ck_num as specified, then remove the oldest saved checkpoint
2022-09-23 13:52:20,503 - trainer - INFO -   Remove checkpoint model/mlp_carrier\ck_74
2022-09-23 13:52:20,504 - trainer - INFO -   Save checkpoint to model/mlp_carrier
2022-09-23 13:52:20,506 - trainer - INFO - save model to path: model/mlp_carrier
2022-09-23 13:52:20,506 - trainer - INFO -   no_improve_count: 0
2022-09-23 13:52:20,506 - trainer - INFO -   patience: 200
2022-09-23 13:52:20,507 - trainer - INFO -    Check 2 checkpoints already saved
2022-09-23 13:52:20,507 - trainer - INFO -   Save checkpoint to model/mlp_carrier\ck_80
2022-09-23 13:52:20,510 - trainer - INFO - save model to path: model/mlp_carrier\ck_80
2022-09-23 13:52:20,511 - trainer - INFO - 
*****************[epoch: 80, global step: 81] eval training set at end of epoch***************
2022-09-23 13:52:20,511 - trainer - INFO - {
  "train_loss": 4.708155632019043
}
2022-09-23 13:52:20,512 - trainer - INFO - start training epoch 81
2022-09-23 13:52:20,512 - trainer - INFO - training using device=cpu
2022-09-23 13:52:20,512 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:20,513 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:20,516 - trainer - INFO - 
*****************[epoch: 81, global step: 82] eval training set at end of epoch***************
2022-09-23 13:52:20,516 - trainer - INFO - {
  "train_loss": 3.8584349155426025
}
2022-09-23 13:52:20,517 - trainer - INFO - start training epoch 82
2022-09-23 13:52:20,517 - trainer - INFO - training using device=cpu
2022-09-23 13:52:20,517 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:20,518 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:20,521 - trainer - INFO - 
*****************[epoch: 82, global step: 82] eval training set based on eval_every=2***************
2022-09-23 13:52:20,521 - trainer - INFO - {
  "train_loss": 3.8368427753448486
}
2022-09-23 13:52:20,523 - trainer - INFO - 
*****************[epoch: 82, global step: 82] eval development set based on eval_every=2***************
2022-09-23 13:52:20,524 - trainer - INFO - {
  "dev_loss": 3.866122245788574,
  "dev_best_score_for_loss": -3.8584349155426025
}
2022-09-23 13:52:20,524 - trainer - INFO -   no_improve_count: 1
2022-09-23 13:52:20,525 - trainer - INFO -   patience: 200
2022-09-23 13:52:20,526 - trainer - INFO -    Check 3 checkpoints already saved
2022-09-23 13:52:20,526 - trainer - INFO -    There are more than keep_ck_num as specified, then remove the oldest saved checkpoint
2022-09-23 13:52:20,526 - trainer - INFO -   Remove checkpoint model/mlp_carrier\ck_76
2022-09-23 13:52:20,528 - trainer - INFO -   Save checkpoint to model/mlp_carrier\ck_82
2022-09-23 13:52:20,531 - trainer - INFO - save model to path: model/mlp_carrier\ck_82
2022-09-23 13:52:20,531 - trainer - INFO - 
*****************[epoch: 82, global step: 83] eval training set at end of epoch***************
2022-09-23 13:52:20,532 - trainer - INFO - {
  "train_loss": 3.8152506351470947
}
2022-09-23 13:52:20,532 - trainer - INFO - start training epoch 83
2022-09-23 13:52:20,532 - trainer - INFO - training using device=cpu
2022-09-23 13:52:20,532 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:20,533 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:20,537 - trainer - INFO - 
*****************[epoch: 83, global step: 84] eval training set at end of epoch***************
2022-09-23 13:52:20,538 - trainer - INFO - {
  "train_loss": 3.8661224842071533
}
2022-09-23 13:52:20,538 - trainer - INFO - start training epoch 84
2022-09-23 13:52:20,538 - trainer - INFO - training using device=cpu
2022-09-23 13:52:20,539 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:20,539 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:20,543 - trainer - INFO - 
*****************[epoch: 84, global step: 84] eval training set based on eval_every=2***************
2022-09-23 13:52:20,544 - trainer - INFO - {
  "train_loss": 3.584648609161377
}
2022-09-23 13:52:20,546 - trainer - INFO - 
*****************[epoch: 84, global step: 84] eval development set based on eval_every=2***************
2022-09-23 13:52:20,546 - trainer - INFO - {
  "dev_loss": 2.6577835083007812,
  "dev_best_score_for_loss": -2.6577835083007812
}
2022-09-23 13:52:20,547 - trainer - INFO -    save the model with best score so far
2022-09-23 13:52:20,548 - trainer - INFO -    Check 3 checkpoints already saved
2022-09-23 13:52:20,548 - trainer - INFO -    There are more than keep_ck_num as specified, then remove the oldest saved checkpoint
2022-09-23 13:52:20,549 - trainer - INFO -   Remove checkpoint model/mlp_carrier\ck_78
2022-09-23 13:52:20,550 - trainer - INFO -   Save checkpoint to model/mlp_carrier
2022-09-23 13:52:20,553 - trainer - INFO - save model to path: model/mlp_carrier
2022-09-23 13:52:20,553 - trainer - INFO -   no_improve_count: 0
2022-09-23 13:52:20,553 - trainer - INFO -   patience: 200
2022-09-23 13:52:20,554 - trainer - INFO -    Check 2 checkpoints already saved
2022-09-23 13:52:20,554 - trainer - INFO -   Save checkpoint to model/mlp_carrier\ck_84
2022-09-23 13:52:20,557 - trainer - INFO - save model to path: model/mlp_carrier\ck_84
2022-09-23 13:52:20,558 - trainer - INFO - 
*****************[epoch: 84, global step: 85] eval training set at end of epoch***************
2022-09-23 13:52:20,558 - trainer - INFO - {
  "train_loss": 3.3031747341156006
}
2022-09-23 13:52:20,559 - trainer - INFO - start training epoch 85
2022-09-23 13:52:20,559 - trainer - INFO - training using device=cpu
2022-09-23 13:52:20,559 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:20,560 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:20,563 - trainer - INFO - 
*****************[epoch: 85, global step: 86] eval training set at end of epoch***************
2022-09-23 13:52:20,563 - trainer - INFO - {
  "train_loss": 2.657783031463623
}
2022-09-23 13:52:20,564 - trainer - INFO - start training epoch 86
2022-09-23 13:52:20,564 - trainer - INFO - training using device=cpu
2022-09-23 13:52:20,564 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:20,564 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:20,568 - trainer - INFO - 
*****************[epoch: 86, global step: 86] eval training set based on eval_every=2***************
2022-09-23 13:52:20,568 - trainer - INFO - {
  "train_loss": 2.615309000015259
}
2022-09-23 13:52:20,572 - trainer - INFO - 
*****************[epoch: 86, global step: 86] eval development set based on eval_every=2***************
2022-09-23 13:52:20,572 - trainer - INFO - {
  "dev_loss": 2.6173250675201416,
  "dev_best_score_for_loss": -2.6173250675201416
}
2022-09-23 13:52:20,573 - trainer - INFO -    save the model with best score so far
2022-09-23 13:52:20,574 - trainer - INFO -    Check 3 checkpoints already saved
2022-09-23 13:52:20,574 - trainer - INFO -    There are more than keep_ck_num as specified, then remove the oldest saved checkpoint
2022-09-23 13:52:20,574 - trainer - INFO -   Remove checkpoint model/mlp_carrier\ck_80
2022-09-23 13:52:20,576 - trainer - INFO -   Save checkpoint to model/mlp_carrier
2022-09-23 13:52:20,578 - trainer - INFO - save model to path: model/mlp_carrier
2022-09-23 13:52:20,578 - trainer - INFO -   no_improve_count: 0
2022-09-23 13:52:20,579 - trainer - INFO -   patience: 200
2022-09-23 13:52:20,580 - trainer - INFO -    Check 2 checkpoints already saved
2022-09-23 13:52:20,580 - trainer - INFO -   Save checkpoint to model/mlp_carrier\ck_86
2022-09-23 13:52:20,583 - trainer - INFO - save model to path: model/mlp_carrier\ck_86
2022-09-23 13:52:20,584 - trainer - INFO - 
*****************[epoch: 86, global step: 87] eval training set at end of epoch***************
2022-09-23 13:52:20,584 - trainer - INFO - {
  "train_loss": 2.5728349685668945
}
2022-09-23 13:52:20,585 - trainer - INFO - start training epoch 87
2022-09-23 13:52:20,585 - trainer - INFO - training using device=cpu
2022-09-23 13:52:20,585 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:20,585 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:20,590 - trainer - INFO - 
*****************[epoch: 87, global step: 88] eval training set at end of epoch***************
2022-09-23 13:52:20,590 - trainer - INFO - {
  "train_loss": 2.6173250675201416
}
2022-09-23 13:52:20,590 - trainer - INFO - start training epoch 88
2022-09-23 13:52:20,591 - trainer - INFO - training using device=cpu
2022-09-23 13:52:20,591 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:20,591 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:20,594 - trainer - INFO - 
*****************[epoch: 88, global step: 88] eval training set based on eval_every=2***************
2022-09-23 13:52:20,595 - trainer - INFO - {
  "train_loss": 2.4246232509613037
}
2022-09-23 13:52:20,597 - trainer - INFO - 
*****************[epoch: 88, global step: 88] eval development set based on eval_every=2***************
2022-09-23 13:52:20,597 - trainer - INFO - {
  "dev_loss": 1.8079733848571777,
  "dev_best_score_for_loss": -1.8079733848571777
}
2022-09-23 13:52:20,598 - trainer - INFO -    save the model with best score so far
2022-09-23 13:52:20,599 - trainer - INFO -    Check 3 checkpoints already saved
2022-09-23 13:52:20,599 - trainer - INFO -    There are more than keep_ck_num as specified, then remove the oldest saved checkpoint
2022-09-23 13:52:20,599 - trainer - INFO -   Remove checkpoint model/mlp_carrier\ck_82
2022-09-23 13:52:20,600 - trainer - INFO -   Save checkpoint to model/mlp_carrier
2022-09-23 13:52:20,603 - trainer - INFO - save model to path: model/mlp_carrier
2022-09-23 13:52:20,603 - trainer - INFO -   no_improve_count: 0
2022-09-23 13:52:20,603 - trainer - INFO -   patience: 200
2022-09-23 13:52:20,604 - trainer - INFO -    Check 2 checkpoints already saved
2022-09-23 13:52:20,604 - trainer - INFO -   Save checkpoint to model/mlp_carrier\ck_88
2022-09-23 13:52:20,607 - trainer - INFO - save model to path: model/mlp_carrier\ck_88
2022-09-23 13:52:20,607 - trainer - INFO - 
*****************[epoch: 88, global step: 89] eval training set at end of epoch***************
2022-09-23 13:52:20,608 - trainer - INFO - {
  "train_loss": 2.231921434402466
}
2022-09-23 13:52:20,608 - trainer - INFO - start training epoch 89
2022-09-23 13:52:20,608 - trainer - INFO - training using device=cpu
2022-09-23 13:52:20,608 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:20,609 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:20,612 - trainer - INFO - 
*****************[epoch: 89, global step: 90] eval training set at end of epoch***************
2022-09-23 13:52:20,613 - trainer - INFO - {
  "train_loss": 1.8079733848571777
}
2022-09-23 13:52:20,613 - trainer - INFO - start training epoch 90
2022-09-23 13:52:20,613 - trainer - INFO - training using device=cpu
2022-09-23 13:52:20,614 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:20,614 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:20,617 - trainer - INFO - 
*****************[epoch: 90, global step: 90] eval training set based on eval_every=2***************
2022-09-23 13:52:20,617 - trainer - INFO - {
  "train_loss": 1.7906468510627747
}
2022-09-23 13:52:20,619 - trainer - INFO - 
*****************[epoch: 90, global step: 90] eval development set based on eval_every=2***************
2022-09-23 13:52:20,620 - trainer - INFO - {
  "dev_loss": 1.7961446046829224,
  "dev_best_score_for_loss": -1.7961446046829224
}
2022-09-23 13:52:20,620 - trainer - INFO -    save the model with best score so far
2022-09-23 13:52:20,621 - trainer - INFO -    Check 3 checkpoints already saved
2022-09-23 13:52:20,621 - trainer - INFO -    There are more than keep_ck_num as specified, then remove the oldest saved checkpoint
2022-09-23 13:52:20,621 - trainer - INFO -   Remove checkpoint model/mlp_carrier\ck_84
2022-09-23 13:52:20,622 - trainer - INFO -   Save checkpoint to model/mlp_carrier
2022-09-23 13:52:20,624 - trainer - INFO - save model to path: model/mlp_carrier
2022-09-23 13:52:20,625 - trainer - INFO -   no_improve_count: 0
2022-09-23 13:52:20,625 - trainer - INFO -   patience: 200
2022-09-23 13:52:20,626 - trainer - INFO -    Check 2 checkpoints already saved
2022-09-23 13:52:20,626 - trainer - INFO -   Save checkpoint to model/mlp_carrier\ck_90
2022-09-23 13:52:20,628 - trainer - INFO - save model to path: model/mlp_carrier\ck_90
2022-09-23 13:52:20,629 - trainer - INFO - 
*****************[epoch: 90, global step: 91] eval training set at end of epoch***************
2022-09-23 13:52:20,630 - trainer - INFO - {
  "train_loss": 1.7733203172683716
}
2022-09-23 13:52:20,630 - trainer - INFO - start training epoch 91
2022-09-23 13:52:20,630 - trainer - INFO - training using device=cpu
2022-09-23 13:52:20,630 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:20,631 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:20,634 - trainer - INFO - 
*****************[epoch: 91, global step: 92] eval training set at end of epoch***************
2022-09-23 13:52:20,635 - trainer - INFO - {
  "train_loss": 1.7961444854736328
}
2022-09-23 13:52:20,635 - trainer - INFO - start training epoch 92
2022-09-23 13:52:20,635 - trainer - INFO - training using device=cpu
2022-09-23 13:52:20,636 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:20,636 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:20,639 - trainer - INFO - 
*****************[epoch: 92, global step: 92] eval training set based on eval_every=2***************
2022-09-23 13:52:20,640 - trainer - INFO - {
  "train_loss": 1.6664771437644958
}
2022-09-23 13:52:20,642 - trainer - INFO - 
*****************[epoch: 92, global step: 92] eval development set based on eval_every=2***************
2022-09-23 13:52:20,643 - trainer - INFO - {
  "dev_loss": 1.268151879310608,
  "dev_best_score_for_loss": -1.268151879310608
}
2022-09-23 13:52:20,643 - trainer - INFO -    save the model with best score so far
2022-09-23 13:52:20,644 - trainer - INFO -    Check 3 checkpoints already saved
2022-09-23 13:52:20,644 - trainer - INFO -    There are more than keep_ck_num as specified, then remove the oldest saved checkpoint
2022-09-23 13:52:20,645 - trainer - INFO -   Remove checkpoint model/mlp_carrier\ck_86
2022-09-23 13:52:20,646 - trainer - INFO -   Save checkpoint to model/mlp_carrier
2022-09-23 13:52:20,648 - trainer - INFO - save model to path: model/mlp_carrier
2022-09-23 13:52:20,648 - trainer - INFO -   no_improve_count: 0
2022-09-23 13:52:20,648 - trainer - INFO -   patience: 200
2022-09-23 13:52:20,649 - trainer - INFO -    Check 2 checkpoints already saved
2022-09-23 13:52:20,649 - trainer - INFO -   Save checkpoint to model/mlp_carrier\ck_92
2022-09-23 13:52:20,651 - trainer - INFO - save model to path: model/mlp_carrier\ck_92
2022-09-23 13:52:20,652 - trainer - INFO - 
*****************[epoch: 92, global step: 93] eval training set at end of epoch***************
2022-09-23 13:52:20,652 - trainer - INFO - {
  "train_loss": 1.5368098020553589
}
2022-09-23 13:52:20,652 - trainer - INFO - start training epoch 93
2022-09-23 13:52:20,653 - trainer - INFO - training using device=cpu
2022-09-23 13:52:20,653 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:20,653 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:20,657 - trainer - INFO - 
*****************[epoch: 93, global step: 94] eval training set at end of epoch***************
2022-09-23 13:52:20,657 - trainer - INFO - {
  "train_loss": 1.268151879310608
}
2022-09-23 13:52:20,657 - trainer - INFO - start training epoch 94
2022-09-23 13:52:20,657 - trainer - INFO - training using device=cpu
2022-09-23 13:52:20,658 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:20,659 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:20,663 - trainer - INFO - 
*****************[epoch: 94, global step: 94] eval training set based on eval_every=2***************
2022-09-23 13:52:20,664 - trainer - INFO - {
  "train_loss": 1.2673754692077637
}
2022-09-23 13:52:20,666 - trainer - INFO - 
*****************[epoch: 94, global step: 94] eval development set based on eval_every=2***************
2022-09-23 13:52:20,667 - trainer - INFO - {
  "dev_loss": 1.2828662395477295,
  "dev_best_score_for_loss": -1.268151879310608
}
2022-09-23 13:52:20,667 - trainer - INFO -   no_improve_count: 1
2022-09-23 13:52:20,668 - trainer - INFO -   patience: 200
2022-09-23 13:52:20,669 - trainer - INFO -    Check 3 checkpoints already saved
2022-09-23 13:52:20,669 - trainer - INFO -    There are more than keep_ck_num as specified, then remove the oldest saved checkpoint
2022-09-23 13:52:20,669 - trainer - INFO -   Remove checkpoint model/mlp_carrier\ck_88
2022-09-23 13:52:20,671 - trainer - INFO -   Save checkpoint to model/mlp_carrier\ck_94
2022-09-23 13:52:20,674 - trainer - INFO - save model to path: model/mlp_carrier\ck_94
2022-09-23 13:52:20,675 - trainer - INFO - 
*****************[epoch: 94, global step: 95] eval training set at end of epoch***************
2022-09-23 13:52:20,675 - trainer - INFO - {
  "train_loss": 1.2665990591049194
}
2022-09-23 13:52:20,676 - trainer - INFO - start training epoch 95
2022-09-23 13:52:20,676 - trainer - INFO - training using device=cpu
2022-09-23 13:52:20,676 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:20,677 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:20,681 - trainer - INFO - 
*****************[epoch: 95, global step: 96] eval training set at end of epoch***************
2022-09-23 13:52:20,682 - trainer - INFO - {
  "train_loss": 1.2828662395477295
}
2022-09-23 13:52:20,682 - trainer - INFO - start training epoch 96
2022-09-23 13:52:20,682 - trainer - INFO - training using device=cpu
2022-09-23 13:52:20,683 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:20,683 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:20,687 - trainer - INFO - 
*****************[epoch: 96, global step: 96] eval training set based on eval_every=2***************
2022-09-23 13:52:20,687 - trainer - INFO - {
  "train_loss": 1.1918438076972961
}
2022-09-23 13:52:20,690 - trainer - INFO - 
*****************[epoch: 96, global step: 96] eval development set based on eval_every=2***************
2022-09-23 13:52:20,691 - trainer - INFO - {
  "dev_loss": 0.9518857002258301,
  "dev_best_score_for_loss": -0.9518857002258301
}
2022-09-23 13:52:20,691 - trainer - INFO -    save the model with best score so far
2022-09-23 13:52:20,692 - trainer - INFO -    Check 3 checkpoints already saved
2022-09-23 13:52:20,693 - trainer - INFO -    There are more than keep_ck_num as specified, then remove the oldest saved checkpoint
2022-09-23 13:52:20,693 - trainer - INFO -   Remove checkpoint model/mlp_carrier\ck_90
2022-09-23 13:52:20,694 - trainer - INFO -   Save checkpoint to model/mlp_carrier
2022-09-23 13:52:20,696 - trainer - INFO - save model to path: model/mlp_carrier
2022-09-23 13:52:20,697 - trainer - INFO -   no_improve_count: 0
2022-09-23 13:52:20,697 - trainer - INFO -   patience: 200
2022-09-23 13:52:20,698 - trainer - INFO -    Check 2 checkpoints already saved
2022-09-23 13:52:20,698 - trainer - INFO -   Save checkpoint to model/mlp_carrier\ck_96
2022-09-23 13:52:20,701 - trainer - INFO - save model to path: model/mlp_carrier\ck_96
2022-09-23 13:52:20,702 - trainer - INFO - 
*****************[epoch: 96, global step: 97] eval training set at end of epoch***************
2022-09-23 13:52:20,702 - trainer - INFO - {
  "train_loss": 1.1008213758468628
}
2022-09-23 13:52:20,702 - trainer - INFO - start training epoch 97
2022-09-23 13:52:20,703 - trainer - INFO - training using device=cpu
2022-09-23 13:52:20,703 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:20,703 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:20,707 - trainer - INFO - 
*****************[epoch: 97, global step: 98] eval training set at end of epoch***************
2022-09-23 13:52:20,708 - trainer - INFO - {
  "train_loss": 0.9518856406211853
}
2022-09-23 13:52:20,708 - trainer - INFO - start training epoch 98
2022-09-23 13:52:20,708 - trainer - INFO - training using device=cpu
2022-09-23 13:52:20,709 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:20,709 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:20,712 - trainer - INFO - 
*****************[epoch: 98, global step: 98] eval training set based on eval_every=2***************
2022-09-23 13:52:20,712 - trainer - INFO - {
  "train_loss": 0.9688283801078796
}
2022-09-23 13:52:20,715 - trainer - INFO - 
*****************[epoch: 98, global step: 98] eval development set based on eval_every=2***************
2022-09-23 13:52:20,715 - trainer - INFO - {
  "dev_loss": 0.9886069297790527,
  "dev_best_score_for_loss": -0.9518857002258301
}
2022-09-23 13:52:20,715 - trainer - INFO -   no_improve_count: 1
2022-09-23 13:52:20,716 - trainer - INFO -   patience: 200
2022-09-23 13:52:20,717 - trainer - INFO -    Check 3 checkpoints already saved
2022-09-23 13:52:20,717 - trainer - INFO -    There are more than keep_ck_num as specified, then remove the oldest saved checkpoint
2022-09-23 13:52:20,717 - trainer - INFO -   Remove checkpoint model/mlp_carrier\ck_92
2022-09-23 13:52:20,718 - trainer - INFO -   Save checkpoint to model/mlp_carrier\ck_98
2022-09-23 13:52:20,720 - trainer - INFO - save model to path: model/mlp_carrier\ck_98
2022-09-23 13:52:20,721 - trainer - INFO - 
*****************[epoch: 98, global step: 99] eval training set at end of epoch***************
2022-09-23 13:52:20,721 - trainer - INFO - {
  "train_loss": 0.985771119594574
}
2022-09-23 13:52:20,722 - trainer - INFO - start training epoch 99
2022-09-23 13:52:20,722 - trainer - INFO - training using device=cpu
2022-09-23 13:52:20,722 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:20,723 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:20,727 - trainer - INFO - 
*****************[epoch: 99, global step: 100] eval training set at end of epoch***************
2022-09-23 13:52:20,727 - trainer - INFO - {
  "train_loss": 0.9886069297790527
}
2022-09-23 13:52:20,728 - trainer - INFO - start training epoch 100
2022-09-23 13:52:20,728 - trainer - INFO - training using device=cpu
2022-09-23 13:52:20,729 - trainer - INFO - 
*************hyperparam_dict**********

2022-09-23 13:52:20,729 - trainer - INFO - {
  "train_epochs": 100,
  "eval_batch_size": 64,
  "train_batch_size": 130,
  "no_improve_count": 0,
  "device": "cpu",
  "patience": 200,
  "save_path": "model/mlp_carrier",
  "eval_on": "loss",
  "eval_every": 2,
  "use_wandb": false,
  "loss_fn": "mse",
  "keep_ck_num": 3,
  "lr": 0.03
}
2022-09-23 13:52:20,732 - trainer - INFO - 
*****************[epoch: 100, global step: 100] eval training set based on eval_every=2***************
2022-09-23 13:52:20,733 - trainer - INFO - {
  "train_loss": 0.9258590638637543
}
2022-09-23 13:52:20,735 - trainer - INFO - 
*****************[epoch: 100, global step: 100] eval development set based on eval_every=2***************
2022-09-23 13:52:20,735 - trainer - INFO - {
  "dev_loss": 0.7996847033500671,
  "dev_best_score_for_loss": -0.7996847033500671
}
2022-09-23 13:52:20,735 - trainer - INFO -    save the model with best score so far
2022-09-23 13:52:20,736 - trainer - INFO -    Check 3 checkpoints already saved
2022-09-23 13:52:20,736 - trainer - INFO -    There are more than keep_ck_num as specified, then remove the oldest saved checkpoint
2022-09-23 13:52:20,737 - trainer - INFO -   Remove checkpoint model/mlp_carrier\ck_94
2022-09-23 13:52:20,737 - trainer - INFO -   Save checkpoint to model/mlp_carrier
2022-09-23 13:52:20,740 - trainer - INFO - save model to path: model/mlp_carrier
2022-09-23 13:52:20,740 - trainer - INFO -   no_improve_count: 0
2022-09-23 13:52:20,740 - trainer - INFO -   patience: 200
2022-09-23 13:52:20,741 - trainer - INFO -    Check 2 checkpoints already saved
2022-09-23 13:52:20,741 - trainer - INFO -   Save checkpoint to model/mlp_carrier\ck_100
2022-09-23 13:52:20,744 - trainer - INFO - save model to path: model/mlp_carrier\ck_100
2022-09-23 13:52:20,744 - trainer - INFO - 
*****************[epoch: 100, global step: 101] eval training set at end of epoch***************
2022-09-23 13:52:20,744 - trainer - INFO - {
  "train_loss": 0.8631111979484558
}
